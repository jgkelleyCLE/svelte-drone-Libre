{"version":3,"file":"_internal.js","sources":["../../src/_internal/cli/commands/backup/backupGroup.ts","../../src/_internal/cli/actions/backup/parseApiErr.ts","../../src/_internal/cli/debug.ts","../../src/_internal/cli/actions/dataset/validateDatasetName.ts","../../src/_internal/cli/actions/dataset/datasetNamePrompt.ts","../../src/_internal/cli/actions/dataset/chooseDatasetPrompt.ts","../../src/_internal/cli/actions/backup/resolveApiClient.ts","../../src/_internal/cli/commands/backup/disableBackupCommand.ts","../../src/_internal/cli/actions/backup/debug.ts","../../src/_internal/cli/actions/backup/archiveDir.ts","../../src/_internal/cli/actions/backup/chooseBackupIdPrompt.ts","../../src/_internal/cli/actions/backup/cleanupTmpDir.ts","../../src/_internal/cli/actions/backup/withRetry.ts","../../src/_internal/cli/actions/backup/downloadAsset.ts","../../src/_internal/cli/actions/backup/downloadDocument.ts","../../src/_internal/cli/actions/backup/fetchNextBackupPage.ts","../../src/_internal/cli/actions/backup/progressSpinner.ts","../../src/_internal/cli/util/humanFileSize.ts","../../src/_internal/cli/util/isPathDirName.ts","../../src/_internal/cli/commands/backup/downloadBackupCommand.ts","../../src/_internal/cli/commands/backup/enableBackupCommand.ts","../../src/_internal/cli/commands/backup/listBackupCommand.ts","../../src/_internal/cli/commands/build/buildCommand.ts","../../src/_internal/cli/actions/cors/addCorsOrigin.ts","../../src/_internal/cli/commands/cors/addCorsOriginCommand.ts","../../src/_internal/cli/commands/cors/corsGroup.ts","../../src/_internal/cli/commands/cors/deleteCorsOriginCommand.ts","../../src/_internal/cli/commands/cors/listCorsOriginsCommand.ts","../../src/_internal/cli/actions/dataset/alias/validateDatasetAliasName.ts","../../src/_internal/cli/actions/dataset/alias/promptForDatasetAliasName.ts","../../src/_internal/cli/commands/dataset/alias/datasetAliasesClient.ts","../../src/_internal/cli/commands/dataset/alias/createAliasHandler.ts","../../src/_internal/cli/commands/dataset/alias/deleteAliasHandler.ts","../../src/_internal/cli/commands/dataset/alias/linkAliasHandler.ts","../../src/_internal/cli/commands/dataset/alias/unlinkAliasHandler.ts","../../src/_internal/cli/commands/dataset/alias/aliasCommands.ts","../../src/_internal/cli/actions/dataset/listDatasetCopyJobs.ts","../../src/_internal/cli/util/getClientUrl.ts","../../src/_internal/cli/commands/dataset/copyDatasetCommand.ts","../../src/_internal/cli/commands/dataset/createDatasetCommand.ts","../../src/_internal/cli/commands/dataset/datasetGroup.ts","../../src/_internal/cli/commands/dataset/datasetVisibilityCommand.ts","../../src/_internal/cli/commands/dataset/deleteDatasetCommand.ts","../../src/_internal/cli/commands/dataset/exportDatasetCommand.ts","../../src/_internal/cli/commands/dataset/importDatasetCommand.ts","../../src/_internal/cli/commands/dataset/alias/listAliasesHandler.ts","../../src/_internal/cli/commands/dataset/listDatasetsCommand.ts","../../src/_internal/cli/util/determineIsCoreApp.ts","../../src/_internal/cli/commands/deploy/deployCommand.ts","../../src/_internal/cli/commands/deploy/undeployCommand.ts","../../src/_internal/cli/commands/dev/devCommand.ts","../../src/_internal/cli/commands/documents/createDocumentsCommand.ts","../../src/_internal/cli/commands/documents/deleteDocumentsCommand.ts","../../src/_internal/cli/commands/documents/documentsGroup.ts","../../src/_internal/cli/util/colorizeJson.ts","../../src/_internal/cli/commands/documents/getDocumentsCommand.ts","../../src/_internal/cli/commands/documents/queryDocumentsCommand.ts","../../src/_internal/cli/commands/documents/validateDocumentsCommand.ts","../../src/_internal/cli/commands/exec/execCommand.ts","../../src/_internal/cli/commands/graphql/deleteGraphQLAPICommand.ts","../../src/_internal/cli/commands/graphql/deployGraphQLAPICommand.ts","../../src/_internal/cli/commands/graphql/graphqlGroup.ts","../../src/_internal/cli/commands/graphql/listGraphQLAPIsCommand.ts","../../src/_internal/cli/commands/hook/createHookCommand.ts","../../src/_internal/cli/commands/hook/deleteHookCommand.ts","../../src/_internal/cli/commands/hook/hookGroup.ts","../../src/_internal/cli/commands/hook/printHookAttemptCommand.ts","../../src/_internal/cli/commands/hook/listHookLogsCommand.ts","../../src/_internal/cli/commands/hook/listHooksCommand.ts","../../src/_internal/cli/commands/manifest/extractManifestCommand.ts","../../src/_internal/cli/commands/manifest/manifestGroup.ts","../../src/_internal/cli/commands/migration/constants.ts","../../src/_internal/cli/commands/migration/templates/minimalAdvanced.ts","../../src/_internal/cli/commands/migration/templates/minimalSimple.ts","../../src/_internal/cli/commands/migration/templates/renameField.ts","../../src/_internal/cli/commands/migration/templates/renameType.ts","../../src/_internal/cli/commands/migration/templates/stringToPTE.ts","../../src/_internal/cli/commands/migration/createMigrationCommand.ts","../../src/_internal/cli/commands/migration/utils/resolveMigrationScript.ts","../../src/_internal/cli/commands/migration/listMigrationsCommand.ts","../../src/_internal/cli/commands/migration/migrationGroup.ts","../../src/_internal/cli/util/tree.ts","../../src/_internal/cli/commands/migration/prettyMutationFormatter.ts","../../src/_internal/cli/commands/migration/utils/ensureApiVersionFormat.ts","../../src/_internal/cli/commands/migration/runMigrationCommand.ts","../../src/_internal/cli/commands/preview/previewCommand.ts","../../src/_internal/cli/commands/schema/extractSchemaCommand.ts","../../src/_internal/cli/commands/schema/schemaGroup.ts","../../src/_internal/cli/commands/schema/validateSchemaCommand.ts","../../src/_internal/cli/util/isInteractive.ts","../../src/_internal/cli/commands/start/startCommand.ts","../../src/_internal/cli/util/prettifyQuotaError.ts","../../src/_internal/cli/commands/users/inviteUserCommand.ts","../../src/_internal/cli/commands/users/listUsersCommand.ts","../../src/_internal/cli/commands/users/usersGroup.ts","../../src/_internal/cli/commands/index.ts"],"sourcesContent":["import {type CliCommandGroupDefinition} from '@sanity/cli'\n\n// defaultApiVersion is the backend API version used for dataset backup.\nexport const defaultApiVersion = 'v2024-02-21'\n\nconst datasetBackupGroup: CliCommandGroupDefinition = {\n  name: 'backup',\n  signature: '[COMMAND]',\n  description: 'Manage backups.',\n  isGroupRoot: true,\n}\n\nexport default datasetBackupGroup\n","// apiErr is a type that represents an error returned by the API\ninterface ApiErr {\n  statusCode: number\n  message: string\n}\n\n// parseApiErr is a function that attempts with the best effort to parse\n// an error returned by the API since different API endpoint may end up\n// returning different error structures.\n// eslint-disable-next-line @typescript-eslint/no-explicit-any,@typescript-eslint/explicit-module-boundary-types\nfunction parseApiErr(err: any): ApiErr {\n  const apiErr = {} as ApiErr\n  if (err.code) {\n    apiErr.statusCode = err.code\n  } else if (err.statusCode) {\n    apiErr.statusCode = err.statusCode\n  }\n\n  if (err.message) {\n    apiErr.message = err.message\n  } else if (err.statusMessage) {\n    apiErr.message = err.statusMessage\n  } else if (err?.response?.body?.message) {\n    apiErr.message = err.response.body.message\n  } else if (err?.response?.data?.message) {\n    apiErr.message = err.response.data.message\n  } else {\n    // If no message can be extracted, print the whole error.\n    apiErr.message = JSON.stringify(err)\n  }\n\n  return apiErr\n}\n\nexport default parseApiErr\n","import debugIt from 'debug'\n\nexport const debug = debugIt('sanity:core')\n","const MAX_DATASET_NAME_LENGTH = 64\n\nexport function validateDatasetName(datasetName: string): false | string {\n  if (!datasetName) {\n    return 'Dataset name is missing'\n  }\n\n  const name = `${datasetName}`\n\n  if (name.toLowerCase() !== name) {\n    return 'Dataset name must be all lowercase characters'\n  }\n\n  if (name.length < 2) {\n    return 'Dataset name must be at least two characters long'\n  }\n\n  if (name.length > MAX_DATASET_NAME_LENGTH) {\n    return `Dataset name must be at most ${MAX_DATASET_NAME_LENGTH} characters`\n  }\n\n  if (!/^[a-z0-9]/.test(name)) {\n    return 'Dataset name must start with a letter or a number'\n  }\n\n  if (!/^[a-z0-9][-_a-z0-9]+$/.test(name)) {\n    return 'Dataset name must only contain letters, numbers, dashes and underscores'\n  }\n\n  if (/[-_]$/.test(name)) {\n    return 'Dataset name must not end with a dash or an underscore'\n  }\n\n  return false\n}\n","import {type CliPrompter} from '@sanity/cli'\n\nimport {validateDatasetName} from './validateDatasetName'\n\nexport function promptForDatasetName(\n  prompt: CliPrompter,\n  options: {message?: string; default?: string} = {},\n): Promise<string> {\n  return prompt.single({\n    type: 'input',\n    message: 'Dataset name:',\n    validate: (name) => {\n      const err = validateDatasetName(name)\n      if (err) {\n        return err\n      }\n\n      return true\n    },\n    ...options,\n  })\n}\n","import {type CliCommandContext} from '@sanity/cli'\n\nimport {debug} from '../../debug'\nimport {promptForDatasetName} from './datasetNamePrompt'\n\nexport async function chooseDatasetPrompt(\n  context: CliCommandContext,\n  options: {message?: string; allowCreation?: boolean} = {},\n): Promise<string> {\n  const {apiClient, prompt} = context\n  const {message, allowCreation} = options\n  const client = apiClient()\n\n  const datasets = await client.datasets.list()\n  const hasProduction = datasets.find((dataset) => dataset.name === 'production')\n  const datasetChoices = datasets.map((dataset) => ({value: dataset.name}))\n  const selected = await prompt.single({\n    message: message || 'Select dataset to use',\n    type: 'list',\n    choices: allowCreation\n      ? [{value: 'new', name: 'Create new dataset'}, new prompt.Separator(), ...datasetChoices]\n      : datasetChoices,\n  })\n\n  if (selected === 'new') {\n    debug('User wants to create a new dataset, prompting for name')\n    const newDatasetName = await promptForDatasetName(prompt, {\n      message: 'Name your dataset:',\n      default: hasProduction ? undefined : 'production',\n    })\n    await client.datasets.create(newDatasetName)\n    return newDatasetName\n  }\n\n  return selected\n}\n","import {type CliCommandContext} from '@sanity/cli'\nimport {type SanityClient} from '@sanity/client'\n\nimport {chooseDatasetPrompt} from '../dataset/chooseDatasetPrompt'\n\ntype ResolvedApiClient = {\n  projectId: string\n  datasetName: string\n  token?: string\n  client: SanityClient\n}\n\nasync function resolveApiClient(\n  context: CliCommandContext,\n  datasetName: string,\n  apiVersion: string,\n): Promise<ResolvedApiClient> {\n  const {apiClient} = context\n\n  let client = apiClient()\n  const {projectId, token} = client.config()\n\n  if (!projectId) {\n    throw new Error('Project ID not defined')\n  }\n\n  // If no dataset provided, explicitly ask for dataset instead of using dataset\n  // configured in Sanity config. Aligns with `sanity dataset export` behavior.\n  let selectedDataset: string = datasetName\n  if (!selectedDataset) {\n    selectedDataset = await chooseDatasetPrompt(context, {\n      message: 'Select the dataset name:',\n    })\n  }\n\n  client = client.withConfig({dataset: datasetName, apiVersion})\n\n  return {\n    projectId,\n    datasetName: selectedDataset,\n    token,\n    client,\n  }\n}\n\nexport default resolveApiClient\n","import {type CliCommandDefinition} from '@sanity/cli'\n\nimport parseApiErr from '../../actions/backup/parseApiErr'\nimport resolveApiClient from '../../actions/backup/resolveApiClient'\nimport {defaultApiVersion} from './backupGroup'\n\nconst helpText = `\nExamples\n  sanity backup disable DATASET_NAME\n`\n\nconst disableDatasetBackupCommand: CliCommandDefinition = {\n  name: 'disable',\n  group: 'backup',\n  signature: '[DATASET_NAME]',\n  description: 'Disable backup for a dataset.',\n  helpText,\n  action: async (args, context) => {\n    const {output, chalk} = context\n    const [dataset] = args.argsWithoutOptions\n    const {projectId, datasetName, token, client} = await resolveApiClient(\n      context,\n      dataset,\n      defaultApiVersion,\n    )\n\n    try {\n      await client.request({\n        method: 'PUT',\n        headers: {Authorization: `Bearer ${token}`},\n        uri: `/projects/${projectId}/datasets/${datasetName}/settings/backups`,\n        body: {\n          enabled: false,\n        },\n      })\n      output.print(`${chalk.green(`Disabled daily backups for dataset ${datasetName}\\n`)}`)\n    } catch (error) {\n      const {message} = parseApiErr(error)\n      output.print(`${chalk.red(`Disabling dataset backup failed: ${message}`)}\\n`)\n    }\n  },\n}\n\nexport default disableDatasetBackupCommand\n","export default require('debug')('sanity:backup')\n","import {createWriteStream} from 'node:fs'\nimport zlib from 'node:zlib'\n\nimport {type ProgressData} from 'archiver'\n\nimport debug from './debug'\n\nconst archiver = require('archiver')\n\n// ProgressCb is a callback that is called with the number of bytes processed so far.\ntype ProgressCb = (processedBytes: number) => void\n\n// archiveDir creates a tarball of the given directory and writes it to the given file path.\nfunction archiveDir(tmpOutDir: string, outFilePath: string, progressCb: ProgressCb): Promise<void> {\n  return new Promise((resolve, reject) => {\n    const archiveDestination = createWriteStream(outFilePath)\n    archiveDestination.on('error', (err: Error) => {\n      reject(err)\n    })\n\n    archiveDestination.on('close', () => {\n      resolve()\n    })\n\n    const archive = archiver('tar', {\n      gzip: true,\n      gzipOptions: {level: zlib.constants.Z_DEFAULT_COMPRESSION},\n    })\n\n    archive.on('error', (err: Error) => {\n      debug('Archiving errored!\\n%s', err.stack)\n      reject(err)\n    })\n\n    // Catch warnings for non-blocking errors (stat failures and others)\n    archive.on('warning', (err: Error) => {\n      debug('Archive warning: %s', err.message)\n    })\n\n    archive.on('progress', (progress: ProgressData) => {\n      progressCb(progress.fs.processedBytes)\n    })\n\n    // Pipe archive data to the file\n    archive.pipe(archiveDestination)\n    archive.directory(tmpOutDir, false)\n    archive.finalize()\n  })\n}\n\nexport default archiveDir\n","import {type CliCommandContext} from '@sanity/cli'\n\nimport {defaultApiVersion} from '../../commands/backup/backupGroup'\nimport resolveApiClient from './resolveApiClient'\n\n// maxBackupIdsShown is the maximum number of backup IDs to show in the prompt.\n// Higher numbers will cause the prompt to be slow.\nconst maxBackupIdsShown = 100\n\nasync function chooseBackupIdPrompt(\n  context: CliCommandContext,\n  datasetName: string,\n): Promise<string> {\n  const {prompt} = context\n\n  const {projectId, token, client} = await resolveApiClient(context, datasetName, defaultApiVersion)\n\n  try {\n    // Fetch last $maxBackupIdsShown backups for this dataset.\n    // We expect here that API returns backups sorted by creation date in descending order.\n    const response = await client.request({\n      headers: {Authorization: `Bearer ${token}`},\n      uri: `/projects/${projectId}/datasets/${datasetName}/backups`,\n      query: {limit: maxBackupIdsShown.toString()},\n    })\n\n    if (response?.backups?.length > 0) {\n      const backupIdChoices = response.backups.map((backup: {id: string}) => ({\n        value: backup.id,\n      }))\n      const selected = await prompt.single({\n        message: `Select backup ID to use (only last ${maxBackupIdsShown} shown)`,\n        type: 'list',\n        choices: backupIdChoices,\n      })\n\n      return selected\n    }\n  } catch (err) {\n    throw new Error(`Failed to fetch backups for dataset ${datasetName}: ${err.message}`)\n  }\n\n  throw new Error('No backups found')\n}\n\nexport default chooseBackupIdPrompt\n","import {rimraf} from 'rimraf'\n\nimport debug from './debug'\n\nasync function cleanupTmpDir(tmpDir: string): Promise<void> {\n  try {\n    await rimraf(tmpDir)\n  } catch (err) {\n    debug(`Error cleaning up temporary files: ${err.message}`)\n  }\n}\n\nexport default cleanupTmpDir\n","import debug from './debug'\n\nconst MAX_RETRIES = 5\nconst BACKOFF_DELAY_BASE = 200\n\nconst exponentialBackoff = (retryCount: number) => Math.pow(2, retryCount) * BACKOFF_DELAY_BASE\n\nasync function withRetry<T>(\n  operation: () => Promise<T>,\n  maxRetries: number = MAX_RETRIES,\n): Promise<T> {\n  for (let retryCount = 0; retryCount < maxRetries; retryCount++) {\n    try {\n      return await operation()\n    } catch (err) {\n      // Immediately rethrow if the error is not server-related.\n      if (err.response && err.response.statusCode && err.response.statusCode < 500) {\n        throw err\n      }\n\n      const retryDelay = exponentialBackoff(retryCount)\n      debug(`Error encountered, retrying after ${retryDelay}ms: %s`, err.message)\n      await new Promise((resolve) => setTimeout(resolve, retryDelay))\n    }\n  }\n\n  throw new Error('Operation failed after all retries')\n}\n\nexport default withRetry\n","import {createWriteStream} from 'node:fs'\nimport path from 'node:path'\nimport {pipeline} from 'node:stream/promises'\n\nimport {getIt} from 'get-it'\n// eslint-disable-next-line import/extensions\nimport {keepAlive, promise} from 'get-it/middleware'\n\nimport debug from './debug'\nimport withRetry from './withRetry'\n\nconst CONNECTION_TIMEOUT = 15 * 1000 // 15 seconds\nconst READ_TIMEOUT = 3 * 60 * 1000 // 3 minutes\n\nconst request = getIt([keepAlive(), promise()])\n\nasync function downloadAsset(\n  url: string,\n  fileName: string,\n  fileType: string,\n  outDir: string,\n): Promise<void> {\n  // File names that contain a path to file (e.g. sanity-storage/assets/file-name.tar.gz) fail when archive is\n  // created due to missing parent dir (e.g. sanity-storage/assets), so we want to handle them by taking\n  // the base name as file name.\n  const normalizedFileName = path.basename(fileName)\n\n  const assetFilePath = getAssetFilePath(normalizedFileName, fileType, outDir)\n  await withRetry(async () => {\n    const response = await request({\n      url: url,\n      maxRedirects: 5,\n      timeout: {connect: CONNECTION_TIMEOUT, socket: READ_TIMEOUT},\n      stream: true,\n    })\n\n    debug('Received asset %s with status code %d', normalizedFileName, response?.statusCode)\n\n    await pipeline(response.body, createWriteStream(assetFilePath))\n  })\n}\n\nfunction getAssetFilePath(fileName: string, fileType: string, outDir: string): string {\n  // Set assetFilePath if we are downloading an asset file.\n  // If it's a JSON document, assetFilePath will be an empty string.\n  let assetFilePath = ''\n  if (fileType === 'image') {\n    assetFilePath = path.join(outDir, 'images', fileName)\n  } else if (fileType === 'file') {\n    assetFilePath = path.join(outDir, 'files', fileName)\n  }\n\n  return assetFilePath\n}\n\nexport default downloadAsset\n","import {getIt, type MiddlewareResponse} from 'get-it'\n// eslint-disable-next-line import/extensions\nimport {keepAlive, promise} from 'get-it/middleware'\n\nimport debug from './debug'\nimport withRetry from './withRetry'\n\nconst CONNECTION_TIMEOUT = 15 * 1000 // 15 seconds\nconst READ_TIMEOUT = 3 * 60 * 1000 // 3 minutes\n\nconst request = getIt([keepAlive(), promise()])\n\n// eslint-disable-next-line @typescript-eslint/no-explicit-any\nasync function downloadDocument(url: string): Promise<any> {\n  const response = await withRetry<MiddlewareResponse>(() =>\n    request({\n      url,\n      maxRedirects: 5,\n      timeout: {connect: CONNECTION_TIMEOUT, socket: READ_TIMEOUT},\n    }),\n  )\n\n  debug('Received document from %s with status code %d', url, response?.statusCode)\n\n  return response.body\n}\n\nexport default downloadDocument\n","import {Readable} from 'node:stream'\n\nimport {type QueryParams, type SanityClient} from '@sanity/client'\n\ntype File = {\n  name: string\n  url: string\n  type: string\n}\n\ntype GetBackupResponse = {\n  createdAt: string\n  totalFiles: number\n  files: File[]\n  nextCursor?: string\n}\n\nclass PaginatedGetBackupStream extends Readable {\n  private cursor = ''\n  private readonly client: SanityClient\n  private readonly projectId: string\n  private readonly datasetName: string\n  private readonly backupId: string\n  private readonly token: string\n  public totalFiles = 0\n\n  constructor(\n    client: SanityClient,\n    projectId: string,\n    datasetName: string,\n    backupId: string,\n    token: string,\n  ) {\n    super({objectMode: true})\n    this.client = client\n    this.projectId = projectId\n    this.datasetName = datasetName\n    this.backupId = backupId\n    this.token = token\n  }\n\n  async _read(): Promise<void> {\n    try {\n      const data = await this.fetchNextBackupPage()\n\n      // Set totalFiles when it's fetched for the first time\n      if (this.totalFiles === 0) {\n        this.totalFiles = data.totalFiles\n      }\n\n      data.files.forEach((file: File) => this.push(file))\n\n      if (typeof data.nextCursor === 'string' && data.nextCursor !== '') {\n        this.cursor = data.nextCursor\n      } else {\n        // No more pages left to fetch.\n        this.push(null)\n      }\n    } catch (err) {\n      this.destroy(err as Error)\n    }\n  }\n\n  // fetchNextBackupPage fetches the next page of backed up files from the backup API.\n  async fetchNextBackupPage(): Promise<GetBackupResponse> {\n    const query: QueryParams = this.cursor === '' ? {} : {nextCursor: this.cursor}\n\n    try {\n      return await this.client.request({\n        headers: {Authorization: `Bearer ${this.token}`},\n        uri: `/projects/${this.projectId}/datasets/${this.datasetName}/backups/${this.backupId}`,\n        query,\n      })\n    } catch (error) {\n      // It can be clearer to pull this logic out in a  common error handling function for re-usability.\n      let msg = error.statusCode ? error.response.body.message : error.message\n\n      // If no message can be extracted, print the whole error.\n      if (msg === undefined) {\n        msg = String(error)\n      }\n      throw new Error(`Downloading dataset backup failed: ${msg}`)\n    }\n  }\n}\n\nexport {PaginatedGetBackupStream}\nexport type {File, GetBackupResponse}\n","import {type CliOutputter} from '@sanity/cli'\nimport prettyMs from 'pretty-ms'\n\ntype ProgressEvent = {\n  step: string\n  update?: boolean\n  current?: number\n  total?: number\n}\n\ninterface ProgressSpinner {\n  set: (progress: ProgressEvent) => void\n  update: (progress: ProgressEvent) => void\n  succeed: () => void\n  fail: () => void\n}\n\nconst newProgress = (output: CliOutputter, startStep: string): ProgressSpinner => {\n  let spinner = output.spinner(startStep).start()\n  let lastProgress: ProgressEvent = {step: startStep}\n  let start = Date.now()\n\n  const print = (progress: ProgressEvent) => {\n    const elapsed = prettyMs(Date.now() - start)\n    if (progress.current && progress.current > 0 && progress.total && progress.total > 0) {\n      spinner.text = `${progress.step} (${progress.current}/${progress.total}) [${elapsed}]`\n    } else {\n      spinner.text = `${progress.step} [${elapsed}]`\n    }\n  }\n\n  return {\n    set: (progress: ProgressEvent) => {\n      if (progress.step !== lastProgress.step) {\n        print(lastProgress) // Print the last progress before moving on\n        spinner.succeed()\n        spinner = output.spinner(progress.step).start()\n        start = Date.now()\n      } else if (progress.step === lastProgress.step && progress.update) {\n        print(progress)\n      }\n      lastProgress = progress\n    },\n    update: (progress: ProgressEvent) => {\n      print(progress)\n      lastProgress = progress\n    },\n    succeed: () => {\n      spinner.succeed()\n      start = Date.now()\n    },\n    fail: () => {\n      spinner.fail()\n      start = Date.now()\n    },\n  }\n}\n\nexport default newProgress\n","function humanFileSize(size: number): string {\n  const i = size == 0 ? 0 : Math.floor(Math.log(size) / Math.log(1024))\n  return `${(size / Math.pow(1024, i)).toFixed(2)} ${['B', 'kB', 'MB', 'GB', 'TB'][i]}`\n}\n\nexport default humanFileSize\n","function isPathDirName(filepath: string): boolean {\n  // Check if the path has an extension, commonly indicating a file\n  return !/\\.\\w+$/.test(filepath)\n}\n\nexport default isPathDirName\n","import {createWriteStream, existsSync, mkdirSync} from 'node:fs'\nimport {mkdtemp} from 'node:fs/promises'\nimport {tmpdir} from 'node:os'\nimport path from 'node:path'\nimport {finished} from 'node:stream/promises'\n\nimport {\n  type CliCommandArguments,\n  type CliCommandContext,\n  type CliCommandDefinition,\n  type SanityClient,\n} from '@sanity/cli'\nimport {absolutify} from '@sanity/util/fs'\nimport {Mutex} from 'async-mutex'\nimport createDebug from 'debug'\nimport {isString} from 'lodash'\nimport prettyMs from 'pretty-ms'\nimport {hideBin} from 'yargs/helpers'\nimport yargs from 'yargs/yargs'\n\nimport archiveDir from '../../actions/backup/archiveDir'\nimport chooseBackupIdPrompt from '../../actions/backup/chooseBackupIdPrompt'\nimport cleanupTmpDir from '../../actions/backup/cleanupTmpDir'\nimport downloadAsset from '../../actions/backup/downloadAsset'\nimport downloadDocument from '../../actions/backup/downloadDocument'\nimport {type File, PaginatedGetBackupStream} from '../../actions/backup/fetchNextBackupPage'\nimport parseApiErr from '../../actions/backup/parseApiErr'\nimport newProgress from '../../actions/backup/progressSpinner'\nimport resolveApiClient from '../../actions/backup/resolveApiClient'\nimport humanFileSize from '../../util/humanFileSize'\nimport isPathDirName from '../../util/isPathDirName'\nimport {defaultApiVersion} from './backupGroup'\n\nconst debug = createDebug('sanity:backup')\n\nconst DEFAULT_DOWNLOAD_CONCURRENCY = 10\nconst MAX_DOWNLOAD_CONCURRENCY = 24\n\ninterface DownloadBackupOptions {\n  projectId: string\n  datasetName: string\n  token: string\n  backupId: string\n  outDir: string\n  outFileName: string\n  overwrite: boolean\n  concurrency: number\n}\n\nconst helpText = `\nOptions\n  --backup-id <string> The backup ID to download. (required)\n  --out <string>       The file or directory path the backup should download to.\n  --overwrite          Allows overwriting of existing backup file.\n  --concurrency <num>  Concurrent number of backup item downloads. (max: 24)\n\nExamples\n  sanity backup download DATASET_NAME --backup-id 2024-01-01-backup-1\n  sanity backup download DATASET_NAME --backup-id 2024-01-01-backup-2 --out /path/to/file\n  sanity backup download DATASET_NAME --backup-id 2024-01-01-backup-3 --out /path/to/file --overwrite\n`\n\nfunction parseCliFlags(args: {argv?: string[]}) {\n  return yargs(hideBin(args.argv || process.argv).slice(2))\n    .options('backup-id', {type: 'string'})\n    .options('out', {type: 'string'})\n    .options('concurrency', {type: 'number', default: DEFAULT_DOWNLOAD_CONCURRENCY})\n    .options('overwrite', {type: 'boolean', default: false}).argv\n}\n\nconst downloadBackupCommand: CliCommandDefinition = {\n  name: 'download',\n  group: 'backup',\n  signature: '[DATASET_NAME]',\n  description: 'Download a dataset backup to a local file.',\n  helpText,\n  // eslint-disable-next-line max-statements\n  action: async (args, context) => {\n    const {output, chalk} = context\n    const [client, opts] = await prepareBackupOptions(context, args)\n    const {projectId, datasetName, backupId, outDir, outFileName} = opts\n\n    // If any of the output path or file name is empty, cancel the operation.\n    if (outDir === '' || outFileName === '') {\n      output.print('Operation cancelled.')\n      return\n    }\n    const outFilePath = path.join(outDir, outFileName)\n\n    output.print('╭───────────────────────────────────────────────────────────╮')\n    output.print('│                                                           │')\n    output.print('│ Downloading backup for:                                   │')\n    output.print(`│ ${chalk.bold('projectId')}: ${chalk.cyan(projectId).padEnd(56)} │`)\n    output.print(`│ ${chalk.bold('dataset')}: ${chalk.cyan(datasetName).padEnd(58)} │`)\n    output.print(`│ ${chalk.bold('backupId')}: ${chalk.cyan(backupId).padEnd(56)} │`)\n    output.print('│                                                           │')\n    output.print('╰───────────────────────────────────────────────────────────╯')\n    output.print('')\n    output.print(`Downloading backup to \"${chalk.cyan(outFilePath)}\"`)\n\n    const start = Date.now()\n    const progressSpinner = newProgress(output, 'Setting up backup environment...')\n\n    // Create a unique temporary directory to store files before bundling them into the archive at outputPath.\n    // Temporary directories are normally deleted at the end of backup process, any unexpected exit may leave them\n    // behind, hence it is important to create a unique directory for each attempt.\n    const tmpOutDir = await mkdtemp(path.join(tmpdir(), `sanity-backup-`))\n\n    // Create required directories if they don't exist.\n    for (const dir of [outDir, path.join(tmpOutDir, 'images'), path.join(tmpOutDir, 'files')]) {\n      mkdirSync(dir, {recursive: true})\n    }\n\n    debug('Writing to temporary directory %s', tmpOutDir)\n    const tmpOutDocumentsFile = path.join(tmpOutDir, 'data.ndjson')\n\n    // Handle concurrent writes to the same file using mutex.\n    const docOutStream = createWriteStream(tmpOutDocumentsFile)\n    const docWriteMutex = new Mutex()\n\n    try {\n      const backupFileStream = new PaginatedGetBackupStream(\n        client,\n        opts.projectId,\n        opts.datasetName,\n        opts.backupId,\n        opts.token,\n      )\n\n      const files: File[] = []\n      let i = 0\n      for await (const file of backupFileStream) {\n        files.push(file)\n        i++\n        progressSpinner.set({\n          step: `Reading backup files...`,\n          update: true,\n          current: i,\n          total: backupFileStream.totalFiles,\n        })\n      }\n\n      let totalItemsDownloaded = 0\n      // This is dynamically imported because this module is ESM only and this file gets compiled to CJS at this time.\n      const {default: pMap} = await import('p-map')\n      await pMap(\n        files,\n        async (file: File) => {\n          if (file.type === 'file' || file.type === 'image') {\n            await downloadAsset(file.url, file.name, file.type, tmpOutDir)\n          } else {\n            const doc = await downloadDocument(file.url)\n            await docWriteMutex.runExclusive(() => {\n              docOutStream.write(`${doc}\\n`)\n            })\n          }\n\n          totalItemsDownloaded += 1\n          progressSpinner.set({\n            step: `Downloading documents and assets...`,\n            update: true,\n            current: totalItemsDownloaded,\n            total: backupFileStream.totalFiles,\n          })\n        },\n        {concurrency: opts.concurrency},\n      )\n    } catch (error) {\n      progressSpinner.fail()\n      const {message} = parseApiErr(error)\n      throw new Error(`Downloading dataset backup failed: ${message}`)\n    }\n\n    docOutStream.end()\n    await finished(docOutStream)\n\n    progressSpinner.set({step: `Archiving files into a tarball...`, update: true})\n    try {\n      await archiveDir(tmpOutDir, outFilePath, (processedBytes: number) => {\n        progressSpinner.update({\n          step: `Archiving files into a tarball, ${humanFileSize(processedBytes)} bytes written...`,\n        })\n      })\n    } catch (err) {\n      progressSpinner.fail()\n      throw new Error(`Archiving backup failed: ${err.message}`)\n    }\n\n    progressSpinner.set({\n      step: `Cleaning up temporary files at ${chalk.cyan(`${tmpOutDir}`)}`,\n    })\n    await cleanupTmpDir(tmpOutDir)\n\n    progressSpinner.set({\n      step: `Backup download complete [${prettyMs(Date.now() - start)}]`,\n    })\n    progressSpinner.succeed()\n  },\n}\n\n// prepareBackupOptions validates backup options from CLI and prepares Client and DownloadBackupOptions.\nasync function prepareBackupOptions(\n  context: CliCommandContext,\n  args: CliCommandArguments,\n): Promise<[SanityClient, DownloadBackupOptions]> {\n  const flags = await parseCliFlags(args)\n  const [dataset] = args.argsWithoutOptions\n  const {prompt, workDir} = context\n  const {projectId, datasetName, client} = await resolveApiClient(\n    context,\n    dataset,\n    defaultApiVersion,\n  )\n\n  const {token} = client.config()\n  if (!isString(token) || token.length < 1) {\n    throw new Error(`token is missing`)\n  }\n\n  if (!isString(datasetName) || datasetName.length < 1) {\n    throw new Error(`dataset ${datasetName} must be a valid dataset name`)\n  }\n\n  const backupId = String(flags['backup-id'] || (await chooseBackupIdPrompt(context, datasetName)))\n  if (backupId.length < 1) {\n    throw new Error(`backup-id ${flags['backup-id']} should be a valid string`)\n  }\n\n  if ('concurrency' in flags) {\n    if (flags.concurrency < 1 || flags.concurrency > MAX_DOWNLOAD_CONCURRENCY) {\n      throw new Error(`concurrency should be in 1 to ${MAX_DOWNLOAD_CONCURRENCY} range`)\n    }\n  }\n\n  const defaultOutFileName = `${datasetName}-backup-${backupId}.tar.gz`\n  let out = await (async (): Promise<string> => {\n    if (flags.out !== undefined) {\n      // Rewrite the output path to an absolute path, if it is not already.\n      return absolutify(flags.out)\n    }\n\n    const input = await prompt.single({\n      type: 'input',\n      message: 'Output path:',\n      default: path.join(workDir, defaultOutFileName),\n      filter: absolutify,\n    })\n    return input\n  })()\n\n  // If path is a directory name, then add a default file name to the path.\n  if (isPathDirName(out)) {\n    out = path.join(out, defaultOutFileName)\n  }\n\n  // If the file already exists, ask for confirmation if it should be overwritten.\n  if (!flags.overwrite && existsSync(out)) {\n    const shouldOverwrite = await prompt.single({\n      type: 'confirm',\n      message: `File \"${out}\" already exists, would you like to overwrite it?`,\n      default: false,\n    })\n\n    // If the user does not want to overwrite the file, set the output path to an empty string.\n    // This should be handled by the caller of this function as cancel operation.\n    if (!shouldOverwrite) {\n      out = ''\n    }\n  }\n\n  return [\n    client,\n    {\n      projectId,\n      datasetName,\n      backupId,\n      token,\n      outDir: path.dirname(out),\n      outFileName: path.basename(out),\n      overwrite: flags.overwrite,\n      concurrency: flags.concurrency || DEFAULT_DOWNLOAD_CONCURRENCY,\n    },\n  ]\n}\n\nexport default downloadBackupCommand\n","import {type CliCommandDefinition} from '@sanity/cli'\n\nimport parseApiErr from '../../actions/backup/parseApiErr'\nimport resolveApiClient from '../../actions/backup/resolveApiClient'\nimport {defaultApiVersion} from './backupGroup'\n\nconst helpText = `\nExamples\n  sanity backup enable DATASET_NAME\n`\n\nconst enableDatasetBackupCommand: CliCommandDefinition = {\n  name: 'enable',\n  group: 'backup',\n  signature: '[DATASET_NAME]',\n  description: 'Enable backup for a dataset.',\n  helpText,\n  action: async (args, context) => {\n    const {output, chalk} = context\n    const [dataset] = args.argsWithoutOptions\n    const {projectId, datasetName, token, client} = await resolveApiClient(\n      context,\n      dataset,\n      defaultApiVersion,\n    )\n\n    try {\n      await client.request({\n        method: 'PUT',\n        headers: {Authorization: `Bearer ${token}`},\n        uri: `/projects/${projectId}/datasets/${datasetName}/settings/backups`,\n        body: {\n          enabled: true,\n        },\n      })\n\n      output.print(\n        `${chalk.green(\n          `Enabled backups for dataset ${datasetName}.\\nPlease note that it may take up to 24 hours before the first backup is created.\\n`,\n        )}`,\n      )\n\n      output.print(\n        `${chalk.bold(`Retention policies may apply depending on your plan and agreement.\\n`)}`,\n      )\n    } catch (error) {\n      const {message} = parseApiErr(error)\n      output.print(`${chalk.red(`Enabling dataset backup failed: ${message}`)}\\n`)\n    }\n  },\n}\nexport default enableDatasetBackupCommand\n","import {type CliCommandDefinition} from '@sanity/cli'\nimport {Table} from 'console-table-printer'\nimport {isAfter, isValid, lightFormat, parse} from 'date-fns'\nimport {hideBin} from 'yargs/helpers'\nimport yargs from 'yargs/yargs'\n\nimport parseApiErr from '../../actions/backup/parseApiErr'\nimport resolveApiClient from '../../actions/backup/resolveApiClient'\nimport {defaultApiVersion} from './backupGroup'\n\nconst DEFAULT_LIST_BACKUP_LIMIT = 30\n\ninterface ListDatasetBackupFlags {\n  before?: string\n  after?: string\n  limit?: string\n}\n\ntype ListBackupRequestQueryParams = {\n  before?: string\n  after?: string\n  limit: string\n}\n\ntype ListBackupResponse = {\n  backups: ListBackupResponseItem[]\n}\n\ntype ListBackupResponseItem = {\n  id: string\n  createdAt: string\n}\n\nconst helpText = `\nOptions\n  --limit <int>     Maximum number of backups returned. Default 30.\n  --after <string>  Only return backups after this date (inclusive)\n  --before <string> Only return backups before this date (exclusive). Cannot be younger than <after> if specified.\n\nExamples\n  sanity backup list DATASET_NAME\n  sanity backup list DATASET_NAME --limit 50\n  sanity backup list DATASET_NAME --after 2024-01-31 --limit 10\n  sanity backup list DATASET_NAME --after 2024-01-31 --before 2024-01-10\n`\n\nfunction parseCliFlags(args: {argv?: string[]}) {\n  return yargs(hideBin(args.argv || process.argv).slice(2))\n    .options('after', {type: 'string'})\n    .options('before', {type: 'string'})\n    .options('limit', {type: 'number', default: DEFAULT_LIST_BACKUP_LIMIT, alias: 'l'}).argv\n}\n\nconst listDatasetBackupCommand: CliCommandDefinition<ListDatasetBackupFlags> = {\n  name: 'list',\n  group: 'backup',\n  signature: '[DATASET_NAME]',\n  description: 'List available backups for a dataset.',\n  helpText,\n  action: async (args, context) => {\n    const {output, chalk} = context\n    const flags = await parseCliFlags(args)\n    const [dataset] = args.argsWithoutOptions\n\n    const {projectId, datasetName, token, client} = await resolveApiClient(\n      context,\n      dataset,\n      defaultApiVersion,\n    )\n\n    const query: ListBackupRequestQueryParams = {limit: DEFAULT_LIST_BACKUP_LIMIT.toString()}\n    if (flags.limit) {\n      // We allow limit up to Number.MAX_SAFE_INTEGER to leave it for server-side validation,\n      //  while still sending sensible value in limit string.\n      if (flags.limit < 1 || flags.limit > Number.MAX_SAFE_INTEGER) {\n        throw new Error(\n          `Parsing --limit: must be an integer between 1 and ${Number.MAX_SAFE_INTEGER}`,\n        )\n      }\n      query.limit = flags.limit.toString()\n    }\n\n    if (flags.before || flags.after) {\n      try {\n        const parsedBefore = processDateFlags(flags.before)\n        const parsedAfter = processDateFlags(flags.after)\n\n        if (parsedAfter && parsedBefore && isAfter(parsedAfter, parsedBefore)) {\n          throw new Error('--after date must be before --before')\n        }\n\n        query.before = flags.before\n        query.after = flags.after\n      } catch (err) {\n        throw new Error(`Parsing date flags: ${err}`)\n      }\n    }\n\n    let response\n    try {\n      response = await client.request<ListBackupResponse>({\n        headers: {Authorization: `Bearer ${token}`},\n        uri: `/projects/${projectId}/datasets/${datasetName}/backups`,\n        query: {...query},\n      })\n    } catch (error) {\n      const {message} = parseApiErr(error)\n      output.error(`${chalk.red(`List dataset backup failed: ${message}`)}\\n`)\n    }\n\n    if (response && response.backups) {\n      if (response.backups.length === 0) {\n        output.print('No backups found.')\n        return\n      }\n\n      const table = new Table({\n        columns: [\n          {name: 'resource', title: 'RESOURCE', alignment: 'left'},\n          {name: 'createdAt', title: 'CREATED AT', alignment: 'left'},\n          {name: 'backupId', title: 'BACKUP ID', alignment: 'left'},\n        ],\n      })\n\n      response.backups.forEach((backup: ListBackupResponseItem) => {\n        const {id, createdAt} = backup\n        table.addRow({\n          resource: 'Dataset',\n          createdAt: lightFormat(Date.parse(createdAt), 'yyyy-MM-dd HH:mm:ss'),\n          backupId: id,\n        })\n      })\n\n      table.printTable()\n    }\n  },\n}\n\nfunction processDateFlags(date: string | undefined): Date | undefined {\n  if (!date) return undefined\n  const parsedDate = parse(date, 'yyyy-MM-dd', new Date())\n  if (isValid(parsedDate)) {\n    return parsedDate\n  }\n\n  throw new Error(`Invalid ${date} date format. Use YYYY-MM-DD`)\n}\n\nexport default listDatasetBackupCommand\n","import type {CliCommandArguments, CliCommandContext, CliCommandDefinition} from '@sanity/cli'\nimport {BuildSanityStudioCommandFlags} from '../../actions/build/buildAction'\n\nconst helpText = `\nOptions\n  --source-maps Enable source maps for built bundles (increases size of bundle)\n  --auto-updates / --no-auto-updates Enable/disable auto updates of studio versions\n  --no-minify Skip minifying built JavaScript (speeds up build, increases size of bundle)\n  -y, --yes Unattended mode, answers \"yes\" to any \"yes/no\" prompt and otherwise uses defaults\n\nExamples\n  sanity build\n  sanity build --no-minify --source-maps\n`\n\nconst buildCommand: CliCommandDefinition = {\n  name: 'build',\n  signature: '[OUTPUT_DIR]',\n  description: 'Builds the Sanity Studio configuration into a static bundle',\n  action: async (\n    args: CliCommandArguments<BuildSanityStudioCommandFlags>,\n    context: CliCommandContext,\n    overrides?: {basePath?: string},\n  ) => {\n    const buildAction = await getBuildAction()\n\n    return buildAction(args, context, overrides)\n  },\n  helpText,\n}\n\nasync function getBuildAction() {\n  // NOTE: in dev-mode we want to include from `src` so we need to use `.ts` extension\n  // NOTE: this `if` statement is not included in the output bundle\n  if (__DEV__) {\n    // eslint-disable-next-line import/extensions\n    const mod: typeof import('../../actions/build/buildAction') = require('../../actions/build/buildAction.ts')\n\n    return mod.default\n  }\n\n  const mod = await import('../../actions/build/buildAction')\n\n  return mod.default\n}\n\nexport default buildCommand\n","import url from 'node:url'\n\nimport {type CliCommandContext, type CliPrompter} from '@sanity/cli'\nimport logSymbols from 'log-symbols'\nimport oneline from 'oneline'\n\nconst wildcardReplacement = 'a-wild-card-r3pl4c3m3n7-a'\nconst portReplacement = ':7777777'\n\ninterface AddCorsOriginFlags {\n  credentials?: boolean\n}\n\nexport async function addCorsOrigin(\n  givenOrigin: string,\n  flags: AddCorsOriginFlags,\n  context: CliCommandContext,\n): Promise<boolean> {\n  const {apiClient, prompt, output} = context\n  const origin = await (givenOrigin\n    ? filterAndValidateOrigin(givenOrigin)\n    : promptForOrigin(prompt))\n\n  const hasWildcard = origin.includes('*')\n  if (hasWildcard && !(await promptForWildcardConfirmation(origin, context))) {\n    return false\n  }\n  const allowCredentials =\n    typeof flags.credentials === 'undefined'\n      ? await promptForCredentials(hasWildcard, context)\n      : Boolean(flags.credentials)\n\n  if (givenOrigin !== origin) {\n    output.print(`Normalized origin to ${origin}`)\n  }\n\n  const client = apiClient({\n    requireUser: true,\n    requireProject: true,\n  })\n\n  await client.request({\n    method: 'POST',\n    url: '/cors',\n    body: {origin, allowCredentials},\n    maxRedirects: 0,\n  })\n\n  return true\n}\n\nfunction promptForCredentials(hasWildcard: boolean, context: CliCommandContext): Promise<string> {\n  const {prompt, output, chalk} = context\n\n  output.print('')\n  if (hasWildcard) {\n    output.print(oneline`\n      ${chalk.yellow(`${logSymbols.warning} Warning:`)}\n      We ${chalk.red(chalk.underline('HIGHLY'))} recommend NOT allowing credentials\n      on origins containing wildcards. If you are logged in to a studio, people will\n      be able to send requests ${chalk.underline('on your behalf')} to read and modify\n      data, from any matching origin. Please tread carefully!\n    `)\n  } else {\n    output.print(oneline`\n      ${chalk.yellow(`${logSymbols.warning} Warning:`)}\n      Should this origin be allowed to send requests using authentication tokens or\n      session cookies? Be aware that any script on this origin will be able to send\n      requests ${chalk.underline('on your behalf')} to read and modify data if you\n      are logged in to a Sanity studio. If this origin hosts a studio, you will need\n      this, otherwise you should probably answer \"No\" (n).\n    `)\n  }\n\n  output.print('')\n\n  return prompt.single({\n    type: 'confirm',\n    message: oneline`\n      Allow credentials to be sent from this origin? Please read the warning above.\n    `,\n    default: false,\n  })\n}\n\nfunction promptForWildcardConfirmation(\n  origin: string,\n  context: CliCommandContext,\n): Promise<boolean> {\n  const {prompt, output, chalk} = context\n\n  output.print('')\n  output.print(chalk.yellow(`${logSymbols.warning} Warning: Examples of allowed origins:`))\n\n  if (origin === '*') {\n    output.print('- http://www.some-malicious.site')\n    output.print('- https://not.what-you-were-expecting.com')\n    output.print('- https://high-traffic-site.com')\n    output.print('- http://192.168.1.1:8080')\n  } else {\n    output.print(`- ${origin.replace(/:\\*/, ':1234').replace(/\\*/g, 'foo')}`)\n    output.print(`- ${origin.replace(/:\\*/, ':3030').replace(/\\*/g, 'foo.bar')}`)\n  }\n\n  output.print('')\n\n  return prompt.single({\n    type: 'confirm',\n    message: oneline`\n      Using wildcards can be ${chalk.red('risky')}.\n      Are you ${chalk.underline('absolutely sure')} you want to allow this origin?`,\n    default: false,\n  })\n}\n\nfunction promptForOrigin(prompt: CliPrompter): Promise<string> {\n  return prompt.single({\n    type: 'input',\n    message: 'Origin (including protocol):',\n    filter: filterOrigin,\n    validate: (origin) => validateOrigin(origin, origin),\n  })\n}\n\nfunction filterOrigin(origin: string): string | null {\n  if (origin === '*' || origin === 'file:///*' || origin === 'null') {\n    return origin\n  }\n\n  try {\n    const example = origin\n      .replace(/([^:])\\*/g, `$1${wildcardReplacement}`)\n      .replace(/:\\*/, portReplacement)\n\n    const parsed = url.parse(example)\n    let host = parsed.host || ''\n    if (/^https?:$/.test(parsed.protocol || '')) {\n      host = host.replace(/:(80|443)$/, '')\n    }\n\n    host = host.replace(portReplacement, ':*').replace(new RegExp(wildcardReplacement, 'g'), '*')\n\n    return `${parsed.protocol}//${host}`\n  } catch (err) {\n    return null\n  }\n}\n\nfunction validateOrigin(origin: string | null, givenOrigin: string): true | string {\n  if (origin === '*' || origin === 'file:///*' || origin === 'null') {\n    return true\n  }\n\n  try {\n    url.parse(origin || (0 as any as string)) // Use 0 to trigger error for unset values\n    return true\n  } catch (err) {\n    // Fall-through to error\n  }\n\n  if (/^file:\\/\\//.test(givenOrigin)) {\n    return `Only a local file wildcard is currently allowed: file:///*`\n  }\n\n  return `Invalid origin \"${givenOrigin}\", must include protocol (https://some.host)`\n}\n\nfunction filterAndValidateOrigin(givenOrigin: string): string {\n  const origin = filterOrigin(givenOrigin)\n  const result = validateOrigin(origin, givenOrigin)\n  if (result !== true) {\n    throw new Error(result)\n  }\n\n  if (!origin) {\n    throw new Error('Invalid origin')\n  }\n\n  return origin\n}\n","import fs from 'node:fs'\nimport path from 'node:path'\n\nimport {type CliCommandDefinition} from '@sanity/cli'\n\nimport {addCorsOrigin} from '../../actions/cors/addCorsOrigin'\n\nconst helpText = `\nOptions\n  --credentials Allow credentials (token/cookie) to be sent from this origin\n  --no-credentials Disallow credentials (token/cookie) to be sent from this origin\n\nExamples\n  sanity cors add\n  sanity cors add http://localhost:3000 --no-credentials\n`\n\nconst addCorsOriginCommand: CliCommandDefinition = {\n  name: 'add',\n  group: 'cors',\n  signature: '[ORIGIN]',\n  helpText,\n  description: 'Allow a new origin to use your project API through CORS',\n  action: async (args, context) => {\n    const {output} = context\n    const [origin] = args.argsWithoutOptions\n\n    if (!origin) {\n      throw new Error('No origin specified, use `sanity cors add <origin-url>`')\n    }\n\n    const flags = args.extOptions\n\n    // eslint-disable-next-line no-sync\n    const isFile = fs.existsSync(path.join(process.cwd(), origin))\n    if (isFile) {\n      output.warn(`Origin \"${origin}?\" Remember to quote values (sanity cors add \"*\")`)\n    }\n\n    const success = await addCorsOrigin(origin, flags, context)\n    if (success) {\n      output.print('CORS origin added successfully')\n    }\n  },\n}\n\nexport default addCorsOriginCommand\n","import {type CliCommandGroupDefinition} from '@sanity/cli'\n\nconst corsGroup: CliCommandGroupDefinition = {\n  name: 'cors',\n  signature: '[COMMAND]',\n  isGroupRoot: true,\n  description: 'Configures CORS settings for Sanity projects',\n}\n\nexport default corsGroup\n","import {type CliCommandContext, type CliCommandDefinition} from '@sanity/cli'\n\nimport {type CorsOrigin} from './types'\n\nconst helpText = `\nExamples\n  sanity cors delete\n  sanity cors delete http://localhost:3000\n`\n\nconst deleteCorsOriginCommand: CliCommandDefinition = {\n  name: 'delete',\n  group: 'cors',\n  signature: '[ORIGIN]',\n  helpText,\n  description: 'Delete an existing CORS-origin from your project',\n  action: async (args, context) => {\n    const {output, apiClient} = context\n    const [origin] = args.argsWithoutOptions\n    const client = apiClient({requireUser: true, requireProject: true})\n    const originId = await promptForOrigin(origin, context)\n    try {\n      await client.request({method: 'DELETE', uri: `/cors/${originId}`})\n      output.print('Origin deleted')\n    } catch (err) {\n      throw new Error(`Origin deletion failed:\\n${err.message}`)\n    }\n  },\n}\n\nexport default deleteCorsOriginCommand\n\nasync function promptForOrigin(specified: string | undefined, context: CliCommandContext) {\n  const specifiedOrigin = specified && specified.toLowerCase()\n  const {prompt, apiClient} = context\n  const client = apiClient({requireUser: true, requireProject: true})\n\n  const origins = await client.request<CorsOrigin[]>({url: '/cors'})\n  if (specifiedOrigin) {\n    const selected = origins.filter((origin) => origin.origin.toLowerCase() === specifiedOrigin)[0]\n    if (!selected) {\n      throw new Error(`Origin \"${specified} not found\"`)\n    }\n\n    return selected.id\n  }\n\n  const choices = origins.map((origin) => ({value: origin.id, name: origin.origin}))\n  return prompt.single({\n    message: 'Select origin to delete',\n    type: 'list',\n    choices,\n  })\n}\n","import {type CliCommandDefinition} from '@sanity/cli'\n\nimport {type CorsOrigin} from './types'\n\nconst helpText = `\nExamples\n  sanity cors list\n`\n\nconst listCorsOriginsCommand: CliCommandDefinition = {\n  name: 'list',\n  group: 'cors',\n  signature: '',\n  helpText,\n  description: 'List all origins allowed to access the API for this project',\n  action: async (args, context) => {\n    const {output} = context\n    const {apiClient} = context\n    const client = apiClient({requireUser: true, requireProject: true})\n    const origins = await client.request<CorsOrigin[]>({url: '/cors'})\n    output.print(origins.map((origin) => origin.origin).join('\\n'))\n  },\n}\n\nexport default listCorsOriginsCommand\n","const MAX_DATASET_NAME_LENGTH = 64\n\nexport function validateDatasetAliasName(datasetName: string): false | string {\n  if (!datasetName) {\n    return 'Alias name is missing'\n  }\n\n  const name = `${datasetName}`\n\n  if (name.toLowerCase() !== name) {\n    return 'Alias name must be all lowercase characters'\n  }\n\n  if (name.length < 2) {\n    return 'Alias name must be at least two characters long'\n  }\n\n  if (name.length > MAX_DATASET_NAME_LENGTH) {\n    return `Alias name must be at most ${MAX_DATASET_NAME_LENGTH} characters`\n  }\n\n  if (!/^[a-z0-9~]/.test(name)) {\n    return 'Alias name must start with a letter or a number'\n  }\n\n  if (!/^[a-z0-9~][-_a-z0-9]+$/.test(name)) {\n    return 'Alias name must only contain letters, numbers, dashes and underscores'\n  }\n\n  if (/[-_]$/.test(name)) {\n    return 'Alias name must not end with a dash or an underscore'\n  }\n\n  return false\n}\n","import {type CliPrompter} from '@sanity/cli'\n\nimport {validateDatasetAliasName} from './validateDatasetAliasName'\n\nexport function promptForDatasetAliasName(\n  prompt: CliPrompter,\n  options: {message?: string; default?: string} = {},\n): Promise<string> {\n  return prompt.single({\n    type: 'input',\n    message: 'Alias name:',\n    validate: (name) => {\n      const err = validateDatasetAliasName(name)\n      if (err) {\n        return err\n      }\n\n      return true\n    },\n    ...options,\n  })\n}\n","import {type SanityClient} from '@sanity/client'\n\nimport {validateDatasetAliasName} from '../../../actions/dataset/alias/validateDatasetAliasName'\nimport {type DatasetAliasDefinition, type DatasetModificationResponse} from './types'\n\nexport const ALIAS_PREFIX = '~'\n\nexport function listAliases(client: SanityClient): Promise<DatasetAliasDefinition[]> {\n  return client.request<DatasetAliasDefinition[]>({uri: '/aliases'})\n}\n\nexport function createAlias(\n  client: SanityClient,\n  aliasName: string,\n  datasetName: string | null,\n): Promise<DatasetModificationResponse> {\n  return modify(client, 'PUT', aliasName, datasetName ? {datasetName} : undefined)\n}\n\nexport function updateAlias(\n  client: SanityClient,\n  aliasName: string,\n  datasetName: string | null,\n): Promise<DatasetModificationResponse> {\n  return modify(client, 'PATCH', aliasName, datasetName ? {datasetName} : undefined)\n}\n\nexport function unlinkAlias(\n  client: SanityClient,\n  aliasName: string,\n): Promise<DatasetModificationResponse> {\n  validateDatasetAliasName(aliasName)\n  return modify(client, 'PATCH', `${aliasName}/unlink`, {})\n}\n\nexport function removeAlias(client: SanityClient, aliasName: string): Promise<{deleted: boolean}> {\n  return modify(client, 'DELETE', aliasName)\n}\n\nfunction modify(\n  client: SanityClient,\n  method: string,\n  aliasName: string,\n  body?: {datasetName?: string},\n) {\n  return client.request({method, uri: `/aliases/${aliasName}`, body})\n}\n","import {type CliCommandAction} from '@sanity/cli'\n\nimport {promptForDatasetAliasName} from '../../../actions/dataset/alias/promptForDatasetAliasName'\nimport {validateDatasetAliasName} from '../../../actions/dataset/alias/validateDatasetAliasName'\nimport {promptForDatasetName} from '../../../actions/dataset/datasetNamePrompt'\nimport {validateDatasetName} from '../../../actions/dataset/validateDatasetName'\nimport * as aliasClient from './datasetAliasesClient'\nimport {ALIAS_PREFIX} from './datasetAliasesClient'\n\nexport const createAliasHandler: CliCommandAction = async (args, context) => {\n  const {apiClient, output, prompt} = context\n  const [, alias, targetDataset] = args.argsWithoutOptions\n  const client = apiClient()\n\n  const nameError = alias && validateDatasetAliasName(alias)\n  if (nameError) {\n    throw new Error(nameError)\n  }\n\n  const [datasets, aliases, projectFeatures] = await Promise.all([\n    client.datasets.list().then((sets) => sets.map((ds) => ds.name)),\n    aliasClient.listAliases(client).then((sets) => sets.map((ds) => ds.name)),\n    client.request({uri: '/features'}),\n  ])\n\n  let aliasName = await (alias || promptForDatasetAliasName(prompt))\n  let aliasOutputName = aliasName\n\n  if (aliasName.startsWith(ALIAS_PREFIX)) {\n    aliasName = aliasName.slice(1)\n  } else {\n    aliasOutputName = `${ALIAS_PREFIX}${aliasName}`\n  }\n\n  if (aliases.includes(aliasName)) {\n    throw new Error(`Dataset alias \"${aliasOutputName}\" already exists`)\n  }\n\n  if (targetDataset) {\n    const datasetErr = validateDatasetName(targetDataset)\n    if (datasetErr) {\n      throw new Error(datasetErr)\n    }\n  }\n\n  const datasetName = await (targetDataset || promptForDatasetName(prompt))\n  if (datasetName && !datasets.includes(datasetName)) {\n    throw new Error(`Dataset \"${datasetName}\" does not exist `)\n  }\n\n  const canCreateAlias = projectFeatures.includes('advancedDatasetManagement')\n  if (!canCreateAlias) {\n    throw new Error(`This project cannot create a dataset alias`)\n  }\n\n  try {\n    await aliasClient.createAlias(client, aliasName, datasetName)\n    output.print(\n      `Dataset alias ${aliasOutputName} created ${\n        datasetName && `and linked to ${datasetName}`\n      } successfully`,\n    )\n  } catch (err) {\n    throw new Error(`Dataset alias creation failed:\\n${err.message}`)\n  }\n}\n","import {type CliCommandAction} from '@sanity/cli'\nimport {hideBin} from 'yargs/helpers'\nimport yargs from 'yargs/yargs'\n\nimport {validateDatasetAliasName} from '../../../actions/dataset/alias/validateDatasetAliasName'\nimport * as aliasClient from './datasetAliasesClient'\nimport {ALIAS_PREFIX} from './datasetAliasesClient'\n\nfunction parseCliFlags(args: {argv?: string[]}) {\n  return yargs(hideBin(args.argv || process.argv).slice(2)).option('force', {type: 'boolean'}).argv\n}\n\ninterface DeleteAliasFlags {\n  force?: boolean\n}\n\nexport const deleteAliasHandler: CliCommandAction<DeleteAliasFlags> = async (args, context) => {\n  const {apiClient, prompt, output} = context\n  const [, ds] = args.argsWithoutOptions\n  const {force} = await parseCliFlags(args)\n  const client = apiClient()\n  if (!ds) {\n    throw new Error('Dataset alias name must be provided')\n  }\n\n  let aliasName = `${ds}`\n  const dsError = validateDatasetAliasName(aliasName)\n  if (dsError) {\n    throw dsError\n  }\n  aliasName = aliasName.startsWith(ALIAS_PREFIX) ? aliasName.slice(1) : aliasName\n\n  const [fetchedAliases] = await Promise.all([aliasClient.listAliases(client)])\n  const linkedAlias = fetchedAliases.find((elem) => elem.name === aliasName)\n  const message =\n    linkedAlias && linkedAlias.datasetName\n      ? `This dataset alias is linked to ${linkedAlias.datasetName}. `\n      : ''\n\n  if (force) {\n    output.warn(`'--force' used: skipping confirmation, deleting alias \"${aliasName}\"`)\n  } else {\n    await prompt.single({\n      type: 'input',\n      message: `${message}Are you ABSOLUTELY sure you want to delete this dataset alias?\\n  Type the name of the dataset alias to confirm delete: `,\n      filter: (input) => `${input}`.trim(),\n      validate: (input) => {\n        return input === aliasName || 'Incorrect dataset alias name. Ctrl + C to cancel delete.'\n      },\n    })\n  }\n\n  return aliasClient.removeAlias(client, aliasName).then(() => {\n    output.print('Dataset alias deleted successfully')\n  })\n}\n","import {type CliCommandAction} from '@sanity/cli'\n\nimport {promptForDatasetAliasName} from '../../../actions/dataset/alias/promptForDatasetAliasName'\nimport {validateDatasetAliasName} from '../../../actions/dataset/alias/validateDatasetAliasName'\nimport {promptForDatasetName} from '../../../actions/dataset/datasetNamePrompt'\nimport {validateDatasetName} from '../../../actions/dataset/validateDatasetName'\nimport * as aliasClient from './datasetAliasesClient'\nimport {ALIAS_PREFIX} from './datasetAliasesClient'\n\nexport const linkAliasHandler: CliCommandAction = async (args, context) => {\n  const {apiClient, output, prompt} = context\n  const [, alias, targetDataset] = args.argsWithoutOptions\n  const flags = args.extOptions\n  const client = apiClient()\n\n  const nameError = alias && validateDatasetAliasName(alias)\n  if (nameError) {\n    throw new Error(nameError)\n  }\n\n  const [datasets, fetchedAliases] = await Promise.all([\n    client.datasets.list().then((sets) => sets.map((ds) => ds.name)),\n    aliasClient.listAliases(client),\n  ])\n  const aliases = fetchedAliases.map((da) => da.name)\n\n  let aliasName = await (alias || promptForDatasetAliasName(prompt))\n  let aliasOutputName = aliasName\n\n  if (aliasName.startsWith(ALIAS_PREFIX)) {\n    aliasName = aliasName.slice(1)\n  } else {\n    aliasOutputName = `${ALIAS_PREFIX}${aliasName}`\n  }\n\n  if (!aliases.includes(aliasName)) {\n    throw new Error(`Dataset alias \"${aliasOutputName}\" does not exist `)\n  }\n\n  const datasetName = await (targetDataset || promptForDatasetName(prompt))\n  const datasetErr = validateDatasetName(datasetName)\n  if (datasetErr) {\n    throw new Error(datasetErr)\n  }\n\n  if (!datasets.includes(datasetName)) {\n    throw new Error(`Dataset \"${datasetName}\" does not exist `)\n  }\n\n  const linkedAlias = fetchedAliases.find((elem) => elem.name === aliasName)\n\n  if (linkedAlias && linkedAlias.datasetName) {\n    if (linkedAlias.datasetName === datasetName) {\n      throw new Error(`Dataset alias ${aliasOutputName} already linked to ${datasetName}`)\n    }\n\n    if (!flags.force) {\n      await prompt.single({\n        type: 'input',\n        message: `This alias is linked to dataset <${linkedAlias.datasetName}>. Are you ABSOLUTELY sure you want to link this dataset alias to this dataset?\n        \\n  Type YES/NO: `,\n        filter: (input) => `${input}`.toLowerCase(),\n        validate: (input) => {\n          return input === 'yes' || 'Ctrl + C to cancel dataset alias link.'\n        },\n      })\n    }\n  }\n\n  try {\n    await aliasClient.updateAlias(client, aliasName, datasetName)\n    output.print(`Dataset alias ${aliasOutputName} linked to ${datasetName} successfully`)\n  } catch (err) {\n    throw new Error(`Dataset alias link failed:\\n${err.message}`)\n  }\n}\n","import {type CliCommandAction} from '@sanity/cli'\nimport {hideBin} from 'yargs/helpers'\nimport yargs from 'yargs/yargs'\n\nimport {promptForDatasetAliasName} from '../../../actions/dataset/alias/promptForDatasetAliasName'\nimport {validateDatasetAliasName} from '../../../actions/dataset/alias/validateDatasetAliasName'\nimport * as aliasClient from './datasetAliasesClient'\nimport {ALIAS_PREFIX} from './datasetAliasesClient'\n\ninterface UnlinkFlags {\n  force?: boolean\n}\n\nfunction parseCliFlags(args: {argv?: string[]}) {\n  return yargs(hideBin(args.argv || process.argv).slice(2)).option('force', {type: 'boolean'}).argv\n}\n\nexport const unlinkAliasHandler: CliCommandAction<UnlinkFlags> = async (args, context) => {\n  const {apiClient, output, prompt} = context\n  const [, alias] = args.argsWithoutOptions\n  const {force} = await parseCliFlags(args)\n  const client = apiClient()\n\n  const nameError = alias && validateDatasetAliasName(alias)\n  if (nameError) {\n    throw new Error(nameError)\n  }\n\n  const fetchedAliases = await aliasClient.listAliases(client)\n\n  let aliasName = await (alias || promptForDatasetAliasName(prompt))\n  let aliasOutputName = aliasName\n\n  if (aliasName.startsWith(ALIAS_PREFIX)) {\n    aliasName = aliasName.slice(1)\n  } else {\n    aliasOutputName = `${ALIAS_PREFIX}${aliasName}`\n  }\n\n  // get the current alias from the remote alias list\n  const linkedAlias = fetchedAliases.find((elem) => elem.name === aliasName)\n  if (!linkedAlias) {\n    throw new Error(`Dataset alias \"${aliasOutputName}\" does not exist`)\n  }\n\n  if (!linkedAlias.datasetName) {\n    throw new Error(`Dataset alias \"${aliasOutputName}\" is not linked to a dataset`)\n  }\n\n  if (force) {\n    output.warn(`'--force' used: skipping confirmation, unlinking alias \"${aliasOutputName}\"`)\n  } else {\n    await prompt.single({\n      type: 'input',\n      message: `Are you ABSOLUTELY sure you want to unlink this alias from the \"${linkedAlias.datasetName}\" dataset?\n        \\n  Type YES/NO: `,\n      filter: (input) => `${input}`.toLowerCase(),\n      validate: (input) => {\n        return input === 'yes' || 'Ctrl + C to cancel dataset alias unlink.'\n      },\n    })\n  }\n\n  try {\n    const result = await aliasClient.unlinkAlias(client, aliasName)\n    output.print(\n      `Dataset alias ${aliasOutputName} unlinked from ${result.datasetName} successfully`,\n    )\n  } catch (err) {\n    throw new Error(`Dataset alias unlink failed:\\n${err.message}`)\n  }\n}\n","import {type CliCommandDefinition} from '@sanity/cli'\nimport oneline from 'oneline'\n\nimport {createAliasHandler} from './createAliasHandler'\nimport {deleteAliasHandler} from './deleteAliasHandler'\nimport {linkAliasHandler} from './linkAliasHandler'\nimport {unlinkAliasHandler} from './unlinkAliasHandler'\n\nconst helpText = `\nBelow are examples of the alias subcommand\n\nCreate Alias\n  sanity dataset alias create\n  sanity dataset alias create <alias-name>\n  sanity dataset alias create <alias-name> <target-dataset>\n\nDelete Alias\n  Options\n    --force Skips security prompt and forces link command\n\n  Usage\n    sanity dataset alias delete <alias-name>\n    sanity dataset alias delete <alias-name> --force\n\nLink Alias\n  Options\n    --force Skips security prompt and forces link command\n\n  Usage\n    sanity dataset alias link\n    sanity dataset alias link <alias-name>\n    sanity dataset alias link <alias-name> <target-dataset>\n    sanity dataset alias link <alias-name> <target-dataset> --force\n\nUn-link Alias\n  Options\n    --force Skips security prompt and forces link command\n\n  Usage\n    sanity dataset alias unlink\n    sanity dataset alias unlink <alias-name>\n    sanity dataset alias unlink <alias-name> --force\n`\n\nconst aliasCommand: CliCommandDefinition = {\n  name: 'alias',\n  group: 'dataset',\n  signature: 'SUBCOMMAND [ALIAS_NAME, TARGET_DATASET]',\n  helpText,\n  description: 'You can manage your dataset alias using this command.',\n  action: async (args, context) => {\n    const [verb] = args.argsWithoutOptions\n    switch (verb) {\n      case 'create':\n        await createAliasHandler(args, context)\n        break\n      case 'delete':\n        await deleteAliasHandler(args, context)\n        break\n      case 'unlink':\n        await unlinkAliasHandler(args, context)\n        break\n      case 'link':\n        await linkAliasHandler(args, context)\n        break\n      default:\n        throw new Error(oneline`\n          Invalid command provided. Available commands are: create, delete, link and unlink.\n          For more guide run the help command 'sanity dataset alias --help'\n        `)\n    }\n  },\n}\n\nexport default aliasCommand\n","import {type CliCommandContext} from '@sanity/cli'\nimport {Table} from 'console-table-printer'\nimport {formatDistance, formatDistanceToNow, parseISO} from 'date-fns'\n\ninterface ListFlags {\n  offset?: number\n  limit?: number\n}\n\ntype CopyDatasetListResponse = {\n  id: string\n  state: string\n  createdAt: string\n  updatedAt: string\n  sourceDataset: string\n  targetDataset: string\n  withHistory: boolean\n}[]\n\nexport async function listDatasetCopyJobs(\n  flags: ListFlags,\n  context: CliCommandContext,\n): Promise<void> {\n  const {apiClient, output, chalk} = context\n  const client = apiClient()\n  const projectId = client.config().projectId\n  const query: {offset?: string; limit?: string} = {}\n  let response\n\n  if (flags.offset && flags.offset >= 0) {\n    query.offset = `${flags.offset}`\n  }\n  if (flags.limit && flags.limit > 0) {\n    query.limit = `${flags.limit}`\n  }\n\n  try {\n    response = await client.request<CopyDatasetListResponse>({\n      method: 'GET',\n      uri: `/projects/${projectId}/datasets/copy`,\n      query,\n    })\n  } catch (error) {\n    if (error.statusCode) {\n      output.error(`${chalk.red(`Dataset copy list failed:\\n${error.response.body.message}`)}\\n`)\n    } else {\n      output.error(`${chalk.red(`Dataset copy list failed:\\n${error.message}`)}\\n`)\n    }\n  }\n\n  if (response && response.length > 0) {\n    const table = new Table({\n      title: 'Dataset copy jobs for this project in descending order',\n      columns: [\n        {name: 'id', title: 'Job ID', alignment: 'left'},\n        {name: 'sourceDataset', title: 'Source Dataset', alignment: 'left'},\n        {name: 'targetDataset', title: 'Target Dataset', alignment: 'left'},\n        {name: 'state', title: 'State', alignment: 'left'},\n        {name: 'withHistory', title: 'With history', alignment: 'left'},\n        {name: 'timeStarted', title: 'Time started', alignment: 'left'},\n        {name: 'timeTaken', title: 'Time taken', alignment: 'left'},\n      ],\n    })\n\n    response.forEach((job) => {\n      const {id, state, createdAt, updatedAt, sourceDataset, targetDataset, withHistory} = job\n\n      let timeStarted = ''\n      if (createdAt !== '') {\n        timeStarted = formatDistanceToNow(parseISO(createdAt))\n      }\n\n      let timeTaken = ''\n      if (updatedAt !== '') {\n        timeTaken = formatDistance(parseISO(updatedAt), parseISO(createdAt))\n      }\n\n      let color\n      switch (state) {\n        case 'completed':\n          color = 'green'\n          break\n        case 'failed':\n          color = 'red'\n          break\n        case 'pending':\n          color = 'yellow'\n          break\n        default:\n          color = ''\n      }\n\n      table.addRow(\n        {\n          id,\n          state,\n          withHistory,\n          timeStarted: `${timeStarted} ago`,\n          timeTaken,\n          sourceDataset,\n          targetDataset,\n        },\n        {color},\n      )\n    })\n\n    table.printTable()\n  } else {\n    output.print(\"This project doesn't have any dataset copy jobs\")\n  }\n}\n","import {type SanityClient} from '@sanity/client'\n\nexport const getClientUrl = (client: SanityClient, uri: string, useCdn = false): string => {\n  const config = client.config()\n  const base = useCdn ? config.cdnUrl : config.url\n  return `${base}/${uri.replace(/^\\//, '')}`\n}\n","import {type CliCommandDefinition, type CliOutputter} from '@sanity/cli'\nimport {type SanityClient} from '@sanity/client'\nimport EventSource from '@sanity/eventsource'\nimport {Observable} from 'rxjs'\nimport {hideBin} from 'yargs/helpers'\nimport yargs from 'yargs/yargs'\n\nimport {promptForDatasetName} from '../../actions/dataset/datasetNamePrompt'\nimport {listDatasetCopyJobs} from '../../actions/dataset/listDatasetCopyJobs'\nimport {validateDatasetName} from '../../actions/dataset/validateDatasetName'\nimport {debug} from '../../debug'\nimport {getClientUrl} from '../../util/getClientUrl'\n\nconst helpText = `\nOptions\n  --detach Start the copy without waiting for it to finish\n  --attach <job-id> Attach to the running copy process to show progress\n  --skip-history Don't preserve document history on copy\n  --list Lists all dataset copy jobs corresponding to a certain criteria.\n  --offset Start position in the list of jobs. Default 0. With --list.\n  --limit Maximum number of jobs returned. Default 10. Maximum 1000. With --list.\n\nExamples\n  sanity dataset copy\n  sanity dataset copy <source-dataset>\n  sanity dataset copy <source-dataset> <target-dataset>\n  sanity dataset copy --skip-history <source-dataset> <target-dataset>\n  sanity dataset copy --detach <source-dataset> <target-dataset>\n  sanity dataset copy --attach <job-id>\n  sanity dataset copy --list\n  sanity dataset copy --list --offset=2\n  sanity dataset copy --list --offset=2 --limit=10\n`\n\ninterface CopyProgressStreamEvent {\n  type: 'reconnect' | string\n  progress?: number\n}\n\ninterface CopyDatasetFlags {\n  'list'?: boolean\n  'attach'?: string\n  'detach'?: boolean\n  'offset'?: number\n  'limit'?: number\n  'skip-history'?: boolean\n}\n\ninterface CopyDatasetResponse {\n  jobId: string\n}\n\nfunction parseCliFlags(args: {argv?: string[]}) {\n  return yargs(hideBin(args.argv || process.argv).slice(2))\n    .option('attach', {type: 'string'})\n    .option('list', {type: 'boolean'})\n    .option('limit', {type: 'number'})\n    .option('offset', {type: 'number'})\n    .option('skip-history', {type: 'boolean'})\n    .option('detach', {type: 'boolean'}).argv\n}\n\nconst progress = (url: string) => {\n  return new Observable<CopyProgressStreamEvent>((observer) => {\n    let progressSource = new EventSource(url)\n    let stopped = false\n\n    function onError(error: unknown) {\n      if (progressSource) {\n        progressSource.close()\n      }\n\n      debug(`Error received: ${error}`)\n      if (stopped) {\n        return\n      }\n      observer.next({type: 'reconnect'})\n      progressSource = new EventSource(url)\n    }\n\n    function onChannelError(error: MessageEvent) {\n      stopped = true\n      progressSource.close()\n      observer.error(error)\n    }\n\n    function onMessage(event: MessageEvent) {\n      const data = JSON.parse(event.data)\n      if (data.state === 'failed') {\n        debug('Job failed. Data: %o', event)\n        observer.error(event)\n      } else if (data.state === 'completed') {\n        debug('Job succeeded. Data: %o', event)\n        onComplete()\n      } else {\n        debug(`Job progressed. Data: %o`, event)\n        observer.next(data)\n      }\n    }\n\n    function onComplete() {\n      progressSource.removeEventListener('error', onError)\n      progressSource.removeEventListener('channel_error', onChannelError)\n      progressSource.removeEventListener('job', onMessage)\n      progressSource.removeEventListener('done', onComplete)\n      progressSource.close()\n      observer.complete()\n    }\n\n    progressSource.addEventListener('error', onError)\n    progressSource.addEventListener('channel_error', onChannelError)\n    progressSource.addEventListener('job', onMessage)\n    progressSource.addEventListener('done', onComplete)\n  })\n}\n\nconst followProgress = (\n  jobId: string,\n  client: SanityClient,\n  output: CliOutputter,\n): Promise<void> => {\n  let currentProgress = 0\n\n  const spinner = output.spinner({}).start()\n  const listenUrl = getClientUrl(client, `jobs/${jobId}/listen`)\n\n  debug(`Listening to ${listenUrl}`)\n\n  return new Promise((resolve, reject) => {\n    progress(listenUrl).subscribe({\n      next: (event) => {\n        if (typeof event.progress === 'number') {\n          currentProgress = event.progress\n        }\n\n        spinner.text = `Copy in progress: ${currentProgress}%`\n      },\n      error: (err) => {\n        spinner.fail()\n        reject(new Error(`${err.data}`))\n      },\n      complete: () => {\n        spinner.succeed('Copy finished.')\n        resolve()\n      },\n    })\n  })\n}\n\nconst copyDatasetCommand: CliCommandDefinition<CopyDatasetFlags> = {\n  name: 'copy',\n  group: 'dataset',\n  signature: '[SOURCE_DATASET] [TARGET_DATASET]',\n  helpText,\n  description:\n    'Manages dataset copying, including starting a new copy job, listing copy jobs and following the progress of a running copy job',\n  action: async (args, context) => {\n    const {apiClient, output, prompt, chalk} = context\n    // Reparsing CLI flags for better control of binary flags\n    const flags: CopyDatasetFlags = await parseCliFlags(args)\n    const client = apiClient()\n\n    if (flags.list) {\n      await listDatasetCopyJobs(flags, context)\n      return\n    }\n\n    if (flags.attach) {\n      const jobId = flags.attach\n\n      if (!jobId) {\n        throw new Error('Please supply a jobId')\n      }\n\n      await followProgress(jobId, client, output)\n      return\n    }\n\n    const [sourceDataset, targetDataset] = args.argsWithoutOptions\n    const shouldSkipHistory = Boolean(flags['skip-history'])\n\n    const nameError = sourceDataset && validateDatasetName(sourceDataset)\n    if (nameError) {\n      throw new Error(nameError)\n    }\n\n    const existingDatasets = await client.datasets\n      .list()\n      .then((datasets) => datasets.map((ds) => ds.name))\n\n    const sourceDatasetName = await (sourceDataset ||\n      promptForDatasetName(prompt, {message: 'Source dataset name:'}))\n    if (!existingDatasets.includes(sourceDatasetName)) {\n      throw new Error(`Source dataset \"${sourceDatasetName}\" doesn't exist`)\n    }\n\n    const targetDatasetName = await (targetDataset ||\n      promptForDatasetName(prompt, {message: 'Target dataset name:'}))\n    if (existingDatasets.includes(targetDatasetName)) {\n      throw new Error(`Target dataset \"${targetDatasetName}\" already exists`)\n    }\n\n    const err = validateDatasetName(targetDatasetName)\n    if (err) {\n      throw new Error(err)\n    }\n\n    try {\n      const response = await client.request<CopyDatasetResponse>({\n        method: 'PUT',\n        uri: `/datasets/${sourceDatasetName}/copy`,\n        body: {\n          targetDataset: targetDatasetName,\n          skipHistory: shouldSkipHistory,\n        },\n      })\n\n      output.print(\n        `Copying dataset ${chalk.green(sourceDatasetName)} to ${chalk.green(targetDatasetName)}...`,\n      )\n\n      if (!shouldSkipHistory) {\n        output.print(\n          `Note: You can run this command with flag '--skip-history'. The flag will reduce copy time in larger datasets.`,\n        )\n      }\n\n      output.print(`Job ${chalk.green(response.jobId)} started`)\n\n      if (flags.detach) {\n        return\n      }\n\n      await followProgress(response.jobId, client, output)\n      output.print(`Job ${chalk.green(response.jobId)} completed`)\n    } catch (error) {\n      if (error.statusCode) {\n        output.print(`${chalk.red(`Dataset copying failed:\\n${error.response.body.message}`)}\\n`)\n      } else {\n        output.print(`${chalk.red(`Dataset copying failed:\\n${error.message}`)}\\n`)\n      }\n    }\n  },\n}\n\nexport default copyDatasetCommand\n","import {type CliCommandDefinition, type CliOutputter, type CliPrompter} from '@sanity/cli'\n\nimport {promptForDatasetName} from '../../actions/dataset/datasetNamePrompt'\nimport {validateDatasetName} from '../../actions/dataset/validateDatasetName'\nimport {debug} from '../../debug'\n\nconst helpText = `\nOptions\n  --visibility <mode> Set visibility for this dataset (public/private)\n\nExamples\n  sanity dataset create\n  sanity dataset create <name>\n  sanity dataset create <name> --visibility private\n`\n\nconst allowedModes = ['private', 'public', 'custom']\n\ninterface CreateFlags {\n  visibility?: 'private' | 'public' | 'custom'\n}\n\nconst createDatasetCommand: CliCommandDefinition<CreateFlags> = {\n  name: 'create',\n  group: 'dataset',\n  signature: '[NAME]',\n  helpText,\n  description: 'Create a new dataset within your project',\n  action: async (args, context) => {\n    const {apiClient, output, prompt} = context\n    const flags = args.extOptions\n    const [dataset] = args.argsWithoutOptions\n    const client = apiClient()\n\n    const nameError = dataset && validateDatasetName(dataset)\n    if (nameError) {\n      throw new Error(nameError)\n    }\n\n    const [datasets, projectFeatures] = await Promise.all([\n      client.datasets.list().then((sets) => sets.map((ds) => ds.name)),\n      client.request({uri: '/features'}),\n    ])\n\n    if (flags.visibility && !allowedModes.includes(flags.visibility)) {\n      throw new Error(`Visibility mode \"${flags.visibility}\" not allowed`)\n    }\n\n    const datasetName = await (dataset || promptForDatasetName(prompt))\n    if (datasets.includes(datasetName)) {\n      throw new Error(`Dataset \"${datasetName}\" already exists`)\n    }\n\n    const canCreatePrivate = projectFeatures.includes('privateDataset')\n    debug('%s create private datasets', canCreatePrivate ? 'Can' : 'Cannot')\n\n    const defaultAclMode = canCreatePrivate ? flags.visibility : 'public'\n    const aclMode = await (defaultAclMode || promptForDatasetVisibility(prompt, output))\n\n    try {\n      await client.datasets.create(datasetName, {aclMode})\n      output.print('Dataset created successfully')\n    } catch (err) {\n      throw new Error(`Dataset creation failed:\\n${err.message}`)\n    }\n  },\n}\n\nasync function promptForDatasetVisibility(prompt: CliPrompter, output: CliOutputter) {\n  const mode = await prompt.single<'public' | 'private'>({\n    type: 'list',\n    message: 'Dataset visibility',\n    choices: [\n      {\n        value: 'public',\n        name: 'Public (world readable)',\n      },\n      {\n        value: 'private',\n        name: 'Private (Authenticated user or token needed)',\n      },\n    ],\n  })\n\n  if (mode === 'private') {\n    output.print(\n      'Please note that while documents are private, assets (files and images) are still public\\n',\n    )\n  }\n\n  return mode\n}\n\nexport default createDatasetCommand\n","export default {\n  name: 'dataset',\n  signature: '[COMMAND]',\n  isGroupRoot: true,\n  description: 'Manages datasets, like create or delete, within projects',\n}\n","import {type CliCommandDefinition} from '@sanity/cli'\n\nimport {validateDatasetName} from '../../actions/dataset/validateDatasetName'\n\nconst datasetVisibilityCommand: CliCommandDefinition = {\n  name: 'visibility',\n  group: 'dataset',\n  helpText: '',\n  signature: 'get/set [dataset] [mode]',\n  description: 'Set visibility of a dataset',\n  action: async (args, context) => {\n    const {apiClient, output} = context\n    const [action, ds, aclMode] = args.argsWithoutOptions\n    const client = apiClient()\n\n    if (!client.datasets.edit) {\n      throw new Error('@sanity/cli must be upgraded first:\\n  npm install -g @sanity/cli')\n    }\n\n    if (!action) {\n      throw new Error('Action must be provided (get/set)')\n    }\n\n    if (!['set', 'get'].includes(action)) {\n      throw new Error('Invalid action (only get/set allowed)')\n    }\n\n    if (!ds) {\n      throw new Error('Dataset name must be provided')\n    }\n\n    if (action === 'set' && !aclMode) {\n      throw new Error('Please provide a visibility mode (public/private)')\n    }\n\n    const dataset = `${ds}`\n    const dsError = validateDatasetName(dataset)\n    if (dsError) {\n      throw new Error(dsError)\n    }\n\n    const current = (await client.datasets.list()).find((curr) => curr.name === dataset)\n\n    if (!current) {\n      throw new Error('Dataset not found')\n    }\n\n    if (action === 'get') {\n      output.print(current.aclMode)\n      return\n    }\n\n    if (current.aclMode === aclMode) {\n      output.print(`Dataset already in \"${aclMode}\"-mode`)\n      return\n    }\n\n    if (aclMode === 'private') {\n      output.print(\n        'Please note that while documents are private, assets (files and images) are still public\\n',\n      )\n    }\n\n    await client.datasets.edit(dataset, {aclMode: aclMode as 'public' | 'private'})\n    output.print('Dataset visibility changed')\n  },\n}\n\nexport default datasetVisibilityCommand\n","import {type CliCommandDefinition} from '@sanity/cli'\nimport {hideBin} from 'yargs/helpers'\nimport yargs from 'yargs/yargs'\n\nimport {validateDatasetName} from '../../actions/dataset/validateDatasetName'\n\nconst helpText = `\nOptions\n  --force Do not prompt for delete confirmation - forcefully delete\n\nExamples\n  sanity dataset delete\n  sanity dataset delete my-dataset\n  sanity dataset delete my-dataset --force\n`\n\nfunction parseCliFlags(args: {argv?: string[]}) {\n  return yargs(hideBin(args.argv || process.argv).slice(2)).option('force', {type: 'boolean'}).argv\n}\n\ninterface DeleteDatasetFlags {\n  force?: boolean\n}\n\nconst deleteDatasetCommand: CliCommandDefinition<DeleteDatasetFlags> = {\n  name: 'delete',\n  group: 'dataset',\n  helpText,\n  signature: '[datasetName]',\n  description: 'Delete a dataset within your project',\n  action: async (args, context) => {\n    const {apiClient, prompt, output} = context\n    const {force} = await parseCliFlags(args)\n    const [ds] = args.argsWithoutOptions\n    if (!ds) {\n      throw new Error('Dataset name must be provided')\n    }\n\n    const dataset = `${ds}`\n    const dsError = validateDatasetName(dataset)\n    if (dsError) {\n      throw dsError\n    }\n\n    if (force) {\n      output.warn(`'--force' used: skipping confirmation, deleting dataset \"${dataset}\"`)\n    } else {\n      await prompt.single({\n        type: 'input',\n        message:\n          'Are you ABSOLUTELY sure you want to delete this dataset?\\n  Type the name of the dataset to confirm delete:',\n        filter: (input) => `${input}`.trim(),\n        validate: (input) => {\n          return input === dataset || 'Incorrect dataset name. Ctrl + C to cancel delete.'\n        },\n      })\n    }\n\n    await apiClient().datasets.delete(dataset)\n    output.print('Dataset deleted successfully')\n  },\n}\n\nexport default deleteDatasetCommand\n","import fs from 'node:fs/promises'\nimport path from 'node:path'\n\nimport {type CliCommandDefinition, type CliPrompter} from '@sanity/cli'\nimport exportDataset from '@sanity/export'\nimport {absolutify} from '@sanity/util/fs'\nimport prettyMs from 'pretty-ms'\n\nimport {chooseDatasetPrompt} from '../../actions/dataset/chooseDatasetPrompt'\nimport {validateDatasetName} from '../../actions/dataset/validateDatasetName'\n\nconst noop = () => null\n\nconst helpText = `\nOptions\n  --raw                     Extract only documents, without rewriting asset references\n  --no-assets               Export only non-asset documents and remove references to image assets\n  --no-drafts               Export only published versions of documents\n  --no-compress             Skips compressing tarball entries (still generates a gzip file)\n  --types                   Defines which document types to export\n  --overwrite               Overwrite any file with the same name\n  --asset-concurrency <num> Concurrent number of asset downloads\n  --mode <stream|cursor>    Uses a cursor when exporting, this might be more performant for larger datasets, but might not be as accurate if the dataset is being modified during export. Defaults to stream\n\nExamples\n  sanity dataset export moviedb localPath.tar.gz\n  sanity dataset export moviedb assetless.tar.gz --no-assets\n  sanity dataset export staging staging.tar.gz --raw\n  sanity dataset export staging staging.tar.gz --types products,shops\n`\n\ninterface ExportFlags {\n  'raw'?: boolean\n  'assets'?: boolean\n  'drafts'?: boolean\n  'compress'?: boolean\n  'overwrite'?: boolean\n  'types'?: string\n  'asset-concurrency'?: string\n  'mode'?: string\n}\n\ninterface ParsedExportFlags {\n  raw?: boolean\n  assets?: boolean\n  drafts?: boolean\n  compress?: boolean\n  overwrite?: boolean\n  types?: string[]\n  assetConcurrency?: number\n  mode?: string\n}\n\nfunction parseFlags(rawFlags: ExportFlags): ParsedExportFlags {\n  const flags: ParsedExportFlags = {}\n  if (rawFlags.types) {\n    flags.types = `${rawFlags.types}`.split(',')\n  }\n\n  if (rawFlags['asset-concurrency']) {\n    flags.assetConcurrency = parseInt(rawFlags['asset-concurrency'], 10)\n  }\n\n  if (typeof rawFlags.raw !== 'undefined') {\n    flags.raw = Boolean(rawFlags.raw)\n  }\n\n  if (typeof rawFlags.assets !== 'undefined') {\n    flags.assets = Boolean(rawFlags.assets)\n  }\n\n  if (typeof rawFlags.drafts !== 'undefined') {\n    flags.drafts = Boolean(rawFlags.drafts)\n  }\n\n  if (typeof rawFlags.compress !== 'undefined') {\n    flags.compress = Boolean(rawFlags.compress)\n  }\n\n  if (typeof rawFlags.overwrite !== 'undefined') {\n    flags.overwrite = Boolean(rawFlags.overwrite)\n  }\n\n  if (typeof rawFlags.mode !== 'undefined') {\n    flags.mode = rawFlags.mode\n  }\n\n  return flags\n}\n\ninterface ProgressEvent {\n  step: string\n  update?: boolean\n  current: number\n  total: number\n}\n\nconst exportDatasetCommand: CliCommandDefinition<ExportFlags> = {\n  name: 'export',\n  group: 'dataset',\n  signature: '[NAME] [DESTINATION]',\n  description: 'Export dataset to local filesystem as a gzipped tarball',\n  helpText,\n  action: async (args, context) => {\n    const {apiClient, output, chalk, workDir, prompt} = context\n    const client = apiClient()\n    const [targetDataset, targetDestination] = args.argsWithoutOptions\n    const flags = parseFlags(args.extOptions)\n\n    let dataset = targetDataset ? `${targetDataset}` : null\n    if (!dataset) {\n      dataset = await chooseDatasetPrompt(context, {message: 'Select dataset to export'})\n    }\n\n    const dsError = validateDatasetName(dataset)\n    if (dsError) {\n      throw dsError\n    }\n\n    // Verify existence of dataset before trying to export from it\n    const datasets = await client.datasets.list()\n    if (!datasets.find((set) => set.name === dataset)) {\n      throw new Error(`Dataset with name \"${dataset}\" not found`)\n    }\n\n    // Print information about what projectId and dataset it is being exported from\n    const {projectId} = client.config()\n\n    output.print('╭───────────────────────────────────────────────╮')\n    output.print('│                                               │')\n    output.print('│ Exporting from:                               │')\n    output.print(`│ ${chalk.bold('projectId')}: ${chalk.cyan(projectId).padEnd(44)} │`)\n    output.print(`│ ${chalk.bold('dataset')}: ${chalk.cyan(dataset).padEnd(46)} │`)\n    output.print('│                                               │')\n    output.print('╰───────────────────────────────────────────────╯')\n    output.print('')\n\n    let destinationPath = targetDestination\n    if (!destinationPath) {\n      destinationPath = await prompt.single({\n        type: 'input',\n        message: 'Output path:',\n        default: path.join(workDir, `${dataset}.tar.gz`),\n        filter: absolutify,\n      })\n    }\n\n    const outputPath = await getOutputPath(destinationPath, dataset, prompt, flags)\n    if (!outputPath) {\n      output.print('Cancelled')\n      return\n    }\n\n    // If we are dumping to a file, let the user know where it's at\n    if (outputPath !== '-') {\n      output.print(`Exporting dataset \"${chalk.cyan(dataset)}\" to \"${chalk.cyan(outputPath)}\"`)\n    }\n\n    let currentStep = 'Exporting documents...'\n    let spinner = output.spinner(currentStep).start()\n    const onProgress = (progress: ProgressEvent) => {\n      if (progress.step !== currentStep) {\n        spinner.succeed()\n        spinner = output.spinner(progress.step).start()\n      } else if (progress.step === currentStep && progress.update) {\n        spinner.text = `${progress.step} (${progress.current}/${progress.total})`\n      }\n\n      currentStep = progress.step\n    }\n\n    const start = Date.now()\n    try {\n      await exportDataset({\n        client,\n        dataset,\n        outputPath,\n        onProgress,\n        ...flags,\n      })\n      spinner.succeed()\n    } catch (err) {\n      spinner.fail()\n      throw err\n    }\n\n    output.print(`Export finished (${prettyMs(Date.now() - start)})`)\n  },\n}\n\n// eslint-disable-next-line complexity\nasync function getOutputPath(\n  destination: string,\n  dataset: string,\n  prompt: CliPrompter,\n  flags: ParsedExportFlags,\n) {\n  if (destination === '-') {\n    return '-'\n  }\n\n  const dstPath = path.isAbsolute(destination)\n    ? destination\n    : path.resolve(process.cwd(), destination)\n\n  let dstStats = await fs.stat(dstPath).catch(noop)\n  const looksLikeFile = dstStats ? dstStats.isFile() : path.basename(dstPath).indexOf('.') !== -1\n\n  if (!dstStats) {\n    const createPath = looksLikeFile ? path.dirname(dstPath) : dstPath\n\n    await fs.mkdir(createPath, {recursive: true})\n  }\n\n  const finalPath = looksLikeFile ? dstPath : path.join(dstPath, `${dataset}.tar.gz`)\n  dstStats = await fs.stat(finalPath).catch(noop)\n\n  if (!flags.overwrite && dstStats && dstStats.isFile()) {\n    const shouldOverwrite = await prompt.single({\n      type: 'confirm',\n      message: `File \"${finalPath}\" already exists, would you like to overwrite it?`,\n      default: false,\n    })\n\n    if (!shouldOverwrite) {\n      return false\n    }\n  }\n\n  return finalPath\n}\n\nexport default exportDatasetCommand\n","import {createReadStream} from 'node:fs'\nimport fs from 'node:fs/promises'\nimport path from 'node:path'\n\nimport {type CliCommandContext, type CliCommandDefinition, type CliOutputter} from '@sanity/cli'\nimport sanityImport from '@sanity/import'\nimport {getIt} from 'get-it'\n// eslint-disable-next-line import/extensions\nimport {promise} from 'get-it/middleware'\nimport {padStart} from 'lodash'\nimport prettyMs from 'pretty-ms'\n\nimport {chooseDatasetPrompt} from '../../actions/dataset/chooseDatasetPrompt'\nimport {validateDatasetName} from '../../actions/dataset/validateDatasetName'\nimport {debug} from '../../debug'\n\nconst yellow = (str: string) => `\\u001b[33m${str}\\u001b[39m`\n\nconst helpText = `\nOptions\n  --missing On duplicate document IDs, skip importing document in question\n  --replace On duplicate document IDs, replace existing document with imported document\n  --allow-failing-assets Skip assets that cannot be fetched/uploaded\n  --replace-assets Skip reuse of existing assets\n  --skip-cross-dataset-references Skips references to other datasets\n\nRarely used options (should generally not be used)\n  --allow-assets-in-different-dataset Allow asset documents to reference different project/dataset\n  --allow-system-documents Allow system documents like dataset permissions and custom retention to be imported\n\nExamples\n  # Import \"moviedb.ndjson\" from the current directory to the dataset called \"moviedb\"\n  sanity dataset import moviedb.ndjson moviedb\n\n  # Import \"moviedb.tar.gz\" from the current directory to the dataset called \"moviedb\",\n  # replacing any documents encountered that have the same document IDs\n  sanity dataset import moviedb.tar.gz moviedb --replace\n\n  # Import from a folder containing an ndjson file, such as an extracted tarball\n  # retrieved through \"sanity dataset export\".\n  sanity dataset import ~/some/folder moviedb\n\n  # Import from a remote URL. Will download and extract the tarball to a temporary\n  # location before importing it.\n  sanity dataset import https://some.url/moviedb.tar.gz moviedb --replace\n`\n\ninterface ImportFlags {\n  'allow-assets-in-different-dataset'?: boolean\n  'allow-failing-assets'?: boolean\n  'asset-concurrency'?: boolean\n  'replace-assets'?: boolean\n  'skip-cross-dataset-references'?: boolean\n  'allow-system-documents'?: boolean\n  'replace'?: boolean\n  'missing'?: boolean\n}\n\ninterface ParsedImportFlags {\n  allowAssetsInDifferentDataset?: boolean\n  allowFailingAssets?: boolean\n  assetConcurrency?: boolean\n  skipCrossDatasetReferences?: boolean\n  allowSystemDocuments?: boolean\n  replaceAssets?: boolean\n  replace?: boolean\n  missing?: boolean\n}\n\ninterface ProgressEvent {\n  step: string\n  total?: number\n  current?: number\n}\n\ninterface ImportWarning {\n  type?: string\n  url?: string\n}\n\nfunction toBoolIfSet(flag: unknown): boolean | undefined {\n  return typeof flag === 'undefined' ? undefined : Boolean(flag)\n}\n\nfunction parseFlags(rawFlags: ImportFlags): ParsedImportFlags {\n  const allowAssetsInDifferentDataset = toBoolIfSet(rawFlags['allow-assets-in-different-dataset'])\n  const allowFailingAssets = toBoolIfSet(rawFlags['allow-failing-assets'])\n  const assetConcurrency = toBoolIfSet(rawFlags['asset-concurrency'])\n  const replaceAssets = toBoolIfSet(rawFlags['replace-assets'])\n  const skipCrossDatasetReferences = toBoolIfSet(rawFlags['skip-cross-dataset-references'])\n  const allowSystemDocuments = toBoolIfSet(rawFlags['allow-system-documents'])\n  const replace = toBoolIfSet(rawFlags.replace)\n  const missing = toBoolIfSet(rawFlags.missing)\n  return {\n    allowAssetsInDifferentDataset,\n    allowFailingAssets,\n    assetConcurrency,\n    skipCrossDatasetReferences,\n    allowSystemDocuments,\n    replaceAssets,\n    replace,\n    missing,\n  }\n}\n\nconst importDatasetCommand: CliCommandDefinition = {\n  name: 'import',\n  group: 'dataset',\n  signature: '[FILE | FOLDER | URL] [TARGET_DATASET]',\n  description: 'Import documents to given dataset from either an ndjson file or a gzipped tarball',\n  helpText,\n  // eslint-disable-next-line max-statements\n  action: async (args, context) => {\n    const {apiClient, output, chalk, fromInitCommand} = context\n    const flags = parseFlags(args.extOptions)\n    const {\n      allowAssetsInDifferentDataset,\n      allowFailingAssets,\n      assetConcurrency,\n      skipCrossDatasetReferences,\n      allowSystemDocuments,\n      replaceAssets,\n    } = flags\n\n    const operation = getMutationOperation(args.extOptions)\n    const client = apiClient()\n\n    const [file, target] = args.argsWithoutOptions\n    if (!file) {\n      throw new Error(\n        `Source file name and target dataset must be specified (\"sanity dataset import ${chalk.bold(\n          '[file]',\n        )} [dataset]\")`,\n      )\n    }\n\n    const targetDataset = await determineTargetDataset(target, context)\n    debug(`Target dataset has been set to \"${targetDataset}\"`)\n\n    const isUrl = /^https?:\\/\\//i.test(file)\n    let inputStream\n    let assetsBase\n    let sourceIsFolder = false\n\n    if (isUrl) {\n      debug('Input is a URL, streaming from source URL')\n      inputStream = await getUrlStream(file)\n    } else {\n      const sourceFile = path.resolve(process.cwd(), file)\n      const fileStats = await fs.stat(sourceFile).catch(() => null)\n      if (!fileStats) {\n        throw new Error(`${sourceFile} does not exist or is not readable`)\n      }\n\n      sourceIsFolder = fileStats.isDirectory()\n      if (sourceIsFolder) {\n        inputStream = sourceFile\n      } else {\n        assetsBase = path.dirname(sourceFile)\n        inputStream = await createReadStream(sourceFile)\n      }\n    }\n\n    const importClient = client.clone().config({dataset: targetDataset})\n\n    // Print information about what projectId and dataset it is being imported to\n    const {projectId, dataset} = importClient.config()\n\n    output.print('╭───────────────────────────────────────────────╮')\n    output.print('│                                               │')\n    output.print('│ Importing to:                                 │')\n    output.print(`│ ${chalk.bold('projectId')}: ${chalk.cyan(projectId).padEnd(44)} │`)\n    output.print(`│ ${chalk.bold('dataset')}: ${chalk.cyan(dataset).padEnd(46)} │`)\n    output.print('│                                               │')\n    output.print('╰───────────────────────────────────────────────╯')\n    output.print('')\n\n    let currentStep: string | undefined\n    let currentProgress: ReturnType<CliOutputter['spinner']> | undefined\n    let stepStart: number | undefined\n    let spinInterval: ReturnType<typeof setInterval> | null = null\n    let percent: string | undefined\n\n    function onProgress(opts: ProgressEvent) {\n      const lengthComputable = opts.total\n      const sameStep = opts.step == currentStep\n      percent = getPercentage(opts)\n\n      if (lengthComputable && opts.total === opts.current) {\n        if (spinInterval) {\n          clearInterval(spinInterval)\n        }\n        spinInterval = null\n      }\n\n      if (sameStep) {\n        return\n      }\n\n      // Moved to a new step\n      const prevStep = currentStep\n      const prevStepStart = stepStart || Date.now()\n      stepStart = Date.now()\n      currentStep = opts.step\n\n      if (currentProgress && currentProgress.succeed) {\n        const timeSpent = prettyMs(Date.now() - prevStepStart, {\n          secondsDecimalDigits: 2,\n        })\n        currentProgress.text = `[100%] ${prevStep} (${timeSpent})`\n        currentProgress.succeed()\n      }\n\n      currentProgress = output.spinner(`[0%] ${opts.step} (0.00s)`).start()\n\n      if (spinInterval) {\n        clearInterval(spinInterval)\n        spinInterval = null\n      }\n\n      spinInterval = setInterval(() => {\n        const timeSpent = prettyMs(Date.now() - prevStepStart, {\n          secondsDecimalDigits: 2,\n        })\n\n        if (currentProgress) {\n          currentProgress.text = `${percent}${opts.step} (${timeSpent})`\n        }\n      }, 60)\n    }\n\n    function endTask({success}: {success: boolean}) {\n      if (spinInterval) {\n        clearInterval(spinInterval)\n      }\n\n      spinInterval = null\n\n      if (success && stepStart && currentProgress) {\n        const timeSpent = prettyMs(Date.now() - stepStart, {\n          secondsDecimalDigits: 2,\n        })\n        currentProgress.text = `[100%] ${currentStep} (${timeSpent})`\n        currentProgress.succeed()\n      } else if (currentProgress) {\n        currentProgress.fail()\n      }\n    }\n\n    // Start the import!\n    try {\n      const {numDocs, warnings} = await sanityImport(inputStream, {\n        client: importClient,\n        assetsBase,\n        operation,\n        onProgress,\n        allowFailingAssets,\n        allowAssetsInDifferentDataset,\n        skipCrossDatasetReferences,\n        allowSystemDocuments,\n        assetConcurrency,\n        replaceAssets,\n      })\n\n      endTask({success: true})\n\n      output.print('Done! Imported %d documents to dataset \"%s\"\\n', numDocs, targetDataset)\n      printWarnings(warnings, output)\n    } catch (err) {\n      endTask({success: false})\n\n      const isNonRefConflict =\n        !fromInitCommand &&\n        err.response &&\n        err.response.statusCode === 409 &&\n        err.step !== 'strengthen-references'\n\n      if (!isNonRefConflict) {\n        throw err\n      }\n\n      const message = [\n        err.message,\n        '',\n        'You probably want either:',\n        ' --replace (replace existing documents with same IDs)',\n        ' --missing (only import documents that do not already exist)',\n        '',\n      ].join('\\n')\n\n      // @todo SUBCLASS ERROR?\n      const error = new Error(message) as any\n      error.details = err.details\n      error.response = err.response\n      error.responseBody = err.responseBody\n\n      throw error\n    }\n  },\n}\n\nasync function determineTargetDataset(target: string, context: CliCommandContext) {\n  const {apiClient, output, prompt} = context\n  const client = apiClient()\n\n  if (target) {\n    const dsError = validateDatasetName(target)\n    if (dsError) {\n      throw new Error(dsError)\n    }\n  }\n\n  debug('Fetching available datasets')\n  const spinner = output.spinner('Fetching available datasets').start()\n  const datasets = await client.datasets.list()\n  spinner.succeed('[100%] Fetching available datasets')\n\n  let targetDataset = target ? `${target}` : null\n  if (!targetDataset) {\n    targetDataset = await chooseDatasetPrompt(context, {\n      message: 'Select target dataset',\n      allowCreation: true,\n    })\n  } else if (!datasets.find((dataset) => dataset.name === targetDataset)) {\n    debug('Target dataset does not exist, prompting for creation')\n    const shouldCreate = await prompt.single({\n      type: 'confirm',\n      message: `Dataset \"${targetDataset}\" does not exist, would you like to create it?`,\n      default: true,\n    })\n\n    if (!shouldCreate) {\n      throw new Error(`Dataset \"${targetDataset}\" does not exist`)\n    }\n\n    await client.datasets.create(targetDataset)\n  }\n\n  return targetDataset\n}\n\nfunction getMutationOperation(flags: ParsedImportFlags) {\n  const {replace, missing} = flags\n  if (replace && missing) {\n    throw new Error('Cannot use both --replace and --missing')\n  }\n\n  if (flags.replace) {\n    return 'createOrReplace'\n  }\n\n  if (flags.missing) {\n    return 'createIfNotExists'\n  }\n\n  return 'create'\n}\n\nfunction getPercentage(opts: ProgressEvent) {\n  if (!opts.total || typeof opts.current === 'undefined') {\n    return ''\n  }\n\n  const percent = Math.floor((opts.current / opts.total) * 100)\n  return `[${padStart(`${percent}`, 3, ' ')}%] `\n}\n\nfunction getUrlStream(url: string) {\n  const request = getIt([promise({onlyBody: true})])\n  return request({url, stream: true})\n}\n\nfunction printWarnings(warnings: ImportWarning[], output: CliOutputter) {\n  const assetFails = warnings.filter((warn) => warn.type === 'asset')\n\n  if (!assetFails.length) {\n    return\n  }\n\n  const warn = (output.warn || output.print).bind(output)\n\n  warn(yellow('⚠ Failed to import the following %s:'), assetFails.length > 1 ? 'assets' : 'asset')\n\n  warnings.forEach((warning) => {\n    warn(`  ${warning.url}`)\n  })\n}\n\nexport default importDatasetCommand\n","import {type CliCommandAction} from '@sanity/cli'\n\nimport * as aliasClient from './datasetAliasesClient'\nimport {ALIAS_PREFIX} from './datasetAliasesClient'\n\nexport const listAliasesHandler: CliCommandAction = async (args, context) => {\n  const {apiClient, output} = context\n  const client = apiClient()\n\n  const aliases = await aliasClient.listAliases(client)\n  output.print(\n    aliases\n      .map((set) => `${ALIAS_PREFIX}${set.name} -> ${set.datasetName || '<unlinked>'}`)\n      .join('\\n'),\n  )\n}\n","import {type CliCommandDefinition} from '@sanity/cli'\n\nimport {listAliasesHandler} from './alias/listAliasesHandler'\n\nconst listDatasetsCommand: CliCommandDefinition = {\n  name: 'list',\n  group: 'dataset',\n  helpText: '',\n  signature: '',\n  description: 'List datasets of your project',\n  action: async (args, context) => {\n    const {apiClient, output} = context\n    const client = apiClient()\n    const datasets = await client.datasets.list()\n    output.print(datasets.map((set) => set.name).join('\\n'))\n\n    // Print alias list\n    await listAliasesHandler(args, context)\n  },\n}\n\nexport default listDatasetsCommand\n","import {type CliConfig} from '@sanity/cli'\n\nexport function determineIsCoreApp(cliConfig?: CliConfig): boolean {\n  return Boolean(cliConfig && '__experimental_coreAppConfiguration' in cliConfig)\n}\n","import {\n  type CliCommandArguments,\n  type CliCommandContext,\n  type CliCommandDefinition,\n} from '@sanity/cli'\n\nimport {type DeployStudioActionFlags} from '../../actions/deploy/deployAction'\nimport {determineIsCoreApp} from '../../util/determineIsCoreApp'\n\nconst helpText = `\nOptions\n  --source-maps Enable source maps for built bundles (increases size of bundle)\n  --auto-updates / --no-auto-updates Enable/disable auto updates of studio versions\n  --no-minify Skip minifying built JavaScript (speeds up build, increases size of bundle)\n  --no-build Don't build the studio prior to deploy, instead deploying the version currently in \\`dist/\\`\n  -y, --yes Unattended mode, answers \"yes\" to any \"yes/no\" prompt and otherwise uses defaults\n\nExamples\n  sanity deploy\n  sanity deploy --no-minify --source-maps\n`\n\nconst deployCommand: CliCommandDefinition = {\n  name: 'deploy',\n  signature: '[SOURCE_DIR] [--no-build] [--source-maps] [--no-minify]',\n  description: 'Builds and deploys Sanity Studio or application to Sanity hosting',\n  action: async (\n    args: CliCommandArguments<DeployStudioActionFlags>,\n    context: CliCommandContext,\n  ) => {\n    let mod: {\n      default: (\n        args: CliCommandArguments<DeployStudioActionFlags>,\n        context: CliCommandContext,\n      ) => Promise<void>\n    }\n\n    const isCoreApp = determineIsCoreApp(context.cliConfig)\n\n    if (isCoreApp) {\n      mod = await import('../../actions/app/deployAction')\n    } else {\n      mod = await import('../../actions/deploy/deployAction')\n    }\n\n    return mod.default(args, context)\n  },\n  helpText,\n}\n\nexport default deployCommand\n","import {\n  type CliCommandArguments,\n  type CliCommandContext,\n  type CliCommandDefinition,\n} from '@sanity/cli'\n\nimport {type UndeployStudioActionFlags} from '../../actions/deploy/undeployAction'\nimport {determineIsCoreApp} from '../../util/determineIsCoreApp'\n\nconst helpText = `\nOptions\n  -y, --yes Unattended mode, answers \"yes\" to any \"yes/no\" prompt and otherwise uses defaults\n\nExamples\n  sanity undeploy\n  sanity undeploy --yes\n`\n\nconst undeployCommand: CliCommandDefinition = {\n  name: 'undeploy',\n  signature: '',\n  description: 'Removes the deployed Sanity Studio from Sanity hosting',\n  action: async (\n    args: CliCommandArguments<UndeployStudioActionFlags>,\n    context: CliCommandContext,\n  ) => {\n    let mod: {\n      default: (\n        args: CliCommandArguments<UndeployStudioActionFlags>,\n        context: CliCommandContext,\n      ) => Promise<void>\n    }\n\n    const isCoreApp = determineIsCoreApp(context.cliConfig)\n\n    if (isCoreApp) {\n      mod = await import('../../actions/app/undeployAction')\n    } else {\n      mod = await import('../../actions/deploy/undeployAction')\n    }\n\n    return mod.default(args, context)\n  },\n  helpText,\n}\n\nexport default undeployCommand\n","import {\n  type CliCommandArguments,\n  type CliCommandContext,\n  type CliCommandDefinition,\n} from '@sanity/cli'\n\nimport {type StartDevServerCommandFlags} from '../../actions/dev/devAction'\nimport {determineIsCoreApp} from '../../util/determineIsCoreApp'\n\nconst helpText = `\nNotes\n  Changing the hostname or port number might require a new entry to the CORS-origins allow list.\n\nOptions\n  --port <port> TCP port to start server on. [default: 3333]\n  --host <host> The local network interface at which to listen. [default: \"127.0.0.1\"]\n\nExamples\n  sanity dev --host=0.0.0.0\n  sanity dev --port=1942\n`\n\nconst devCommand: CliCommandDefinition = {\n  name: 'dev',\n  signature: '[--port <port>] [--host <host>]',\n  description: 'Starts a local dev server for Sanity Studio with live reloading',\n  action: async (\n    args: CliCommandArguments<StartDevServerCommandFlags>,\n    context: CliCommandContext,\n  ) => {\n    const devAction = await getDevAction(context)\n\n    return devAction(args, context)\n  },\n  helpText,\n}\n\nexport async function getDevAction(\n  context: CliCommandContext,\n): Promise<\n  (\n    args: CliCommandArguments<StartDevServerCommandFlags>,\n    context: CliCommandContext,\n  ) => Promise<void>\n> {\n  const isCoreApp = determineIsCoreApp(context.cliConfig)\n\n  // NOTE: in dev-mode we want to include from `src` so we need to use `.ts` extension\n  if (__DEV__) {\n    if (isCoreApp) {\n      // eslint-disable-next-line import/extensions,@typescript-eslint/consistent-type-imports\n      const mod = require('../../actions/app/devAction.ts')\n      return mod.default\n    }\n    // eslint-disable-next-line import/extensions,@typescript-eslint/consistent-type-imports\n    const mod = require('../../actions/dev/devAction.ts')\n    return mod.default\n  }\n  if (isCoreApp) {\n    const mod = await import('../../actions/app/devAction')\n    return mod.default\n  }\n  const mod = await import('../../actions/dev/devAction')\n  return mod.default\n}\n\nexport default devCommand\n","import fs from 'node:fs/promises'\nimport os from 'node:os'\nimport path from 'node:path'\n\nimport {type CliCommandDefinition} from '@sanity/cli'\nimport {\n  type IdentifiedSanityDocumentStub,\n  type MultipleMutationResult,\n  type Mutation,\n  type SanityClient,\n} from '@sanity/client'\nimport {uuid} from '@sanity/uuid'\nimport chokidar from 'chokidar'\nimport execa from 'execa'\nimport json5 from 'json5'\nimport {isEqual, isPlainObject, noop} from 'lodash'\n\ntype MutationOperationName = 'create' | 'createOrReplace' | 'createIfNotExists'\n\ninterface CreateFlags {\n  dataset?: string\n  replace?: boolean\n  missing?: boolean\n  watch?: boolean\n  json5?: boolean\n  id?: string\n}\n\nconst helpText = `\nOptions\n  --replace On duplicate document IDs, replace existing document with specified document(s)\n  --missing On duplicate document IDs, don't modify the target document(s)\n  --watch   Write the documents whenever the target file or buffer changes\n  --json5   Use JSON5 file type to allow a \"simplified\" version of JSON\n  --id <id> Specify a document ID to use. Will fetch remote document ID and populate editor.\n  --dataset NAME to override dataset\n\nExamples\n  # Create the document specified in \"myDocument.json\".\n  sanity documents create myDocument.json\n\n  # Open configured $EDITOR and create the specified document(s)\n  sanity documents create\n\n  # Fetch document with the ID \"myDocId\" and open configured $EDITOR with the\n  # current document content (if any). Replace document with the edited version\n  # when the editor closes\n  sanity documents create --id myDocId --replace\n\n  # Open configured $EDITOR and replace the document with the given content\n  # on each save. Use JSON5 file extension and parser for simplified syntax.\n  sanity documents create --id myDocId --watch --replace --json5\n`\n\nconst createDocumentsCommand: CliCommandDefinition<CreateFlags> = {\n  name: 'create',\n  group: 'documents',\n  signature: '[FILE]',\n  helpText,\n  description: 'Create one or more documents',\n  // eslint-disable-next-line complexity\n  action: async (args, context) => {\n    const {apiClient, output} = context\n    const {replace, missing, watch, id, dataset} = args.extOptions\n    const [file] = args.argsWithoutOptions\n    const useJson5 = args.extOptions.json5\n    const client = dataset ? apiClient().clone().config({dataset}) : apiClient()\n\n    if (replace && missing) {\n      throw new Error('Cannot use both --replace and --missing')\n    }\n\n    if (id && file) {\n      throw new Error('Cannot use --id when specifying a file path')\n    }\n\n    let operation: MutationOperationName = 'create'\n    if (replace || missing) {\n      operation = replace ? 'createOrReplace' : 'createIfNotExists'\n    }\n\n    if (file) {\n      const contentPath = path.resolve(process.cwd(), file)\n      const content = json5.parse(await fs.readFile(contentPath, 'utf8'))\n      const result = await writeDocuments(content, operation, client)\n      output.print(getResultMessage(result, operation))\n      return\n    }\n\n    // Create a temporary file and use that as source, opening an editor on it\n    const docId = id || uuid()\n    const ext = useJson5 ? 'json5' : 'json'\n    const tmpFile = path.join(os.tmpdir(), 'sanity-cli', `${docId}.${ext}`)\n    const stringify = useJson5 ? json5.stringify : JSON.stringify\n    const defaultValue = (id && (await client.getDocument(id))) || {_id: docId, _type: 'specify-me'}\n    await fs.mkdir(path.join(os.tmpdir(), 'sanity-cli'), {recursive: true})\n    await fs.writeFile(tmpFile, stringify(defaultValue, null, 2), 'utf8')\n\n    const editor = getEditor()\n    if (watch) {\n      // If we're in watch mode, we want to run the creation on each change (if it validates)\n      registerUnlinkOnSigInt(tmpFile)\n      output.print(`Watch mode: ${tmpFile}`)\n      output.print('Watch mode: Will write documents on each save.')\n      output.print('Watch mode: Press Ctrl + C to cancel watch mode.')\n      chokidar.watch(tmpFile).on('change', () => {\n        output.print('')\n        return readAndPerformCreatesFromFile(tmpFile)\n      })\n      execa(editor.bin, editor.args.concat(tmpFile), {stdio: 'inherit'})\n    } else {\n      // While in normal mode, we just want to wait for the editor to close and run the thing once\n      execa.sync(editor.bin, editor.args.concat(tmpFile), {stdio: 'inherit'})\n      await readAndPerformCreatesFromFile(tmpFile)\n      await fs.unlink(tmpFile).catch(noop)\n    }\n\n    async function readAndPerformCreatesFromFile(filePath: string) {\n      let content\n      try {\n        content = json5.parse(await fs.readFile(filePath, 'utf8'))\n      } catch (err) {\n        output.error(`Failed to read input: ${err.message}`)\n        return\n      }\n\n      if (isEqual(content, defaultValue)) {\n        output.print('Value not modified, doing nothing.')\n        output.print('Modify document to trigger creation.')\n        return\n      }\n\n      try {\n        const writeResult = await writeDocuments(content, operation, client)\n        output.print(getResultMessage(writeResult, operation))\n      } catch (err) {\n        output.error(`Failed to write documents: ${err.message}`)\n        if (err.message.includes('already exists')) {\n          output.error('Perhaps you want to use `--replace` or `--missing`?')\n        }\n      }\n    }\n  },\n}\n\nfunction registerUnlinkOnSigInt(tmpFile: string) {\n  process.on('SIGINT', async () => {\n    await fs.unlink(tmpFile).catch(noop)\n    // eslint-disable-next-line no-process-exit\n    process.exit(130)\n  })\n}\n\nfunction writeDocuments(\n  documents: {_id?: string; _type: string} | {_id?: string; _type: string}[],\n  operation: MutationOperationName,\n  client: SanityClient,\n) {\n  const docs = Array.isArray(documents) ? documents : [documents]\n  if (docs.length === 0) {\n    throw new Error('No documents provided')\n  }\n\n  const mutations = docs.map((doc, index): Mutation => {\n    validateDocument(doc, index, docs)\n    if (operation === 'create') {\n      return {create: doc}\n    }\n\n    if (operation === 'createIfNotExists') {\n      if (isIdentifiedSanityDocument(doc)) {\n        return {createIfNotExists: doc}\n      }\n\n      throw new Error(`Missing required _id attribute for ${operation}`)\n    }\n\n    if (operation === 'createOrReplace') {\n      if (isIdentifiedSanityDocument(doc)) {\n        return {createOrReplace: doc}\n      }\n\n      throw new Error(`Missing required _id attribute for ${operation}`)\n    }\n\n    throw new Error(`Unsupported operation ${operation}`)\n  })\n\n  return client.transaction(mutations).commit()\n}\n\nfunction validateDocument(doc: unknown, index: number, arr: unknown[]) {\n  const isSingle = arr.length === 1\n\n  if (!isPlainObject(doc)) {\n    throw new Error(getErrorMessage('must be an object', index, isSingle))\n  }\n\n  if (!isSanityDocumentish(doc)) {\n    throw new Error(getErrorMessage('must have a `_type` property of type string', index, isSingle))\n  }\n}\n\nfunction isSanityDocumentish(doc: unknown): doc is {_type: string} {\n  return (\n    doc !== null &&\n    typeof doc === 'object' &&\n    '_type' in doc &&\n    typeof (doc as any)._type === 'string'\n  )\n}\n\nfunction isIdentifiedSanityDocument(doc: unknown): doc is IdentifiedSanityDocumentStub {\n  return isSanityDocumentish(doc) && '_id' in doc\n}\n\nfunction getErrorMessage(message: string, index: number, isSingle: boolean): string {\n  return isSingle ? `Document ${message}` : `Document at index ${index} ${message}`\n}\n\nfunction getResultMessage(\n  result: MultipleMutationResult,\n  operation: MutationOperationName,\n): string {\n  const joiner = '\\n  - '\n  if (operation === 'createOrReplace') {\n    return `Upserted:\\n  - ${result.results.map((res) => res.id).join(joiner)}`\n  }\n\n  if (operation === 'create') {\n    return `Created:\\n  - ${result.results.map((res) => res.id).join(joiner)}`\n  }\n\n  // \"Missing\" (createIfNotExists)\n  const created: string[] = []\n  const skipped: string[] = []\n  for (const res of result.results) {\n    if (res.operation === 'update') {\n      skipped.push(res.id)\n    } else {\n      created.push(res.id)\n    }\n  }\n\n  if (created.length > 0 && skipped.length > 0) {\n    return [\n      `Created:\\n  - ${created.join(joiner)}`,\n      `Skipped (already exists):${joiner}${skipped.join(joiner)}`,\n    ].join('\\n\\n')\n  } else if (created.length > 0) {\n    return `Created:\\n  - ${created.join(joiner)}`\n  }\n\n  return `Skipped (already exists):\\n  - ${skipped.join(joiner)}`\n}\n\nfunction getEditor() {\n  const defaultEditor = /^win/.test(process.platform) ? 'notepad' : 'vim'\n  // eslint-disable-next-line no-process-env\n  const editor = process.env.VISUAL || process.env.EDITOR || defaultEditor\n  const args = editor.split(/\\s+/)\n  const bin = args.shift() || ''\n  return {bin, args}\n}\n\nexport default createDocumentsCommand\n","import {type CliCommandDefinition} from '@sanity/cli'\nimport pluralize from 'pluralize-esm'\n\nconst helpText = `\nDelete a document from the projects configured dataset\n\nOptions\n  --dataset NAME to override dataset\n\nExample\n  # Delete the document with the ID \"myDocId\"\n  sanity documents delete myDocId\n\n  # ID wrapped in double or single quote works equally well\n  sanity documents delete 'myDocId'\n\n  # Delete document with ID \"someDocId\" from dataset \"blog\"\n  sanity documents delete --dataset=blog someDocId\n\n  # Delete the document with ID \"doc1\" and \"doc2\"\n  sanity documents delete doc1 doc2\n`\n\ninterface DeleteFlags {\n  dataset?: string\n}\n\nconst deleteDocumentsCommand: CliCommandDefinition<DeleteFlags> = {\n  name: 'delete',\n  group: 'documents',\n  signature: '[ID] [...IDS]',\n  helpText,\n  description: 'Delete a document by ID',\n  action: async (args, context) => {\n    const {apiClient, output, chalk} = context\n    const {dataset} = args.extOptions\n    const ids = args.argsWithoutOptions.map((str) => `${str}`)\n\n    if (!ids.length) {\n      throw new Error('Document ID must be specified')\n    }\n\n    const client = dataset ? apiClient().clone().config({dataset}) : apiClient()\n\n    const transaction = ids.reduce((trx, id) => trx.delete(id), client.transaction())\n    try {\n      const {results} = await transaction.commit()\n      const deleted = results.filter((res) => res.operation === 'delete').map((res) => res.id)\n      const notFound = ids.filter((id) => !deleted.includes(id))\n      if (deleted.length > 0) {\n        output.print(`Deleted ${deleted.length} ${pluralize('document', deleted.length)}`)\n      }\n\n      if (notFound.length > 0) {\n        output.error(\n          chalk.red(`${pluralize('Document', notFound.length)} not found: ${notFound.join(', ')}`),\n        )\n      }\n    } catch (err) {\n      throw new Error(`Failed to delete ${pluralize('document', ids.length)}:\\n${err.message}`)\n    }\n  },\n}\n\nexport default deleteDocumentsCommand\n","import {type CliCommandGroupDefinition} from '@sanity/cli'\n\nconst documentsGroup: CliCommandGroupDefinition = {\n  name: 'documents',\n  signature: '[COMMAND]',\n  isGroupRoot: true,\n  description: 'Manages documents in your Sanity Content Lake datasets',\n}\n\nexport default documentsGroup\n","import {type CliCommandContext} from '@sanity/cli'\nimport tokenize, {type LexerToken} from 'json-lexer'\n\ninterface KeyToken {\n  type: 'key'\n  value: string\n  raw: string\n}\n\ntype ExtendedLexerToken = LexerToken | KeyToken\n\nconst identity = (inp: string): string => inp\n\nexport function colorizeJson(input: unknown, chalk: CliCommandContext['chalk']): string {\n  const formatters: Record<ExtendedLexerToken['type'], (str: string) => string> = {\n    punctuator: chalk.white,\n    key: chalk.white,\n    string: chalk.green,\n    number: chalk.yellow,\n    literal: chalk.bold,\n    whitespace: identity,\n  }\n\n  const json = JSON.stringify(input, null, 2)\n\n  return tokenize(json)\n    .map((token, i, arr): ExtendedLexerToken => {\n      // Note how the following only works because we pretty-print the JSON\n      const prevToken = i === 0 ? token : arr[i - 1]\n      if (\n        token.type === 'string' &&\n        prevToken.type === 'whitespace' &&\n        /^\\n\\s+$/.test(prevToken.value)\n      ) {\n        return {...token, type: 'key'}\n      }\n\n      return token\n    })\n    .map((token) => {\n      const formatter = formatters[token.type] || identity\n      return formatter(token.raw)\n    })\n    .join('')\n}\n","import {type CliCommandDefinition} from '@sanity/cli'\n\nimport {colorizeJson} from '../../util/colorizeJson'\n\nconst helpText = `\nGet and print a document from the projects configured dataset\n\nOptions\n  --pretty colorized JSON output\n  --dataset NAME to override dataset\n\nExamples\n  # Get the document with the ID \"myDocId\"\n  sanity documents get myDocId\n\n  # ID wrapped in double or single quote works equally well\n  sanity documents get 'myDocId'\n`\n\ninterface GetDocumentFlags {\n  pretty?: boolean\n  dataset?: string\n}\n\nconst getDocumentsCommand: CliCommandDefinition<GetDocumentFlags> = {\n  name: 'get',\n  group: 'documents',\n  signature: '[DOCUMENT_ID]',\n  helpText,\n  description: 'Get and print a document by ID',\n  action: async (args, context) => {\n    const {apiClient, output, chalk} = context\n    const {pretty, dataset} = args.extOptions\n    const [docId] = args.argsWithoutOptions.map((str) => `${str}`)\n\n    if (!docId) {\n      throw new Error('Document ID must be specified')\n    }\n\n    const client = dataset ? apiClient().clone().config({dataset}) : apiClient()\n\n    try {\n      const doc = await client.getDocument(docId)\n      if (!doc) {\n        throw new Error(`Document ${docId} not found`)\n      }\n\n      output.print(pretty ? colorizeJson(doc, chalk) : JSON.stringify(doc, null, 2))\n    } catch (err) {\n      throw new Error(`Failed to fetch document:\\n${err.message}`)\n    }\n  },\n}\n\nexport default getDocumentsCommand\n","import {type CliCommandArguments, type CliCommandContext} from '@sanity/cli'\nimport {hideBin} from 'yargs/helpers'\nimport yargs from 'yargs/yargs'\n\nimport {colorizeJson} from '../../util/colorizeJson'\n\nconst defaultApiVersion = 'v2022-06-01'\n\nconst helpText = `\nRun a query against the projects configured dataset\n\nOptions\n  --pretty colorized JSON output\n  --dataset NAME to override dataset\n  --project PROJECT to override project ID\n  --anonymous Send the query without any authorization token\n  --api-version API version to use (defaults to \\`${defaultApiVersion}\\`)\n\nEnvironment variables\n  \\`SANITY_CLI_QUERY_API_VERSION\\` - will use the defined API version,\n  unless \\`--api-version\\` is specified.\n\nExamples\n  # Fetch 5 documents of type \"movie\"\n  sanity documents query '*[_type == \"movie\"][0..4]'\n\n  # Fetch title of the oldest movie in the dataset named \"staging\"\n  sanity documents query '*[_type == \"movie\"]|order(releaseDate asc)[0]{title}' --dataset staging\n\n  # Use API version v2021-06-07 and do a query\n  sanity documents query --api-version v2021-06-07 '*[_id == \"header\"] { \"headerText\": pt::text(body) }'\n`\n\ninterface CliQueryCommandFlags {\n  pretty?: boolean\n  anonymous?: boolean\n  dataset?: string\n  project?: string\n  apiVersion?: string\n}\n\nexport default {\n  name: 'query',\n  group: 'documents',\n  signature: '[QUERY]',\n  helpText,\n  description: 'Query for documents',\n  action: async (\n    args: CliCommandArguments<CliQueryCommandFlags>,\n    context: CliCommandContext,\n  ): Promise<void> => {\n    // Reparsing arguments for improved control of flags\n    const {\n      pretty,\n      dataset,\n      project,\n      anonymous,\n      'api-version': apiVersion,\n    } = await parseCliFlags(args)\n    const {apiClient, output, chalk, cliConfig} = context\n    const [query] = args.argsWithoutOptions\n\n    if (!query) {\n      throw new Error('Query must be specified')\n    }\n\n    if (!apiVersion) {\n      output.warn(chalk.yellow(`--api-version not specified, using \\`${defaultApiVersion}\\``))\n    }\n\n    const requireDataset = !dataset\n    const requireProject = !project\n    const requireUser = !anonymous\n\n    if (requireProject && !cliConfig?.api?.projectId) {\n      throw new Error(\n        'No project configured in CLI config - either configure one, or use `--project` flag',\n      )\n    }\n\n    if (requireDataset && !cliConfig?.api?.dataset) {\n      throw new Error(\n        'No dataset configured in CLI config - either configure one, or use `--dataset` flag',\n      )\n    }\n\n    const baseClient = apiClient({requireProject, requireUser}).clone()\n    const {dataset: originalDataset, projectId: originalProjectId} = baseClient.config()\n\n    const client = baseClient.config({\n      projectId: project || originalProjectId,\n      dataset: dataset || originalDataset,\n      apiVersion: apiVersion || defaultApiVersion,\n    })\n\n    try {\n      const docs = await client.fetch(query)\n      if (!docs) {\n        throw new Error('Query returned no results')\n      }\n\n      output.print(pretty ? colorizeJson(docs, chalk) : JSON.stringify(docs, null, 2))\n    } catch (err) {\n      throw new Error(`Failed to run query:\\n${err.message}`)\n    }\n  },\n}\n\nfunction parseCliFlags(args: CliCommandArguments<CliQueryCommandFlags>) {\n  // eslint-disable-next-line no-process-env\n  const fallbackApiVersion = process.env.SANITY_CLI_QUERY_API_VERSION\n  return yargs(hideBin(args.argv || process.argv).slice(2))\n    .option('pretty', {type: 'boolean', default: false})\n    .option('dataset', {type: 'string'})\n    .option('project', {type: 'string'})\n    .option('anonymous', {type: 'boolean', default: false})\n    .option('api-version', {type: 'string', default: fallbackApiVersion}).argv\n}\n","import {type CliCommandDefinition} from '@sanity/cli'\n\nconst description = `Downloads and validates all document specified in a workspace`\n\nconst helpText = `\nOptions\n  -y, --yes Skips the first confirmation prompt.\n  --workspace <name> The name of the workspace to use when downloading and validating all documents.\n  --dataset <name> Override the dataset used. By default, this is derived from the given workspace.\n  --file <filepath> Provide a path to either an .ndjson file or a tarball containing an .ndjson file.\n  --format <pretty|ndjson|json> The output format used to print the found validation markers and report progress.\n  --level <error|warning|info> The minimum level reported out. Defaults to warning.\n  --max-custom-validation-concurrency <number> Specify how many custom validators can run concurrently. Defaults to 5.\n  --max-fetch-concurrency <number> Specify how many \\`client.fetch\\` requests are allow concurrency at once. Defaults to 25.\n\nExamples\n  # Validates all documents in a Sanity project with more than one workspace\n  sanity documents validate --workspace default\n\n  # Override the dataset specified in the workspace\n  sanity documents validate --workspace default --dataset staging\n\n  # Save the results of the report into a file\n  sanity documents validate --yes > report.txt\n\n  # Report out info level validation markers too\n  sanity documents validate --level info\n`\n\nconst validateDocumentsCommand: CliCommandDefinition = {\n  name: 'validate',\n  group: 'documents',\n  signature: '',\n  description,\n  helpText,\n  action: async (args, context) => {\n    const mod = await import('../../actions/validation/validateAction')\n\n    return mod.default(args, context)\n  },\n} satisfies CliCommandDefinition\n\nexport default validateDocumentsCommand\n","import {type CliCommandDefinition} from '@sanity/cli'\n\nconst helpText = `\nOptions\n  --with-user-token Prime access token from CLI config into getCliClient()\n  --mock-browser-env Mocks a browser-like environment using jsdom\n\nExamples\n  # Run the script at some/script.js in Sanity context\n  sanity exec some/script.js\n\n  # Run the script at migrations/fullname.ts and configure \\`getCliClient()\\`\n  # from \\`sanity/cli\\`to include the current user's token\n  sanity exec migrations/fullname.ts --with-user-token\n\n  # Run the script at scripts/browserScript.js in a mock browser environment\n  sanity exec scripts/browserScript.js --mock-browser-env\n\n  # Pass arbitrary arguments to scripts by separating them with a \\`--\\`.\n  # Arguments are available in \\`process.argv\\` as they would in regular node scripts\n  # eg the following command would yield a \\`process.argv\\` of:\n  # ['/path/to/node', '/path/to/myscript.js', '--dry-run', 'positional-argument']\n  sanity exec --mock-browser-env myscript.js -- --dry-run positional-argument\n`\n\nexport const execCommand: CliCommandDefinition = {\n  name: 'exec',\n  signature: 'SCRIPT',\n  description: 'Executes a script within the Sanity Studio context',\n  helpText,\n  action: async (args, context) => {\n    const mod = await import('../../actions/exec/execScript')\n\n    return mod.default(args, context)\n  },\n}\n\nexport default execCommand\n","import {\n  type CliCommandArguments,\n  type CliCommandContext,\n  type CliCommandDefinition,\n} from '@sanity/cli'\n\nimport {type DeleteGraphQLApiFlags} from '../../actions/graphql/deleteApiAction'\n\nconst helpText = `\nOptions\n  --api <api-id> Undeploy API with this ID (project, dataset and tag flags takes preference)\n  --project <projectId> Project ID to delete GraphQL API for\n  --dataset <dataset> Delete GraphQL API for the given dataset\n  --tag <tag> Delete GraphQL API for the given tag (defaults to 'default')\n  --force Skip confirmation prompt, forcefully undeploying the GraphQL API\n\nExamples\n  sanity graphql undeploy\n  sanity graphql undeploy --api ios\n  sanity graphql undeploy --dataset staging\n  sanity graphql undeploy --dataset staging --tag next\n`\n\nconst deleteGraphQLAPICommand: CliCommandDefinition = {\n  name: 'undeploy',\n  group: 'graphql',\n  signature: '',\n  description: 'Remove a deployed GraphQL API',\n  action: async (args: CliCommandArguments<DeleteGraphQLApiFlags>, context: CliCommandContext) => {\n    const mod = await import('../../actions/graphql/deleteApiAction')\n\n    return mod.default(args, context)\n  },\n  helpText,\n}\n\nexport default deleteGraphQLAPICommand\n","import {type CliCommandContext, type CliCommandDefinition} from '@sanity/cli'\n\nconst helpText = `\nOptions\n  --dry-run Validate defined APIs, exiting with an error on breaking changes\n  --force Deploy API without confirming breaking changes\n  --api <api-id> Only deploy API with this ID. Can be specified multiple times.\n\nThe following options will override any setting from the CLI configuration file\n(sanity.cli.js/sanity.cli.ts) - and applies to ALL defined APIs defined in that\nconfiguration file. Tread with caution!\n\n  --tag Deploy API(s) to given tag (defaults to 'default')\n  --dataset <name> Deploy API for the given dataset\n  --generation <gen1|gen2|gen3> API generation to deploy (defaults to 'gen3')\n  --non-null-document-fields Use non-null document fields (_id, _type etc)\n  --playground Enable GraphQL playground for easier debugging\n  --no-playground Disable GraphQL playground\n  --with-union-cache *Experimental:* Enable union cache that optimizes schema generation for schemas with many self referencing types\n\nExamples\n  # Deploy all defined GraphQL APIs\n  sanity graphql deploy\n\n  # Validate defined GraphQL APIs, check for breaking changes, skip deploy\n  sanity graphql deploy --dry-run\n\n  # Deploy only the GraphQL APIs with the IDs \"staging\" and \"ios\"\n  sanity graphql deploy --api staging --api ios\n\n  # Deploy all defined GraphQL APIs, overriding any playground setting\n  sanity graphql deploy --playground\n`\n\nconst deployGraphQLAPICommand: CliCommandDefinition = {\n  name: 'deploy',\n  signature: '',\n  group: 'graphql',\n  description: 'Deploy a GraphQL API from the current Sanity schema',\n  action: async (args: {argv?: string[]}, context: CliCommandContext) => {\n    const mod = await import('../../actions/graphql/deployApiAction')\n\n    return mod.default(args, context)\n  },\n  helpText,\n}\n\nexport default deployGraphQLAPICommand\n","import {type CliCommandGroupDefinition} from '@sanity/cli'\n\nconst graphqlGroup: CliCommandGroupDefinition = {\n  name: 'graphql',\n  signature: '[COMMAND]',\n  isGroupRoot: true,\n  description: \"Deploys changes to your project's GraphQL API(s)\",\n}\n\nexport default graphqlGroup\n","import {\n  type CliCommandArguments,\n  type CliCommandContext,\n  type CliCommandDefinition,\n} from '@sanity/cli'\n\nconst helpText = `\nExamples\n  sanity graphql list\n`\n\nconst listGraphQLAPIsCommand: CliCommandDefinition = {\n  name: 'list',\n  signature: '',\n  group: 'graphql',\n  description: 'Lists all the GraphQL endpoints deployed for this project',\n  action: async (\n    args: CliCommandArguments<Record<string, unknown>>,\n    context: CliCommandContext,\n  ) => {\n    const mod = await import('../../actions/graphql/listApisAction')\n\n    return mod.default(args, context)\n  },\n  helpText,\n}\n\nexport default listGraphQLAPIsCommand\n","import {type CliCommandDefinition} from '@sanity/cli'\nimport open from 'open'\n\nconst createHookCommand: CliCommandDefinition = {\n  name: 'create',\n  group: 'hook',\n  signature: '',\n  helpText: '',\n  description: 'Create a new hook for the given dataset',\n  action: async (args, context) => {\n    const {apiClient, output} = context\n    const client = apiClient()\n\n    const {projectId} = client.config()\n    if (!projectId) {\n      throw new Error('No project ID found')\n    }\n\n    const projectInfo = (await client.projects.getById(projectId)) || {}\n    const organizationId = projectInfo.organizationId || 'personal'\n    const manageUrl = `https://www.sanity.io/organizations/${organizationId}/project/${projectId}/api/webhooks/new`\n\n    output.print(`Opening ${manageUrl}`)\n    open(manageUrl)\n  },\n}\n\nexport default createHookCommand\n","import {type CliCommandContext, type CliCommandDefinition} from '@sanity/cli'\n\nimport {type Hook} from './types'\n\nconst deleteHookCommand: CliCommandDefinition = {\n  name: 'delete',\n  group: 'hook',\n  signature: '[NAME]',\n  helpText: '',\n  description: 'Delete a hook within your project',\n  action: async (args, context) => {\n    const {apiClient} = context\n    const [name] = args.argsWithoutOptions\n    const client = apiClient()\n\n    const hookId = await promptForHook(name, context)\n    try {\n      await client\n        .clone()\n        .config({apiVersion: '2021-10-04'})\n        .request({method: 'DELETE', uri: `/hooks/${hookId}`})\n    } catch (err) {\n      throw new Error(`Hook deletion failed:\\n${err.message}`)\n    }\n  },\n}\n\nasync function promptForHook(specified: string | undefined, context: CliCommandContext) {\n  const specifiedName = specified && specified.toLowerCase()\n  const {prompt, apiClient} = context\n  const client = apiClient()\n\n  const hooks = await client\n    .clone()\n    .config({apiVersion: '2021-10-04'})\n    .request<Hook[]>({uri: '/hooks', json: true})\n\n  if (specifiedName) {\n    const selected = hooks.filter((hook) => hook.name.toLowerCase() === specifiedName)[0]\n    if (!selected) {\n      throw new Error(`Hook with name \"${specified} not found\"`)\n    }\n\n    return selected.id\n  }\n\n  const choices = hooks.map((hook) => ({value: hook.id, name: hook.name}))\n  return prompt.single({\n    message: 'Select hook to delete',\n    type: 'list',\n    choices,\n  })\n}\n\nexport default deleteHookCommand\n","import {type CliCommandGroupDefinition} from '@sanity/cli'\n\nconst hookGroup: CliCommandGroupDefinition = {\n  name: 'hook',\n  signature: '[COMMAND]',\n  isGroupRoot: true,\n  description: 'Sets up and manages webhooks within your Sanity project',\n}\n\nexport default hookGroup\n","import {type CliCommandDefinition} from '@sanity/cli'\n\nimport {type DeliveryAttempt} from './types'\n\nconst printHookAttemptCommand: CliCommandDefinition = {\n  name: 'attempt',\n  group: 'hook',\n  signature: 'ATTEMPT_ID',\n  helpText: '',\n  description: 'Print details of a given webhook delivery attempt',\n  action: async (args, context) => {\n    const {apiClient, output} = context\n    const [attemptId] = args.argsWithoutOptions\n    const client = apiClient()\n\n    let attempt\n    try {\n      attempt = await client.request<DeliveryAttempt>({uri: `/hooks/attempts/${attemptId}`})\n    } catch (err) {\n      throw new Error(`Hook attempt retrieval failed:\\n${err.message}`)\n    }\n\n    const {createdAt, resultCode, resultBody, failureReason, inProgress} = attempt\n\n    output.print(`Date: ${createdAt}`)\n    output.print(`Status: ${getStatus(attempt)}`)\n    output.print(`Status code: ${resultCode}`)\n\n    if (attempt.isFailure) {\n      output.print(`Failure: ${formatFailure(attempt)}`)\n    }\n\n    if (!inProgress && (!failureReason || failureReason === 'http')) {\n      const body = resultBody ? `\\n---\\n${resultBody}\\n---\\n` : '<empty>'\n      output.print(`Response body: ${body}`)\n    }\n  },\n}\n\nexport default printHookAttemptCommand\n\nexport function formatFailure(\n  attempt: DeliveryAttempt,\n  options: {includeHelp?: boolean} = {},\n): string {\n  const {includeHelp} = options\n  const {id, failureReason, resultCode} = attempt\n  const help = includeHelp ? `(run \\`sanity hook attempt ${id}\\` for details)` : ''\n  switch (failureReason) {\n    case 'http':\n      return `HTTP ${resultCode} ${help}`\n    case 'timeout':\n      return 'Request timed out'\n    case 'network':\n      return 'Network error'\n    case 'other':\n    default:\n  }\n\n  return 'Unknown error'\n}\n\nexport function getStatus(attempt: DeliveryAttempt): string {\n  if (attempt.isFailure) {\n    return 'Failed'\n  }\n\n  if (attempt.inProgress) {\n    return 'In progress'\n  }\n\n  return 'Delivered'\n}\n","import {inspect} from 'node:util'\n\nimport {type CliCommandContext, type CliCommandDefinition} from '@sanity/cli'\nimport {groupBy} from 'lodash'\n\nimport {formatFailure} from './printHookAttemptCommand'\nimport {type DeliveryAttempt, type Hook, type HookMessage} from './types'\n\ninterface ListHookFlags {\n  detailed?: boolean\n}\n\nconst listHookLogsCommand: CliCommandDefinition<ListHookFlags> = {\n  name: 'logs',\n  group: 'hook',\n  signature: '[NAME]',\n  helpText: '',\n  description: 'List latest log entries for a given hook',\n  action: async (args, context) => {\n    const {apiClient} = context\n    const flags = args.extOptions\n    const [name] = args.argsWithoutOptions\n    const client = apiClient()\n\n    const hookId = await promptForHook(name, context)\n    let messages\n    let attempts\n    try {\n      messages = await client.request<HookMessage[]>({uri: `/hooks/${hookId}/messages`})\n      attempts = await client.request<DeliveryAttempt[]>({uri: `/hooks/${hookId}/attempts`})\n    } catch (err) {\n      throw new Error(`Hook logs retrieval failed:\\n${err.message}`)\n    }\n\n    const groupedAttempts = groupBy(attempts, 'messageId')\n    const populated = messages.map((msg): HookMessage & {attempts: DeliveryAttempt[]} => ({\n      ...msg,\n      attempts: groupedAttempts[msg.id],\n    }))\n\n    const totalMessages = messages.length - 1\n    populated.forEach((message, i) => {\n      printMessage(message, context, {detailed: flags.detailed})\n      printSeparator(context, totalMessages === i)\n    })\n  },\n}\n\nexport default listHookLogsCommand\n\nasync function promptForHook(specified: string | undefined, context: CliCommandContext) {\n  const specifiedName = specified && specified.toLowerCase()\n  const {prompt, apiClient} = context\n  const client = apiClient()\n\n  const hooks = await client\n    .clone()\n    .config({apiVersion: '2021-10-04'})\n    .request<Hook[]>({uri: '/hooks', json: true})\n\n  if (specifiedName) {\n    const selected = hooks.filter((hook) => hook.name.toLowerCase() === specifiedName)[0]\n    if (!selected) {\n      throw new Error(`Hook with name \"${specified} not found\"`)\n    }\n\n    return selected.id\n  }\n\n  if (hooks.length === 0) {\n    throw new Error('No hooks currently registered')\n  }\n\n  if (hooks.length === 1) {\n    return hooks[0].id\n  }\n\n  const choices = hooks.map((hook) => ({value: hook.id, name: hook.name}))\n  return prompt.single({\n    message: 'Select hook to list logs for',\n    type: 'list',\n    choices,\n  })\n}\n\nfunction printSeparator(context: CliCommandContext, skip: boolean) {\n  if (!skip) {\n    context.output.print('---\\n')\n  }\n}\n\nfunction printMessage(\n  message: HookMessage & {attempts: DeliveryAttempt[]},\n  context: CliCommandContext,\n  options: {detailed?: boolean},\n) {\n  const {detailed} = options\n  const {output, chalk} = context\n\n  output.print(`Date: ${message.createdAt}`)\n  output.print(`Status: ${message.status}`)\n  output.print(`Result code: ${message.resultCode}`)\n\n  if (message.failureCount > 0) {\n    output.print(`Failures: ${message.failureCount}`)\n  }\n\n  if (detailed) {\n    output.print('Payload:')\n    output.print(inspect(JSON.parse(message.payload), {colors: true}))\n  }\n\n  if (detailed && message.attempts) {\n    output.print('Attempts:')\n    message.attempts.forEach((attempt) => {\n      const date = attempt.createdAt.replace(/\\.\\d+Z$/, 'Z')\n      const prefix = `  [${date}]`\n\n      if (attempt.inProgress) {\n        output.print(`${prefix} ${chalk.yellow('Pending')}`)\n      } else if (attempt.isFailure) {\n        const failure = formatFailure(attempt, {includeHelp: true})\n        output.print(`${prefix} ${chalk.yellow(`Failure: ${failure}`)}`)\n      } else {\n        output.print(`${prefix} Success: HTTP ${attempt.resultCode} (${attempt.duration}ms)`)\n      }\n    })\n  }\n\n  // Leave some empty space between messages\n  output.print('')\n}\n","import {type CliCommandDefinition} from '@sanity/cli'\n\nimport {type Hook} from './types'\n\nconst listHooksCommand: CliCommandDefinition = {\n  name: 'list',\n  group: 'hook',\n  signature: '',\n  helpText: '',\n  description: 'List hooks for a given project',\n  action: async (args, context) => {\n    const {apiClient, output} = context\n    const client = apiClient()\n\n    let hooks\n    try {\n      hooks = await client\n        .clone()\n        .config({apiVersion: '2021-10-04'})\n        .request<Hook[]>({uri: '/hooks'})\n    } catch (err) {\n      throw new Error(`Hook list retrieval failed:\\n${err.message}`)\n    }\n\n    hooks.forEach((hook) => {\n      output.print(`Name: ${hook.name}`)\n      output.print(`Dataset: ${hook.dataset}`)\n      output.print(`URL: ${hook.url}`)\n\n      if (hook.type === 'document') {\n        output.print(`HTTP method: ${hook.httpMethod}`)\n\n        if (hook.description) {\n          output.print(`Description: ${hook.description}`)\n        }\n      }\n\n      output.print('')\n    })\n  },\n}\n\nexport default listHooksCommand\n","import {type CliCommandDefinition} from '@sanity/cli'\n\nconst description = 'Extracts the studio configuration as one or more JSON manifest files.'\n\nconst helpText = `\n**Note**: This command is experimental and subject to change. It is currently intended for use with Create only.\n\nOptions\n  --path Optional path to specify destination directory of the manifest files. Default: /dist/static\n\nExamples\n  # Extracts manifests\n  sanity manifest extract\n\n  # Extracts manifests into /public/static\n  sanity manifest extract --path /public/static\n`\n\nconst extractManifestCommand: CliCommandDefinition = {\n  name: 'extract',\n  group: 'manifest',\n  signature: '',\n  description,\n  helpText,\n  action: async (args, context) => {\n    const {extractManifestSafe} = await import('../../actions/manifest/extractManifestAction')\n    const extractError = await extractManifestSafe(args, context)\n    if (extractError) {\n      throw extractError\n    }\n    return extractError\n  },\n}\n\nexport default extractManifestCommand\n","export default {\n  name: 'manifest',\n  signature: '[COMMAND]',\n  isGroupRoot: true,\n  description: 'Interacts with the studio configuration.',\n}\n","export const MIGRATIONS_DIRECTORY = 'migrations'\nexport const MIGRATION_SCRIPT_EXTENSIONS = ['mjs', 'js', 'ts', 'cjs']\nexport const DEFAULT_API_VERSION = 'v2024-01-29'\n","export const minimalAdvanced = ({\n  migrationName,\n  documentTypes,\n}: {\n  migrationName: string\n  documentTypes: string[]\n}) => `import {defineMigration, patch, at, setIfMissing} from 'sanity/migrate'\n\n/**\n * this migration will set \\`Default title\\` on all documents that are missing a title\n * and make \\`true\\` the default value for the \\`enabled\\` field\n */\nexport default defineMigration({\n  title: '${migrationName}',\n${\n  documentTypes.length > 0\n    ? `  documentTypes: [${documentTypes.map((t) => JSON.stringify(t)).join(', ')}],\\n`\n    : ''\n}\n  async *migrate(documents, context) {\n    for await (const document of documents()) {\n      yield patch(document._id, [\n        at('title', setIfMissing('Default title')),\n        at('enabled', setIfMissing(true)),\n      ])\n    }\n  }\n})\n`\n","export const minimalSimple = ({\n  migrationName,\n  documentTypes,\n}: {\n  migrationName: string\n  documentTypes: string[]\n}) => `import {at, defineMigration, setIfMissing, unset} from 'sanity/migrate'\n\nexport default defineMigration({\n  title: '${migrationName}',\n${\n  documentTypes.length > 0\n    ? `  documentTypes: [${documentTypes.map((t) => JSON.stringify(t)).join(', ')}],\\n`\n    : ''\n}\n  migrate: {\n    document(doc, context) {\n      // this will be called for every document of the matching type\n      // any patch returned will be applied to the document\n      // you can also return mutations that touches other documents\n\n      return at('title', setIfMissing('Default title'))\n    },\n    node(node, path, context) {\n      // this will be called for every node in every document of the matching type\n      // any patch returned will be applied to the document\n      // you can also return mutations that touches other documents\n\n      if (typeof node === 'string' && node === 'deleteme') {\n        return unset()\n      }\n    },\n    object(node, path, context) {\n      // this will be called for every object node in every document of the matching type\n      // any patch returned will be applied to the document\n      // you can also return mutations that touches other documents\n      if (node._type === 'author') {\n        // make sure all authors objects have a books array\n        return at('books', setIfMissing([]))\n      }\n    },\n    array(node, path, context) {\n      // this will be called for every array node in every document of the matching type\n      // any patch returned will be applied to the document\n      // you can also return mutations that touches other documents\n    },\n    string(node, path, context) {\n      // this will be called for every string node in every document of the matching type\n      // any patch returned will be applied to the document\n      // you can also return mutations that touches other documents\n    },\n    number(node, path, context) {\n      // this will be called for every number node in every document of the matching type\n      // any patch returned will be applied to the document\n      // you can also return mutations that touches other documents\n    },\n    boolean(node, path, context) {\n      // this will be called for every boolean node in every document of the matching type\n      // any patch returned will be applied to the document\n      // you can also return mutations that touches other documents\n    },\n    null(node, path, context) {\n      // this will be called for every null node in every document of the matching type\n      // any patch returned will be applied to the document\n      // you can also return mutations that touches other documents\n    },\n  },\n})\n`\n","export const renameField = ({\n  migrationName,\n  documentTypes,\n}: {\n  migrationName: string\n  documentTypes: string[]\n}) => `import {defineMigration, at, setIfMissing, unset} from 'sanity/migrate'\n\nconst from = 'oldFieldName'\nconst to = 'newFieldName'\n\nexport default defineMigration({\n  title: '${migrationName}',\n${\n  documentTypes.length > 0\n    ? `  documentTypes: [${documentTypes.map((t) => JSON.stringify(t)).join(', ')}],\\n`\n    : ''\n}\n  migrate: {\n    document(doc, context) {\n      return [\n        at(to, setIfMissing(doc[from])),\n        at(from, unset())\n      ]\n    }\n  }\n})\n`\n","export const renameType = ({\n  migrationName,\n  documentTypes,\n}: {\n  migrationName: string\n  documentTypes: string[]\n}) => `import {defineMigration, at, set} from 'sanity/migrate'\n\nconst oldType = 'old'\nconst newType = 'new'\n\nexport default defineMigration({\n  title: '${migrationName}',\n${\n  documentTypes.length > 0\n    ? `  documentTypes: [${documentTypes.map((t) => JSON.stringify(t)).join(', ')}],\\n`\n    : ''\n}\n  migrate: {\n    object(object, path, context) {\n      if (object._type === oldType) {\n        return at('_type', set(newType))\n      }\n    }\n  }\n})\n`\n","export const stringToPTE = ({\n  migrationName,\n  documentTypes,\n}: {\n  migrationName: string\n  documentTypes: string[]\n}) => `import {pathsAreEqual, stringToPath} from 'sanity'\nimport {defineMigration, set} from 'sanity/migrate'\n\nconst targetPath = stringToPath('some.path')\n\nexport default defineMigration({\n  title: '${migrationName}',\n${\n  documentTypes.length > 0\n    ? `  documentTypes: [${documentTypes.map((t) => JSON.stringify(t)).join(', ')}],\\n`\n    : ''\n}\n  migrate: {\n    string(node, path, ctx) {\n      if (pathsAreEqual(path, targetPath)) {\n        return set([\n          {\n            style: 'normal',\n            _type: 'block',\n            children: [\n              {\n                _type: 'span',\n                marks: [],\n                text: node,\n              },\n            ],\n            markDefs: [],\n          },\n        ])\n      }\n    },\n  },\n})\n`\n","import {existsSync, mkdirSync} from 'node:fs'\nimport {writeFile} from 'node:fs/promises'\nimport path from 'node:path'\n\nimport {type CliCommandDefinition} from '@sanity/cli'\nimport {deburr} from 'lodash'\n\nimport {MIGRATIONS_DIRECTORY} from './constants'\nimport {minimalAdvanced} from './templates/minimalAdvanced'\nimport {minimalSimple} from './templates/minimalSimple'\nimport {renameField} from './templates/renameField'\nimport {renameType} from './templates/renameType'\nimport {stringToPTE} from './templates/stringToPTE'\n\nconst helpText = `\nExamples:\n  # Create a new migration, prompting for title and options\n  sanity migration create\n\n  # Create a new migration with the provided title, prompting for options\n  sanity migration create \"Rename field from location to address\"\n`\n\n// eslint-disable-next-line @typescript-eslint/no-empty-interface\ninterface CreateMigrationFlags {}\n\nconst TEMPLATES = [\n  {name: 'Minimalistic migration to get you started', template: minimalSimple},\n  {name: 'Rename an object type', template: renameType},\n  {name: 'Rename a field', template: renameField},\n  {name: 'Convert string field to Portable Text', template: stringToPTE},\n  {\n    name: 'Advanced template using async iterators providing more fine grained control',\n    template: minimalAdvanced,\n  },\n]\n\nconst createMigrationCommand: CliCommandDefinition<CreateMigrationFlags> = {\n  name: 'create',\n  group: 'migration',\n  signature: '[TITLE]',\n  helpText,\n  description: 'Create a new migration within your project',\n  action: async (args, context) => {\n    const {output, prompt, workDir, chalk} = context\n\n    let [title] = args.argsWithoutOptions\n\n    while (!title?.trim()) {\n      title = await prompt.single({\n        type: 'input',\n        suffix: ' (e.g. \"Rename field from location to address\")',\n        message: 'Title of migration',\n      })\n      if (!title.trim()) {\n        output.error(chalk.red('Name cannot be empty'))\n      }\n    }\n    const types = await prompt.single({\n      type: 'input',\n      suffix: ' (optional)',\n      message: 'Type of documents to migrate. You can add multiple types separated by comma',\n    })\n\n    const templatesByName = Object.fromEntries(TEMPLATES.map((t) => [t.name, t]))\n    const template = await prompt.single({\n      type: 'list',\n      message: 'Select a template',\n      choices: TEMPLATES.map((definedTemplate) => ({\n        name: definedTemplate.name,\n        value: definedTemplate.name,\n      })),\n    })\n\n    const sluggedName = deburr(title.toLowerCase())\n      .replace(/\\s+/g, '-')\n      .replace(/[^a-z0-9-]/g, '')\n\n    const destDir = path.join(workDir, MIGRATIONS_DIRECTORY, sluggedName)\n    if (existsSync(destDir)) {\n      if (\n        !(await prompt.single({\n          type: 'confirm',\n          message: `Migration directory ${chalk.cyan(destDir)} already exists. Overwrite?`,\n          default: false,\n        }))\n      ) {\n        return\n      }\n    }\n    mkdirSync(destDir, {recursive: true})\n\n    const renderedTemplate = (templatesByName[template].template || minimalSimple)({\n      migrationName: title,\n      documentTypes: types\n        .split(',')\n        .map((t) => t.trim())\n        .filter(Boolean),\n    })\n\n    const definitionFile = path.join(destDir, 'index.ts')\n\n    await writeFile(definitionFile, renderedTemplate)\n    // To dry run it, run \\`sanity migration run ${sluggedName}\\``)\n    output.print()\n    output.print(`${chalk.green('✓')} Migration created!`)\n    output.print()\n    output.print('Next steps:')\n    output.print(\n      `Open ${chalk.bold(\n        definitionFile,\n      )} in your code editor and write the code for your migration.`,\n    )\n    output.print(\n      `Dry run the migration with:\\n\\`${chalk.bold(\n        `sanity migration run ${sluggedName} --project=<projectId> --dataset <dataset> `,\n      )}\\``,\n    )\n    output.print(\n      `Run the migration against a dataset with:\\n \\`${chalk.bold(\n        `sanity migration run ${sluggedName} --project=<projectId> --dataset <dataset> --no-dry-run`,\n      )}\\``,\n    )\n    output.print()\n    output.print(\n      `👉 Learn more about schema and content migrations at ${chalk.bold(\n        'https://www.sanity.io/docs/schema-and-content-migrations',\n      )}`,\n    )\n  },\n}\nexport default createMigrationCommand\n","import path from 'node:path'\n\nimport {type Migration} from '@sanity/migrate'\nimport {isPlainObject} from 'lodash'\n\nimport {MIGRATION_SCRIPT_EXTENSIONS, MIGRATIONS_DIRECTORY} from '../constants'\n\ninterface ResolvedMigrationScript {\n  /**\n   * Relative path from the working directory to the migration script\n   */\n  relativePath: string\n\n  /**\n   * Absolute path to the migration script\n   */\n  absolutePath: string\n\n  /**\n   * The migration module, if it could be resolved - otherwise `undefined`\n   */\n  mod?: {default: Migration; up?: unknown; down?: unknown}\n}\n\n/**\n * Resolves the potential paths to a migration script.\n * Considers the following paths (where `<ext>` is 'mjs', 'js', 'ts' or 'cjs'):\n *\n * - `<migrationsDir>/<migrationName>.<ext>`\n * - `<migrationsDir>/<migrationName>/index.<ext>`\n *\n * Note that all possible paths are returned, even if the files do not exist.\n * Check the `mod` property to see if a module could actually be loaded.\n *\n * @param workDir - Working directory of the studio\n * @param migrationName - The name of the migration directory to resolve\n * @returns An array of potential migration scripts\n * @internal\n */\nexport function resolveMigrationScript(\n  workDir: string,\n  migrationName: string,\n): ResolvedMigrationScript[] {\n  return [migrationName, path.join(migrationName, 'index')].flatMap((location) =>\n    MIGRATION_SCRIPT_EXTENSIONS.map((ext) => {\n      const relativePath = path.join(MIGRATIONS_DIRECTORY, `${location}.${ext}`)\n      const absolutePath = path.resolve(workDir, relativePath)\n      let mod\n      try {\n        // eslint-disable-next-line import/no-dynamic-require\n        mod = require(absolutePath)\n      } catch (err) {\n        if (err.code !== 'MODULE_NOT_FOUND') {\n          throw new Error(`Error: ${err.message}\"`)\n        }\n      }\n      return {relativePath, absolutePath, mod}\n    }),\n  )\n}\n\n/**\n * Checks whether or not the passed resolved migration script is actually loadable (eg has a default export)\n *\n * @param script - The resolved migration script to check\n * @returns `true` if the script is loadable, `false` otherwise\n * @internal\n */\nexport function isLoadableMigrationScript(\n  script: ResolvedMigrationScript,\n): script is Required<ResolvedMigrationScript> {\n  if (typeof script.mod === 'undefined' || !isPlainObject(script.mod.default)) {\n    return false\n  }\n\n  const mod = script.mod.default\n  return typeof mod.title === 'string' && mod.migrate !== undefined\n}\n","import {readdir} from 'node:fs/promises'\nimport path from 'node:path'\n\nimport {type CliCommandDefinition} from '@sanity/cli'\nimport {type Migration} from '@sanity/migrate'\nimport {Table} from 'console-table-printer'\nimport {register} from 'esbuild-register/dist/node'\n\nimport {MIGRATION_SCRIPT_EXTENSIONS, MIGRATIONS_DIRECTORY} from './constants'\nimport {isLoadableMigrationScript, resolveMigrationScript} from './utils/resolveMigrationScript'\n\nconst helpText = ``\n\nconst listMigrationCommand: CliCommandDefinition = {\n  name: 'list',\n  group: 'migration',\n  signature: '',\n  helpText,\n  description: 'List available migrations',\n  action: async (_, context) => {\n    const {workDir, output, chalk} = context\n    try {\n      const migrations = await resolveMigrations(workDir)\n\n      if (migrations.length === 0) {\n        output.print('No migrations found in migrations folder of the project')\n        output.print(\n          `\\nRun ${chalk.green(`\\`sanity migration create <NAME>\\``)} to create a new migration`,\n        )\n        return\n      }\n\n      const table = new Table({\n        title: `Found ${migrations.length} migrations in project`,\n        columns: [\n          {name: 'id', title: 'ID', alignment: 'left'},\n          {name: 'title', title: 'Title', alignment: 'left'},\n        ],\n      })\n\n      migrations.forEach((definedMigration) => {\n        table.addRow({id: definedMigration.id, title: definedMigration.migration.title})\n      })\n      table.printTable()\n      output.print('\\nRun `sanity migration run <ID>` to run a migration')\n    } catch (error) {\n      if (error.code === 'ENOENT') {\n        output.print('No migrations folder found in the project')\n        output.print(\n          `\\nRun ${chalk.green(`\\`sanity migration create <NAME>\\``)} to create a new migration`,\n        )\n        return\n      }\n      throw new Error(`An error occurred while listing migrations: ${error.message}`)\n    }\n  },\n}\n\n/**\n * A resolved migration, where you are guaranteed that the migration file exists\n *\n * @internal\n */\nexport interface ResolvedMigration {\n  id: string\n  migration: Migration\n}\n\n/**\n * Resolves all migrations in the studio working directory\n *\n * @param workDir - The studio working directory\n * @returns Array of migrations and their respective paths\n * @internal\n */\nexport async function resolveMigrations(workDir: string): Promise<ResolvedMigration[]> {\n  let unregister\n  if (!__DEV__) {\n    unregister = register({\n      target: `node${process.version.slice(1)}`,\n      supported: {'dynamic-import': true},\n    }).unregister\n  }\n\n  const migrationsDir = path.join(workDir, MIGRATIONS_DIRECTORY)\n  const migrationEntries = await readdir(migrationsDir, {withFileTypes: true})\n\n  const migrations: ResolvedMigration[] = []\n  for (const entry of migrationEntries) {\n    const entryName = entry.isDirectory() ? entry.name : removeMigrationScriptExtension(entry.name)\n    const candidates = resolveMigrationScript(workDir, entryName).filter(isLoadableMigrationScript)\n\n    for (const candidate of candidates) {\n      migrations.push({\n        id: entryName,\n        migration: candidate.mod.default,\n      })\n    }\n  }\n\n  if (unregister) {\n    unregister()\n  }\n\n  return migrations\n}\n\nfunction removeMigrationScriptExtension(fileName: string) {\n  // Remove `.ts`, `.js` etc from the end of a filename\n  return MIGRATION_SCRIPT_EXTENSIONS.reduce(\n    (name, ext) => (name.endsWith(`.${ext}`) ? path.basename(name, `.${ext}`) : name),\n    fileName,\n  )\n}\n\nexport default listMigrationCommand\n","export default {\n  name: 'migration',\n  signature: '[COMMAND]',\n  isGroupRoot: true,\n  description: 'Manages content migrations for Content Lake datasets',\n}\n","import {isIndexSegment, isIndexTuple, isKeySegment, type Path} from '@sanity/types'\n\n// FIXME: de-dupe this\n// copy/paste of `pathToString` from 'sanity' to prevent circular imports\nfunction pathToString(path: Path): string {\n  if (!Array.isArray(path)) {\n    throw new Error('Path is not an array')\n  }\n\n  return path.reduce<string>((target, segment, i) => {\n    if (isIndexSegment(segment)) {\n      return `${target}[${segment}]`\n    }\n\n    if (isKeySegment(segment) && segment._key) {\n      return `${target}[_key==\"${segment._key}\"]`\n    }\n\n    if (isIndexTuple(segment)) {\n      const [from, to] = segment\n      return `${target}[${from}:${to}]`\n    }\n\n    if (typeof segment === 'string') {\n      const separator = i === 0 ? '' : '.'\n      return `${target}${separator}${segment}`\n    }\n\n    throw new Error(`Unsupported path segment \\`${JSON.stringify(segment)}\\``)\n  }, '')\n}\n\ninterface BaseNode {\n  path: Path\n}\n\nexport interface Tree<Node extends BaseNode> {\n  nodes?: Node[]\n  children?: Record<string, Tree<Node>>\n}\n\n/**\n * Recursively calculates the max length of all the keys in the given validation\n * tree respecting extra length due to indentation depth. Used to calculate the\n * padding for the rest of the tree.\n */\nexport const maxKeyLength = (children: Record<string, Tree<BaseNode>> = {}, depth = 0): number => {\n  return Object.entries(children)\n    .map(([key, child]) =>\n      Math.max(key.length + depth * 2, maxKeyLength(child.children, depth + 1)),\n    )\n    .reduce((max, next) => (next > max ? next : max), 0)\n}\n\ninterface Options<Node extends BaseNode> {\n  node?: Record<string, Tree<Node>>\n  paddingLength: number\n  indent?: string\n  getNodes?: (node: Tree<Node>) => Node[] | undefined\n  getMessage: (node: Node) => string\n}\n\n/**\n * Recursively formats a given tree into a printed user-friendly tree structure\n */\nexport const formatTree = <Node extends BaseNode>({\n  node = {},\n  paddingLength,\n  indent = '',\n  getNodes: getLeaves = ({nodes}) => nodes,\n  getMessage,\n}: Options<Node>): string => {\n  const entries = Object.entries(node)\n\n  return entries\n    .map(([key, child], index) => {\n      const isLast = index === entries.length - 1\n      const nextIndent = `${indent}${isLast ? '  ' : '│ '}`\n      const leaves = getLeaves(child)\n\n      const nested = formatTree({\n        node: child.children,\n        paddingLength,\n        indent: nextIndent,\n        getNodes: getLeaves,\n        getMessage,\n      })\n\n      if (!leaves?.length) {\n        const current = `${indent}${isLast ? '└' : '├'}─ ${key}`\n        return [current, nested].filter(Boolean).join('\\n')\n      }\n\n      const [first, ...rest] = leaves\n      const firstPadding = '.'.repeat(paddingLength - indent.length - key.length)\n      const elbow = isLast ? '└' : '├'\n      const subsequentPadding = ' '.repeat(paddingLength - indent.length + 2)\n\n      const firstMessage = `${indent}${elbow}─ ${key} ${firstPadding} ${getMessage(first)}`\n      const subsequentMessages = rest\n        .map((marker) => `${nextIndent}${subsequentPadding} ${getMessage(marker)}`)\n        .join('\\n')\n\n      const current = [firstMessage, subsequentMessages].filter(Boolean).join('\\n')\n      return [current, nested].filter(Boolean).join('\\n')\n    })\n    .join('\\n')\n}\n\n/**\n * Converts a set of markers with paths into a tree of markers where the paths\n * are embedded in the tree\n */\nexport function convertToTree<const Node extends BaseNode>(nodes: Node[]): Tree<Node> {\n  const root: Tree<Node> = {}\n\n  // add the markers to the tree\n  function addNode(node: Node, tree: Tree<Node> = root) {\n    // if we've traversed the whole path\n    if (!node.path.length) {\n      if (!tree.nodes) tree.nodes = [] // ensure markers is defined\n\n      // then add the marker to the front\n      tree.nodes.push(node)\n      return\n    }\n\n    const [current, ...rest] = node.path\n    const key = pathToString([current])\n\n    // ensure the current node has children and the next node\n    if (!tree.children) tree.children = {}\n    if (!(key in tree.children)) tree.children[key] = {}\n\n    addNode({...node, path: rest}, tree.children[key])\n  }\n\n  for (const node of nodes) addNode(node)\n  return root\n}\n","import {isatty} from 'node:tty'\n\nimport {type Migration, type Mutation, type NodePatch, type Transaction} from '@sanity/migrate'\nimport {type KeyedSegment} from '@sanity/types'\nimport {type Chalk} from 'chalk'\n\nimport {convertToTree, formatTree, maxKeyLength} from '../../util/tree'\n\ntype ItemRef = string | number\ntype Impact = 'destructive' | 'maybeDestructive' | 'incremental'\ntype Variant = Impact | 'info'\n\nconst isTty = isatty(1)\n\ninterface FormatterOptions<Subject> {\n  chalk: Chalk\n  subject: Subject\n  migration: Migration\n  indentSize?: number\n}\n\nexport function prettyFormat({\n  chalk,\n  subject,\n  migration,\n  indentSize = 0,\n}: FormatterOptions<Mutation | Transaction | (Mutation | Transaction)[]>): string {\n  return (Array.isArray(subject) ? subject : [subject])\n    .map((subjectEntry) => {\n      if (subjectEntry.type === 'transaction') {\n        return [\n          [\n            badge('transaction', 'info', chalk),\n            typeof subjectEntry.id === 'undefined' ? null : chalk.underline(subjectEntry.id),\n          ]\n            .filter(Boolean)\n            .join(' '),\n          indent(\n            prettyFormat({\n              chalk,\n              subject: subjectEntry.mutations,\n              migration,\n              indentSize: indentSize,\n            }),\n          ),\n        ].join('\\n\\n')\n      }\n      return prettyFormatMutation({\n        chalk,\n        subject: subjectEntry,\n        migration,\n        indentSize,\n      })\n    })\n    .join('\\n\\n')\n}\n\nfunction encodeItemRef(ref: number | KeyedSegment): ItemRef {\n  return typeof ref === 'number' ? ref : ref._key\n}\n\nfunction badgeStyle(chalk: Chalk, variant: Variant): Chalk {\n  const styles: Record<Variant, Chalk> = {\n    info: chalk.bgWhite.black,\n    incremental: chalk.bgGreen.black.bold,\n    maybeDestructive: chalk.bgYellow.black.bold,\n    destructive: chalk.bgRed.black.bold,\n  }\n\n  return styles[variant]\n}\n\nfunction badge(label: string, variant: Variant, chalk: Chalk): string {\n  if (!isTty) {\n    return `[${label}]`\n  }\n\n  return badgeStyle(chalk, variant)(` ${label} `)\n}\n\nconst mutationImpact: Record<Mutation['type'], Impact> = {\n  create: 'incremental',\n  createIfNotExists: 'incremental',\n  createOrReplace: 'maybeDestructive',\n  delete: 'destructive',\n  patch: 'maybeDestructive',\n}\n\nfunction documentId(mutation: Mutation): string | undefined {\n  if ('id' in mutation) {\n    return mutation.id\n  }\n\n  if ('document' in mutation) {\n    return mutation.document._id\n  }\n\n  return undefined\n}\n\nconst listFormatter = new Intl.ListFormat('en-US', {\n  type: 'disjunction',\n})\n\nfunction mutationHeader(chalk: Chalk, mutation: Mutation, migration: Migration): string {\n  const mutationType = badge(mutation.type, mutationImpact[mutation.type], chalk)\n\n  const documentType =\n    'document' in mutation || migration.documentTypes\n      ? badge(\n          'document' in mutation\n            ? mutation.document._type\n            : listFormatter.format(migration.documentTypes ?? []),\n          'info',\n          chalk,\n        )\n      : null\n\n  // TODO: Should we list documentType when a mutation can be yielded for any document type?\n  return [mutationType, documentType, chalk.underline(documentId(mutation))]\n    .filter(Boolean)\n    .join(' ')\n}\n\nexport function prettyFormatMutation({\n  chalk,\n  subject,\n  migration,\n  indentSize = 0,\n}: FormatterOptions<Mutation>): string {\n  const lock =\n    'options' in subject ? chalk.cyan(`(if revision==${subject.options?.ifRevision})`) : ''\n  const header = [mutationHeader(chalk, subject, migration), lock].join(' ')\n  const padding = ' '.repeat(indentSize)\n\n  if (\n    subject.type === 'create' ||\n    subject.type === 'createIfNotExists' ||\n    subject.type === 'createOrReplace'\n  ) {\n    return [header, '\\n', indent(JSON.stringify(subject.document, null, 2), indentSize)].join('')\n  }\n\n  if (subject.type === 'patch') {\n    const tree = convertToTree<NodePatch>(subject.patches.flat())\n    const paddingLength = Math.max(maxKeyLength(tree.children) + 2, 30)\n\n    return [\n      header,\n      '\\n',\n      formatTree<NodePatch>({\n        node: tree.children,\n        paddingLength,\n        indent: padding,\n        getMessage: (patch) => formatPatchMutation(chalk, patch),\n      }),\n    ].join('')\n  }\n\n  return header\n}\n\nfunction formatPatchMutation(chalk: Chalk, patch: NodePatch): string {\n  const {op} = patch\n  const formattedType = chalk.bold(op.type)\n  if (op.type === 'unset') {\n    return `${chalk.red(formattedType)}()`\n  }\n  if (op.type === 'diffMatchPatch') {\n    return `${chalk.yellow(formattedType)}(${op.value})`\n  }\n  if (op.type === 'inc' || op.type === 'dec') {\n    return `${chalk.yellow(formattedType)}(${op.amount})`\n  }\n  if (op.type === 'set') {\n    return `${chalk.yellow(formattedType)}(${JSON.stringify(op.value)})`\n  }\n  if (op.type === 'setIfMissing') {\n    return `${chalk.green(formattedType)}(${JSON.stringify(op.value)})`\n  }\n  if (op.type === 'insert') {\n    return `${chalk.green(formattedType)}(${op.position}, ${encodeItemRef(\n      op.referenceItem,\n    )}, ${JSON.stringify(op.items)})`\n  }\n  if (op.type === 'replace') {\n    return `${chalk.yellow(formattedType)}(${encodeItemRef(op.referenceItem)}, ${JSON.stringify(\n      op.items,\n    )})`\n  }\n  if (op.type === 'truncate') {\n    return `${chalk.red(formattedType)}(${op.startIndex}, ${op.endIndex})`\n  }\n  // @ts-expect-error all cases are covered\n  throw new Error(`Invalid operation type: ${op.type}`)\n}\n\nfunction indent(subject: string, size = 2): string {\n  const padding = ' '.repeat(size)\n\n  return subject\n    .split('\\n')\n    .map((line) => padding + line)\n    .join('\\n')\n}\n","import {type APIConfig} from '@sanity/migrate'\n\ntype ApiVersion = APIConfig['apiVersion']\n\nconst VERSION_PATTERN = /^v\\d+-\\d+-\\d+$|^vX$/ // Matches version strings like vYYYY-MM-DD or vX\n\n/**\n * Ensures that the provided API version string is in the correct format.\n * If the version does not start with 'v', it will be prefixed with 'v'.\n * If the version does not match the expected pattern, an error will be thrown.\n */\nexport function ensureApiVersionFormat(version: string): ApiVersion {\n  const normalizedVersion = version.startsWith('v') ? version : `v${version}`\n\n  // Check if the version matches the expected pattern\n  if (!VERSION_PATTERN.test(normalizedVersion)) {\n    throw new Error(\n      `Invalid API version format: ${normalizedVersion}. Expected format: vYYYY-MM-DD or vX`,\n    )\n  }\n\n  return normalizedVersion as ApiVersion\n}\n","import path from 'node:path'\n\nimport {type CliCommandDefinition} from '@sanity/cli'\nimport {\n  DEFAULT_MUTATION_CONCURRENCY,\n  dryRun,\n  MAX_MUTATION_CONCURRENCY,\n  type Migration,\n  type MigrationProgress,\n  run,\n} from '@sanity/migrate'\nimport {Table} from 'console-table-printer'\nimport {register} from 'esbuild-register/dist/node'\nimport {hideBin} from 'yargs/helpers'\nimport yargs from 'yargs/yargs'\n\nimport {debug} from '../../debug'\nimport {DEFAULT_API_VERSION, MIGRATIONS_DIRECTORY} from './constants'\nimport {resolveMigrations} from './listMigrationsCommand'\nimport {prettyFormat} from './prettyMutationFormatter'\nimport {ensureApiVersionFormat} from './utils/ensureApiVersionFormat'\nimport {isLoadableMigrationScript, resolveMigrationScript} from './utils/resolveMigrationScript'\n\nconst helpText = `\nOptions\n  --no-dry-run By default the migration runs in dry mode. Pass this option to migrate dataset.\n  --concurrency <concurrent> How many mutation requests to run in parallel. Must be between 1 and ${MAX_MUTATION_CONCURRENCY}. Default: ${DEFAULT_MUTATION_CONCURRENCY}.\n  --no-progress Don't output progress. Useful if you want debug your migration script and see the output of console.log() statements.\n  --dataset <dataset> Dataset to migrate. Defaults to the dataset configured in your Sanity CLI config.\n  --project <project id> Project ID of the dataset to migrate. Defaults to the projectId configured in your Sanity CLI config.\n  --api-version <version> API version to use when migrating. Defaults to ${DEFAULT_API_VERSION}.\n  --no-confirm Skip the confirmation prompt before running the migration. Make sure you know what you're doing before using this flag.\n  --from-export <export.tar.gz> Use a local dataset export as source for migration instead of calling the Sanity API. Note: this is only supported for dry runs.\n\n\nExamples\n  # dry run the migration\n  sanity migration run <id>\n\n  # execute the migration against a dataset\n  sanity migration run <id> --no-dry-run --project xyz --dataset staging\n\n  # execute the migration using a dataset export as the source\n  sanity migration run <id>  --from-export=production.tar.gz --no-dry-run --projectId xyz --dataset staging\n`\n\ninterface CreateFlags {\n  ['dry-run']?: boolean\n  concurrency?: number\n  ['from-export']?: string\n  progress?: boolean\n  dataset?: string\n  project?: string\n  confirm?: boolean\n}\n\nfunction parseCliFlags(args: {argv?: string[]}) {\n  return yargs(hideBin(args.argv || process.argv).slice(2))\n    .options('dry-run', {type: 'boolean', default: true})\n    .options('concurrency', {type: 'number', default: DEFAULT_MUTATION_CONCURRENCY})\n    .options('progress', {type: 'boolean', default: true})\n    .options('dataset', {type: 'string'})\n    .options('from-export', {type: 'string'})\n    .options('project', {type: 'string'})\n    .options('api-version', {type: 'string'})\n    .options('confirm', {type: 'boolean', default: true}).argv\n}\n\nconst runMigrationCommand: CliCommandDefinition<CreateFlags> = {\n  name: 'run',\n  group: 'migration',\n  signature: 'ID',\n  helpText,\n  description: 'Run a migration against a dataset',\n  // eslint-disable-next-line max-statements\n  action: async (args, context) => {\n    const {apiClient, output, prompt, chalk, workDir} = context\n    const [id] = args.argsWithoutOptions\n    const migrationsDirectoryPath = path.join(workDir, MIGRATIONS_DIRECTORY)\n\n    const flags = await parseCliFlags(args)\n\n    const fromExport = flags.fromExport\n    const dry = flags.dryRun\n    const dataset = flags.dataset\n    const project = flags.project\n    const apiVersion = flags.apiVersion\n\n    if ((dataset && !project) || (project && !dataset)) {\n      throw new Error('If either --dataset or --project is provided, both must be provided')\n    }\n\n    if (!id) {\n      output.error(chalk.red('Error: Migration ID must be provided'))\n      const migrations = await resolveMigrations(workDir)\n      const table = new Table({\n        title: `Migrations found in project`,\n        columns: [\n          {name: 'id', title: 'ID', alignment: 'left'},\n          {name: 'title', title: 'Title', alignment: 'left'},\n        ],\n      })\n\n      migrations.forEach((definedMigration) => {\n        table.addRow({id: definedMigration.id, title: definedMigration.migration.title})\n      })\n      table.printTable()\n      output.print('\\nRun `sanity migration run <ID>` to run a migration')\n\n      return\n    }\n\n    if (!__DEV__) {\n      register({\n        target: `node${process.version.slice(1)}`,\n        supported: {'dynamic-import': true},\n      })\n    }\n\n    const candidates = resolveMigrationScript(workDir, id)\n    const resolvedScripts = candidates.filter(isLoadableMigrationScript)\n\n    if (resolvedScripts.length > 1) {\n      // todo: consider prompt user about which one to run? note: it's likely a mistake if multiple files resolve to the same name\n      throw new Error(\n        `Found multiple migrations for \"${id}\" in ${chalk.cyan(migrationsDirectoryPath)}: \\n - ${candidates\n          .map((candidate) => path.relative(migrationsDirectoryPath, candidate.absolutePath))\n          .join('\\n - ')}`,\n      )\n    }\n\n    const script = resolvedScripts[0]\n    if (!script) {\n      throw new Error(\n        `No migration found for \"${id}\" in ${chalk.cyan(chalk.cyan(migrationsDirectoryPath))}. Make sure that the migration file exists and exports a valid migration as its default export.\\n\n Tried the following files:\\n - ${candidates\n   .map((candidate) => path.relative(migrationsDirectoryPath, candidate.absolutePath))\n   .join('\\n - ')}`,\n      )\n    }\n\n    const mod = script.mod\n    if ('up' in mod || 'down' in mod) {\n      // todo: consider adding support for up/down as separate named exports\n      // For now, make sure we reserve the names for future use\n      throw new Error(\n        'Only \"up\" migrations are supported at this time, please use a default export',\n      )\n    }\n\n    const migration: Migration = mod.default\n\n    if (fromExport && !dry) {\n      throw new Error('Can only dry run migrations from a dataset export file')\n    }\n\n    const concurrency = flags.concurrency\n    if (concurrency !== undefined) {\n      if (concurrency > MAX_MUTATION_CONCURRENCY) {\n        throw new Error(\n          `Concurrency exceeds the maximum allowed value of ${MAX_MUTATION_CONCURRENCY}`,\n        )\n      }\n\n      if (concurrency === 0) {\n        throw new Error(`Concurrency must be a positive number, got ${concurrency}`)\n      }\n    }\n\n    const projectConfig = apiClient({\n      requireUser: true,\n      requireProject: false,\n    }).config()\n\n    if (!project && !projectConfig.projectId) {\n      throw new Error(\n        'sanity.cli.js does not contain a project identifier (\"api.projectId\") and no --project option was provided.',\n      )\n    }\n\n    const apiConfig = {\n      dataset: dataset ?? projectConfig.dataset!,\n      projectId: project ?? projectConfig.projectId!,\n      apiHost: projectConfig.apiHost!,\n      token: projectConfig.token!,\n      apiVersion: ensureApiVersionFormat(apiVersion ?? DEFAULT_API_VERSION),\n    } as const\n    if (dry) {\n      dryRunHandler()\n      return\n    }\n\n    output.print(\n      `\\n${chalk.yellow(chalk.bold('Note: During migrations, your webhooks stay active.'))}`,\n    )\n    output.print(\n      `To adjust them, launch the management interface with ${chalk.cyan('sanity manage')}, navigate to the API settings, and toggle the webhooks before and after the migration as needed.\\n`,\n    )\n\n    if (flags.confirm) {\n      const response = await prompt.single<boolean>({\n        message: `This migration will run on the ${chalk.yellow(\n          chalk.bold(apiConfig.dataset),\n        )} dataset in ${chalk.yellow(chalk.bold(apiConfig.projectId))} project. Are you sure?`,\n        type: 'confirm',\n      })\n\n      if (!response) {\n        debug('User aborted migration')\n        return\n      }\n    }\n\n    const spinner = output.spinner(`Running migration \"${id}\"`).start()\n    await run({api: apiConfig, concurrency, onProgress: createProgress(spinner)}, migration)\n    spinner.stop()\n\n    function createProgress(progressSpinner: ReturnType<typeof output.spinner>) {\n      return function onProgress(progress: MigrationProgress) {\n        if (!flags.progress) {\n          progressSpinner.stop()\n          return\n        }\n        if (progress.done) {\n          progressSpinner.text = `Migration \"${id}\" completed.\n\n  Project id:  ${chalk.bold(apiConfig.projectId)}\n  Dataset:     ${chalk.bold(apiConfig.dataset)}\n\n  ${progress.documents} documents processed.\n  ${progress.mutations} mutations generated.\n  ${chalk.green(progress.completedTransactions.length)} transactions committed.`\n          progressSpinner.stopAndPersist({symbol: chalk.green('✔')})\n          return\n        }\n\n        ;[null, ...progress.currentTransactions].forEach((transaction) => {\n          progressSpinner.text = `Running migration \"${id}\" ${dry ? 'in dry mode...' : '...'}\n\n  Project id:     ${chalk.bold(apiConfig.projectId)}\n  Dataset:        ${chalk.bold(apiConfig.dataset)}\n  Document type:  ${chalk.bold(migration.documentTypes?.join(','))}\n\n  ${progress.documents} documents processed…\n  ${progress.mutations} mutations generated…\n  ${chalk.blue(progress.pending)} requests pending…\n  ${chalk.green(progress.completedTransactions.length)} transactions committed.\n\n  ${\n    transaction && !progress.done\n      ? `» ${prettyFormat({chalk, subject: transaction, migration, indentSize: 2})}`\n      : ''\n  }`\n        })\n      }\n    }\n\n    async function dryRunHandler() {\n      output.print(`Running migration \"${id}\" in dry mode`)\n\n      if (fromExport) {\n        output.print(`Using export ${chalk.cyan(fromExport)}`)\n      }\n\n      output.print()\n      output.print(`Project id:  ${chalk.bold(apiConfig.projectId)}`)\n      output.print(`Dataset:     ${chalk.bold(apiConfig.dataset)}`)\n\n      for await (const mutation of dryRun({api: apiConfig, exportPath: fromExport}, migration)) {\n        if (!mutation) continue\n        output.print()\n        output.print(\n          prettyFormat({\n            chalk,\n            subject: mutation,\n            migration,\n          }),\n        )\n      }\n    }\n  },\n}\n\nexport default runMigrationCommand\n","import {\n  type CliCommandArguments,\n  type CliCommandContext,\n  type CliCommandDefinition,\n} from '@sanity/cli'\n\nimport {type StartPreviewServerCommandFlags} from '../../actions/preview/previewAction'\n\nconst helpText = `\nNotes\n  Changing the hostname or port number might require a new entry to the CORS-origins allow list.\n\nOptions\n  --port <port> TCP port to start server on. [default: 3333]\n  --host <host> The local network interface at which to listen. [default: \"127.0.0.1\"]\n\nExamples\n  sanity preview --host=0.0.0.0\n  sanity preview --port=1942\n  sanity preview some/build-output-dir\n`\n\nconst previewCommand: CliCommandDefinition = {\n  name: 'preview',\n  signature: '[BUILD_OUTPUT_DIR] [--port <port>] [--host <host>]',\n  description: 'Starts a server to preview a production build of Sanity Studio',\n  action: async (\n    args: CliCommandArguments<StartPreviewServerCommandFlags>,\n    context: CliCommandContext,\n  ) => {\n    const previewAction = await getPreviewAction()\n\n    return previewAction(args, context)\n  },\n  helpText,\n}\n\nasync function getPreviewAction() {\n  // NOTE: in dev-mode we want to include from `src` so we need to use `.ts` extension\n  // NOTE: this `if` statement is not included in the output bundle\n  if (__DEV__) {\n    // eslint-disable-next-line import/extensions,@typescript-eslint/consistent-type-imports\n    const mod: typeof import('../../actions/preview/previewAction') = require('../../actions/preview/previewAction.ts')\n\n    return mod.default\n  }\n\n  const mod = await import('../../actions/preview/previewAction')\n\n  return mod.default\n}\n\nexport default previewCommand\n","import {type CliCommandDefinition} from '@sanity/cli'\n\nconst description = 'Extracts a JSON representation of a Sanity schema within a Studio context.'\n\nconst helpText = `\n**Note**: This command is experimental and subject to change.\n\nOptions\n  --workspace <name> The name of the workspace to generate a schema for\n  --path Optional path to specify destination of the schema file\n  --enforce-required-fields Makes the schema generated treat fields marked as required as non-optional. Defaults to false.\n  --format=[groq-type-nodes] Format the schema as GROQ type nodes. Only available format at the moment.\n\nExamples\n  # Extracts schema types in a Sanity project with more than one workspace\n  sanity schema extract --workspace default\n`\n\nconst extractSchemaCommand: CliCommandDefinition = {\n  name: 'extract',\n  group: 'schema',\n  signature: '',\n  description,\n  helpText,\n  action: async (args, context) => {\n    const mod = await import('../../actions/schema/extractAction')\n\n    return mod.default(args, context)\n  },\n} satisfies CliCommandDefinition\n\nexport default extractSchemaCommand\n","export default {\n  name: 'schema',\n  signature: '[COMMAND]',\n  isGroupRoot: true,\n  description: 'Interacts with Sanity Studio schema configurations',\n}\n","import {type CliCommandDefinition} from '@sanity/cli'\n\nconst description = 'Validates all schema types specified in a workspace.'\n\nconst helpText = `\nOptions\n  --workspace <name> The name of the workspace to use when validating all schema types.\n  --format <pretty|ndjson|json> The output format used to print schema errors and warnings.\n  --level <error|warning> The minimum level reported out. Defaults to warning.\n\nExamples\n  # Validates all schema types in a Sanity project with more than one workspace\n  sanity schema validate --workspace default\n\n  # Save the results of the report into a file\n  sanity schema validate > report.txt\n\n  # Report out only errors\n  sanity schema validate --level error\n`\n\nconst validateDocumentsCommand: CliCommandDefinition = {\n  name: 'validate',\n  group: 'schema',\n  signature: '',\n  description,\n  helpText,\n  action: async (args, context) => {\n    const mod = await import('../../actions/schema/validateAction')\n\n    return mod.default(args, context)\n  },\n} satisfies CliCommandDefinition\n\nexport default validateDocumentsCommand\n","/* eslint-disable no-process-env */\nexport const isInteractive =\n  process.stdout.isTTY && process.env.TERM !== 'dumb' && !('CI' in process.env)\n","import {\n  type CliCommandArguments,\n  type CliCommandContext,\n  type CliCommandDefinition,\n} from '@sanity/cli'\n\nimport {type StartPreviewServerCommandFlags} from '../../actions/preview/previewAction'\nimport {isInteractive} from '../../util/isInteractive'\nimport {getDevAction} from '../dev/devCommand'\n\nconst helpText = `\nNotes\n  Changing the hostname or port number might require a new CORS-entry to be added.\n\nOptions\n  --port <port> TCP port to start server on. [default: 3333]\n  --host <host> The local network interface at which to listen. [default: \"127.0.0.1\"]\n\nExamples\n  sanity start --host=0.0.0.0\n  sanity start --port=1942\n  sanity start some/build-output-dir\n`\n\nconst startCommand: CliCommandDefinition = {\n  name: 'start',\n  signature: '[BUILD_OUTPUT_DIR] [--port <port>] [--host <host>]',\n  description: 'Alias for `sanity preview`',\n  action: async (\n    args: CliCommandArguments<StartPreviewServerCommandFlags>,\n    context: CliCommandContext,\n  ) => {\n    const {output, chalk, prompt} = context\n    const previewAction = await getPreviewAction()\n\n    const warn = (msg: string) => output.warn(chalk.yellow.bgBlack(msg))\n    const error = (msg: string) => output.warn(chalk.red.bgBlack(msg))\n    warn('╭───────────────────────────────────────────────────────────╮')\n    warn('│                                                           │')\n    warn(\"│  You're running Sanity Studio v3. In this version the     │\")\n    warn('│  [start] command is used to preview static builds.        |')\n    warn('│                                                           │')\n    warn('│  To run a development server, use the [npm run dev] or    |')\n    warn('│  [npx sanity dev] command instead. For more information,  │')\n    warn('│  see https://www.sanity.io/help/studio-v2-vs-v3           │')\n    warn('│                                                           │')\n    warn('╰───────────────────────────────────────────────────────────╯')\n    warn('') // Newline to separate from other output\n\n    try {\n      await previewAction(args, context)\n    } catch (err) {\n      if (err.name !== 'BUILD_NOT_FOUND') {\n        throw err\n      }\n\n      error(err.message)\n      error('\\n')\n\n      const shouldRunDevServer =\n        isInteractive &&\n        (await prompt.single({\n          message: 'Do you want to start a development server instead?',\n          type: 'confirm',\n        }))\n\n      if (shouldRunDevServer) {\n        const devAction = await getDevAction(context)\n        await devAction(args, context)\n      } else {\n        // Indicate that this isn't an expected exit\n        // eslint-disable-next-line no-process-exit\n        process.exit(1)\n      }\n    }\n  },\n  helpText,\n}\n\nasync function getPreviewAction() {\n  // NOTE: in dev-mode we want to include from `src` so we need to use `.ts` extension\n  // NOTE: this `if` statement is not included in the output bundle\n  if (__DEV__) {\n    // eslint-disable-next-line import/extensions,@typescript-eslint/consistent-type-imports\n    const mod: typeof import('../../actions/preview/previewAction') = require('../../actions/preview/previewAction.ts')\n\n    return mod.default\n  }\n\n  const mod = await import('../../actions/preview/previewAction')\n\n  return mod.default\n}\n\nexport default startCommand\n","export function prettifyQuotaError(message: string) {\n  return (err: Error & {statusCode?: number}): Error & {statusCode?: number} => {\n    if (err.statusCode === 402) {\n      err.message = message\n      throw err\n    }\n\n    throw err\n  }\n}\n","import {type CliCommandDefinition, type CliPrompter} from '@sanity/cli'\n\nimport {prettifyQuotaError} from '../../util/prettifyQuotaError'\nimport {type Role} from './types'\n\nconst helpText = `\nOptions\n  --role Role to invite the user as\n\nExamples\n  # Invite a new user to the project (prompt for details)\n  sanity users invite\n\n  # Send a new user invite to the email \"pippi@sanity.io\", prompt for role\n  sanity users invite pippi@sanity.io\n\n  # Send a new user invite to the email \"pippi@sanity.io\", as administrator\n  sanity users invite pippi@sanity.io --role administrator\n`\n\ninterface InviteFlags {\n  role?: string\n}\n\nconst inviteUserCommand: CliCommandDefinition<InviteFlags> = {\n  name: 'invite',\n  group: 'users',\n  signature: '[EMAIL]',\n  helpText,\n  description: 'Invite a new user to the project',\n  action: async (args, context) => {\n    const {apiClient, output, prompt} = context\n    const [selectedEmail] = args.argsWithoutOptions\n    const flags = args.extOptions\n\n    const client = apiClient().clone().config({useProjectHostname: false, apiVersion: '2021-06-07'})\n    const {projectId} = client.config()\n    const roles = (await client.request<Role[]>({uri: `/projects/${projectId}/roles`})).filter(\n      (role) => role.appliesToUsers,\n    )\n    const email = selectedEmail || (await promptForEmail(prompt))\n    const selectedRole = flags.role || (await promptForRole(prompt, roles))\n    const role = roles.find(({name}) => name.toLowerCase() === selectedRole.toLowerCase())\n    if (!role) {\n      throw new Error(`Role name \"${selectedRole}\" not found`)\n    }\n\n    await client\n      .clone()\n      .request({\n        method: 'POST',\n        uri: `/invitations/project/${projectId}`,\n        body: {email, role: role.name},\n        useGlobalApi: true,\n        maxRedirects: 0,\n      })\n      .catch(\n        prettifyQuotaError(\n          'Project is already at user quota, add billing details to the project in order to allow overage charges.',\n        ),\n      )\n\n    output.print(`Invitation sent to ${email}`)\n  },\n}\n\nexport default inviteUserCommand\n\nfunction promptForEmail(prompt: CliPrompter): Promise<string> {\n  return prompt.single({\n    type: 'input',\n    message: 'Email to invite:',\n    filter: (val) => val.trim(),\n    validate: (name) => {\n      if (!name || !name.includes('@')) {\n        return 'Invalid email'\n      }\n\n      return true\n    },\n  })\n}\n\nfunction promptForRole(prompt: CliPrompter, roles: Role[]): Promise<string> {\n  return prompt.single({\n    type: 'list',\n    message: 'Which role should the user have?',\n    choices: roles.map((role) => ({\n      value: role.name,\n      name: `${role.title} (${role.description})`,\n    })),\n  })\n}\n","import {type CliCommandDefinition} from '@sanity/cli'\nimport {size, sortBy} from 'lodash'\n\nimport {type Invite, type PartialProjectResponse, type User} from './types'\n\nconst sortFields = ['id', 'name', 'role', 'date']\n\nconst helpText = `\nOptions\n  --no-invitations Don't include pending invitations\n  --no-robots Don't include robots (token users)\n  --sort <field> Sort users by specified column: ${sortFields.join(', ')}\n  --order <asc/desc> Sort output ascending/descending\n\nExamples\n  # List all users of the project\n  sanity users list\n\n  # List all users of the project, but exclude pending invitations and robots\n  sanity users list --no-invitations --no-robots\n\n  # List all users, sorted by role\n  sanity users list --sort role\n`\n\nconst listUsersCommand: CliCommandDefinition = {\n  name: 'list',\n  group: 'users',\n  signature: '',\n  helpText,\n  description: 'List all users of the project',\n  action: async (args, context) => {\n    const {apiClient, output, chalk} = context\n    const {sort, order, robots, invitations} = {\n      sort: 'date',\n      order: 'asc',\n      robots: true,\n      invitations: true,\n      ...args.extOptions,\n    }\n\n    if (!sortFields.includes(sort)) {\n      throw new Error(`Can't sort by field \"${sort}\". Must be one of ${sortFields.join(', ')}`)\n    }\n\n    if (order !== 'asc' && order !== 'desc') {\n      throw new Error(`Unknown sort order \"${order}\", must be either \"asc\" or \"desc\"`)\n    }\n\n    const client = apiClient()\n    const globalClient = client.clone().config({useProjectHostname: false})\n    const {projectId} = client.config()\n\n    const useGlobalApi = true\n    const [pendingInvitations, project] = await Promise.all([\n      invitations\n        ? globalClient\n            .request<Invite[]>({uri: `/invitations/project/${projectId}`, useGlobalApi})\n            .then(getPendingInvitations)\n        : [],\n      globalClient.request<PartialProjectResponse>({uri: `/projects/${projectId}`, useGlobalApi}),\n    ])\n\n    const memberIds = project.members.map((member) => member.id)\n    const users = await globalClient\n      .request<User | User[]>({uri: `/users/${memberIds.join(',')}`, useGlobalApi})\n      .then((user) => (Array.isArray(user) ? user : [user]))\n\n    const projectMembers = project.members\n      .map((member) => ({\n        ...member,\n        ...getUserProps(users.find((candidate) => candidate.id === member.id)),\n      }))\n      .filter((member) => !member.isRobot || robots)\n\n    const members = [...projectMembers, ...pendingInvitations]\n\n    const ordered = sortBy(\n      members.map(({id, name, role, date}) => [id, name, role, date]),\n      [sortFields.indexOf(sort)],\n    )\n\n    const rows = order === 'asc' ? ordered : ordered.reverse()\n\n    const maxWidths = rows.reduce(\n      (max, row) => row.map((current, index) => Math.max(size(current), max[index])),\n      sortFields.map((str) => size(str)),\n    )\n\n    const printRow = (row: string[]) => {\n      const isInvite = row[0] === '<pending>'\n      const textRow = row.map((col, i) => `${col}`.padEnd(maxWidths[i])).join('   ')\n      return isInvite ? chalk.dim(textRow) : textRow\n    }\n\n    output.print(chalk.cyan(printRow(sortFields)))\n    rows.forEach((row) => output.print(printRow(row)))\n  },\n}\n\nfunction getUserProps(user: User | undefined) {\n  const {displayName: name, createdAt: date} = user || {}\n  return {name: name || '', date: date || ''}\n}\n\nfunction getPendingInvitations(invitations: Invite[]) {\n  return invitations\n    .filter((invite) => !invite.isAccepted && !invite.isRevoked && !invite.acceptedByUserId)\n    .map((invite) => ({\n      id: '<pending>',\n      name: invite.email,\n      role: invite.role,\n      date: invite.createdAt,\n    }))\n}\n\nexport default listUsersCommand\n","import {type CliCommandGroupDefinition} from '@sanity/cli'\n\nexport const usersGroup: CliCommandGroupDefinition = {\n  name: 'users',\n  signature: '[COMMAND]',\n  isGroupRoot: true,\n  description: 'Manages users of your Sanity project',\n}\n\nexport default usersGroup\n","import {type CliCommandDefinition, type CliCommandGroupDefinition} from '@sanity/cli'\n\nimport backupGroup from './backup/backupGroup'\nimport disableBackupCommand from './backup/disableBackupCommand'\nimport downloadBackupCommand from './backup/downloadBackupCommand'\nimport enableBackupCommand from './backup/enableBackupCommand'\nimport listBackupCommand from './backup/listBackupCommand'\nimport buildCommand from './build/buildCommand'\nimport addCorsOriginCommand from './cors/addCorsOriginCommand'\nimport corsGroup from './cors/corsGroup'\nimport deleteCorsOriginCommand from './cors/deleteCorsOriginCommand'\nimport listCorsOriginsCommand from './cors/listCorsOriginsCommand'\nimport aliasDatasetCommand from './dataset/alias/aliasCommands'\nimport copyDatasetCommand from './dataset/copyDatasetCommand'\nimport createDatasetCommand from './dataset/createDatasetCommand'\nimport datasetGroup from './dataset/datasetGroup'\nimport datasetVisibilityCommand from './dataset/datasetVisibilityCommand'\nimport deleteDatasetCommand from './dataset/deleteDatasetCommand'\nimport exportDatasetCommand from './dataset/exportDatasetCommand'\nimport importDatasetCommand from './dataset/importDatasetCommand'\nimport listDatasetsCommand from './dataset/listDatasetsCommand'\nimport deployCommand from './deploy/deployCommand'\nimport undeployCommand from './deploy/undeployCommand'\nimport devCommand from './dev/devCommand'\nimport createDocumentsCommand from './documents/createDocumentsCommand'\nimport deleteDocumentsCommand from './documents/deleteDocumentsCommand'\nimport documentsGroup from './documents/documentsGroup'\nimport getDocumentsCommand from './documents/getDocumentsCommand'\nimport queryDocumentsCommand from './documents/queryDocumentsCommand'\nimport validateDocumentsCommand from './documents/validateDocumentsCommand'\nimport execCommand from './exec/execCommand'\nimport deleteGraphQLAPICommand from './graphql/deleteGraphQLAPICommand'\nimport deployGraphQLAPICommand from './graphql/deployGraphQLAPICommand'\nimport graphqlGroup from './graphql/graphqlGroup'\nimport listGraphQLAPIsCommand from './graphql/listGraphQLAPIsCommand'\nimport createHookCommand from './hook/createHookCommand'\nimport deleteHookCommand from './hook/deleteHookCommand'\nimport hookGroup from './hook/hookGroup'\nimport listHookLogsCommand from './hook/listHookLogsCommand'\nimport listHooksCommand from './hook/listHooksCommand'\nimport printHookAttemptCommand from './hook/printHookAttemptCommand'\nimport extractManifestCommand from './manifest/extractManifestCommand'\nimport manifestGroup from './manifest/manifestGroup'\nimport createMigrationCommand from './migration/createMigrationCommand'\nimport listMigrationsCommand from './migration/listMigrationsCommand'\nimport migrationGroup from './migration/migrationGroup'\nimport runMigrationCommand from './migration/runMigrationCommand'\nimport previewCommand from './preview/previewCommand'\nimport extractSchemaCommand from './schema/extractSchemaCommand'\nimport schemaGroup from './schema/schemaGroup'\nimport validateSchemaCommand from './schema/validateSchemaCommand'\nimport startCommand from './start/startCommand'\nimport inviteUserCommand from './users/inviteUserCommand'\nimport listUsersCommand from './users/listUsersCommand'\nimport usersGroup from './users/usersGroup'\n\nconst commands: (CliCommandDefinition | CliCommandGroupDefinition)[] = [\n  buildCommand,\n  datasetGroup,\n  deployCommand,\n  undeployCommand,\n  listDatasetsCommand,\n  createDatasetCommand,\n  datasetVisibilityCommand,\n  exportDatasetCommand,\n  importDatasetCommand,\n  deleteDatasetCommand,\n  copyDatasetCommand,\n  aliasDatasetCommand,\n  backupGroup,\n  listBackupCommand,\n  downloadBackupCommand,\n  disableBackupCommand,\n  enableBackupCommand,\n  corsGroup,\n  listCorsOriginsCommand,\n  addCorsOriginCommand,\n  deleteCorsOriginCommand,\n  usersGroup,\n  inviteUserCommand,\n  listUsersCommand,\n  hookGroup,\n  listHooksCommand,\n  createHookCommand,\n  migrationGroup,\n  createMigrationCommand,\n  runMigrationCommand,\n  listMigrationsCommand,\n  deleteHookCommand,\n  listHookLogsCommand,\n  printHookAttemptCommand,\n  documentsGroup,\n  getDocumentsCommand,\n  queryDocumentsCommand,\n  deleteDocumentsCommand,\n  createDocumentsCommand,\n  validateDocumentsCommand,\n  graphqlGroup,\n  listGraphQLAPIsCommand,\n  deployGraphQLAPICommand,\n  deleteGraphQLAPICommand,\n  devCommand,\n  startCommand,\n  schemaGroup,\n  validateSchemaCommand,\n  extractSchemaCommand,\n  previewCommand,\n  execCommand,\n  manifestGroup,\n  extractManifestCommand,\n]\n\n/**\n * @deprecated Not actually deprecated, but these are internals and should not be relied upon outside of the Sanity team\n * @internal\n */\nexport const cliProjectCommands = {\n  requiredCliVersionRange: '^3.0.0',\n  commands,\n}\n"],"names":["defaultApiVersion","datasetBackupGroup","name","signature","description","isGroupRoot","parseApiErr","err","apiErr","code","statusCode","message","statusMessage","response","body","data","JSON","stringify","debug","debugIt","validateDatasetName","datasetName","toLowerCase","length","MAX_DATASET_NAME_LENGTH","test","promptForDatasetName","prompt","options","single","type","validate","chooseDatasetPrompt","context","apiClient","allowCreation","client","datasets","list","hasProduction","find","dataset","datasetChoices","map","value","selected","choices","Separator","newDatasetName","default","undefined","create","resolveApiClient","apiVersion","projectId","token","config","Error","selectedDataset","withConfig","helpText","disableDatasetBackupCommand","group","action","args","output","chalk","argsWithoutOptions","request","method","headers","Authorization","uri","enabled","print","green","error","red","require","archiver","archiveDir","tmpOutDir","outFilePath","progressCb","Promise","resolve","reject","archiveDestination","createWriteStream","on","archive","gzip","gzipOptions","level","zlib","constants","Z_DEFAULT_COMPRESSION","stack","progress","fs","processedBytes","pipe","directory","finalize","maxBackupIdsShown","chooseBackupIdPrompt","query","limit","toString","backups","backupIdChoices","backup","id","cleanupTmpDir","tmpDir","rimraf","MAX_RETRIES","BACKOFF_DELAY_BASE","exponentialBackoff","retryCount","Math","pow","withRetry","operation","maxRetries","retryDelay","setTimeout","CONNECTION_TIMEOUT","READ_TIMEOUT","getIt","keepAlive","promise","downloadAsset","url","fileName","fileType","outDir","normalizedFileName","path","basename","assetFilePath","getAssetFilePath","maxRedirects","timeout","connect","socket","stream","pipeline","join","downloadDocument","PaginatedGetBackupStream","Readable","cursor","totalFiles","constructor","backupId","objectMode","_read","fetchNextBackupPage","files","forEach","file","push","nextCursor","destroy","msg","String","newProgress","startStep","spinner","start","lastProgress","step","Date","now","elapsed","prettyMs","current","total","text","set","succeed","update","fail","humanFileSize","size","i","floor","log","toFixed","isPathDirName","filepath","createDebug","DEFAULT_DOWNLOAD_CONCURRENCY","MAX_DOWNLOAD_CONCURRENCY","parseCliFlags","yargs","hideBin","argv","process","slice","downloadBackupCommand","opts","prepareBackupOptions","outFileName","bold","cyan","padEnd","progressSpinner","mkdtemp","tmpdir","dir","mkdirSync","recursive","tmpOutDocumentsFile","docOutStream","docWriteMutex","Mutex","backupFileStream","totalItemsDownloaded","pMap","doc","runExclusive","write","concurrency","end","finished","flags","workDir","isString","defaultOutFileName","out","absolutify","filter","overwrite","existsSync","dirname","enableDatasetBackupCommand","DEFAULT_LIST_BACKUP_LIMIT","alias","listDatasetBackupCommand","Number","MAX_SAFE_INTEGER","before","after","parsedBefore","processDateFlags","parsedAfter","isAfter","table","Table","columns","title","alignment","createdAt","addRow","resource","lightFormat","parse","printTable","date","parsedDate","isValid","buildCommand","overrides","getBuildAction","wildcardReplacement","portReplacement","addCorsOrigin","givenOrigin","origin","filterAndValidateOrigin","promptForOrigin","hasWildcard","includes","promptForWildcardConfirmation","allowCredentials","credentials","promptForCredentials","Boolean","requireUser","requireProject","oneline","yellow","logSymbols","warning","underline","replace","filterOrigin","validateOrigin","example","parsed","host","protocol","RegExp","result","addCorsOriginCommand","extOptions","cwd","warn","corsGroup","deleteCorsOriginCommand","originId","specified","specifiedOrigin","origins","listCorsOriginsCommand","validateDatasetAliasName","promptForDatasetAliasName","ALIAS_PREFIX","listAliases","createAlias","aliasName","modify","updateAlias","unlinkAlias","removeAlias","createAliasHandler","targetDataset","nameError","aliases","projectFeatures","all","then","sets","ds","aliasClient","aliasOutputName","startsWith","datasetErr","option","deleteAliasHandler","force","dsError","fetchedAliases","linkedAlias","elem","input","trim","linkAliasHandler","da","unlinkAliasHandler","aliasCommand","verb","listDatasetCopyJobs","offset","job","state","updatedAt","sourceDataset","withHistory","timeStarted","formatDistanceToNow","parseISO","timeTaken","formatDistance","color","getClientUrl","useCdn","cdnUrl","Observable","observer","progressSource","EventSource","stopped","onError","close","next","onChannelError","onMessage","event","onComplete","removeEventListener","complete","addEventListener","followProgress","jobId","currentProgress","listenUrl","subscribe","copyDatasetCommand","attach","shouldSkipHistory","existingDatasets","sourceDatasetName","targetDatasetName","skipHistory","detach","allowedModes","createDatasetCommand","visibility","canCreatePrivate","aclMode","promptForDatasetVisibility","mode","datasetVisibilityCommand","edit","curr","deleteDatasetCommand","delete","noop","parseFlags","rawFlags","types","split","assetConcurrency","parseInt","raw","assets","drafts","compress","exportDatasetCommand","targetDestination","destinationPath","outputPath","getOutputPath","currentStep","onProgress","exportDataset","destination","dstPath","isAbsolute","dstStats","stat","catch","looksLikeFile","isFile","indexOf","createPath","mkdir","finalPath","str","toBoolIfSet","flag","allowAssetsInDifferentDataset","allowFailingAssets","replaceAssets","skipCrossDatasetReferences","allowSystemDocuments","missing","importDatasetCommand","fromInitCommand","getMutationOperation","target","determineTargetDataset","isUrl","inputStream","assetsBase","sourceIsFolder","getUrlStream","sourceFile","fileStats","isDirectory","createReadStream","importClient","clone","stepStart","spinInterval","percent","lengthComputable","sameStep","getPercentage","clearInterval","prevStep","prevStepStart","timeSpent","secondsDecimalDigits","setInterval","endTask","success","numDocs","warnings","sanityImport","printWarnings","details","responseBody","padStart","onlyBody","assetFails","bind","listAliasesHandler","listDatasetsCommand","determineIsCoreApp","cliConfig","deployCommand","mod","undeployCommand","devCommand","getDevAction","createDocumentsCommand","watch","useJson5","json5","contentPath","content","readFile","writeDocuments","getResultMessage","docId","uuid","ext","tmpFile","os","defaultValue","getDocument","_id","_type","writeFile","editor","getEditor","registerUnlinkOnSigInt","chokidar","readAndPerformCreatesFromFile","execa","bin","concat","stdio","sync","unlink","filePath","isEqual","writeResult","exit","documents","docs","Array","isArray","mutations","index","validateDocument","isIdentifiedSanityDocument","createIfNotExists","createOrReplace","transaction","commit","arr","isSingle","isPlainObject","getErrorMessage","isSanityDocumentish","joiner","results","res","created","skipped","defaultEditor","platform","env","VISUAL","EDITOR","shift","deleteDocumentsCommand","ids","reduce","trx","deleted","notFound","pluralize","documentsGroup","identity","inp","colorizeJson","formatters","punctuator","white","key","string","number","literal","whitespace","json","tokenize","prevToken","getDocumentsCommand","pretty","project","anonymous","requireDataset","api","baseClient","originalDataset","originalProjectId","fetch","fallbackApiVersion","SANITY_CLI_QUERY_API_VERSION","validateDocumentsCommand","execCommand","deleteGraphQLAPICommand","deployGraphQLAPICommand","graphqlGroup","listGraphQLAPIsCommand","createHookCommand","manageUrl","projects","getById","organizationId","open","deleteHookCommand","hookId","promptForHook","specifiedName","hooks","hook","hookGroup","printHookAttemptCommand","attemptId","attempt","resultCode","resultBody","failureReason","inProgress","getStatus","isFailure","formatFailure","includeHelp","help","listHookLogsCommand","messages","attempts","groupedAttempts","groupBy","populated","totalMessages","printMessage","detailed","printSeparator","skip","status","failureCount","inspect","payload","colors","prefix","failure","duration","listHooksCommand","httpMethod","extractManifestCommand","extractManifestSafe","extractError","MIGRATIONS_DIRECTORY","MIGRATION_SCRIPT_EXTENSIONS","DEFAULT_API_VERSION","minimalAdvanced","migrationName","documentTypes","t","minimalSimple","renameField","renameType","stringToPTE","TEMPLATES","template","createMigrationCommand","suffix","templatesByName","Object","fromEntries","definedTemplate","sluggedName","deburr","destDir","renderedTemplate","definitionFile","resolveMigrationScript","flatMap","location","relativePath","absolutePath","isLoadableMigrationScript","script","migrate","listMigrationCommand","_","migrations","resolveMigrations","definedMigration","migration","unregister","register","version","supported","migrationsDir","migrationEntries","readdir","withFileTypes","entry","entryName","removeMigrationScriptExtension","candidates","candidate","endsWith","pathToString","segment","isIndexSegment","isKeySegment","_key","isIndexTuple","from","to","maxKeyLength","children","depth","entries","child","max","formatTree","node","paddingLength","indent","getNodes","getLeaves","nodes","getMessage","isLast","nextIndent","leaves","nested","first","rest","firstPadding","repeat","elbow","subsequentPadding","firstMessage","subsequentMessages","marker","convertToTree","root","addNode","tree","isTty","isatty","prettyFormat","subject","indentSize","subjectEntry","badge","prettyFormatMutation","encodeItemRef","ref","badgeStyle","variant","info","bgWhite","black","incremental","bgGreen","maybeDestructive","bgYellow","destructive","bgRed","label","mutationImpact","patch","documentId","mutation","document","listFormatter","Intl","ListFormat","mutationHeader","mutationType","documentType","format","lock","ifRevision","header","padding","patches","flat","formatPatchMutation","op","formattedType","amount","position","referenceItem","items","startIndex","endIndex","line","VERSION_PATTERN","ensureApiVersionFormat","normalizedVersion","MAX_MUTATION_CONCURRENCY","DEFAULT_MUTATION_CONCURRENCY","runMigrationCommand","migrationsDirectoryPath","fromExport","dry","dryRun","resolvedScripts","relative","projectConfig","apiConfig","apiHost","confirm","run","createProgress","stop","done","completedTransactions","stopAndPersist","symbol","currentTransactions","blue","pending","dryRunHandler","exportPath","previewCommand","getPreviewAction","extractSchemaCommand","isInteractive","stdout","isTTY","TERM","startCommand","previewAction","bgBlack","prettifyQuotaError","inviteUserCommand","selectedEmail","useProjectHostname","roles","role","appliesToUsers","email","promptForEmail","selectedRole","promptForRole","useGlobalApi","val","sortFields","listUsersCommand","sort","order","robots","invitations","globalClient","pendingInvitations","getPendingInvitations","memberIds","members","member","users","user","getUserProps","isRobot","ordered","sortBy","rows","reverse","maxWidths","row","printRow","isInvite","textRow","col","dim","displayName","invite","isAccepted","isRevoked","acceptedByUserId","usersGroup","commands","datasetGroup","aliasDatasetCommand","backupGroup","listBackupCommand","disableBackupCommand","enableBackupCommand","migrationGroup","listMigrationsCommand","queryDocumentsCommand","schemaGroup","validateSchemaCommand","manifestGroup","cliProjectCommands","requiredCliVersionRange"],"mappings":";;;;;;;;;;;;;;;;;;;;;;;;;AAGO,MAAMA,sBAAoB,eAE3BC,qBAAgD;AAAA,EACpDC,MAAM;AAAA,EACNC,WAAW;AAAA,EACXC,aAAa;AAAA,EACbC,aAAa;AACf;ACAA,SAASC,YAAYC,KAAkB;AACrC,QAAMC,SAAS,CAAC;AACZD,SAAAA,IAAIE,OACND,OAAOE,aAAaH,IAAIE,OACfF,IAAIG,eACbF,OAAOE,aAAaH,IAAIG,aAGtBH,IAAII,UACNH,OAAOG,UAAUJ,IAAII,UACZJ,IAAIK,gBACbJ,OAAOG,UAAUJ,IAAIK,gBACZL,KAAKM,UAAUC,MAAMH,UAC9BH,OAAOG,UAAUJ,IAAIM,SAASC,KAAKH,UAC1BJ,KAAKM,UAAUE,MAAMJ,UAC9BH,OAAOG,UAAUJ,IAAIM,SAASE,KAAKJ,UAGnCH,OAAOG,UAAUK,KAAKC,UAAUV,GAAG,GAG9BC;AACT;AC9BaU,MAAAA,UAAQC,uBAAQ,aAAa;ACAnC,SAASC,oBAAoBC,aAAqC;AACvE,MAAI,CAACA;AACI,WAAA;AAGHnB,QAAAA,OAAO,GAAGmB,WAAW;AAEvBnB,SAAAA,KAAKoB,YAAY,MAAMpB,OAClB,kDAGLA,KAAKqB,SAAS,IACT,sDAGLrB,KAAKqB,SAASC,KACT,+CAGJ,YAAYC,KAAKvB,IAAI,IAIrB,wBAAwBuB,KAAKvB,IAAI,IAIlC,QAAQuB,KAAKvB,IAAI,IACZ,2DAGF,KAPE,4EAJA;AAYX;AC9BO,SAASwB,qBACdC,QACAC,UAAgD,IAC/B;AACjB,SAAOD,OAAOE,OAAO;AAAA,IACnBC,MAAM;AAAA,IACNnB,SAAS;AAAA,IACToB,UAAW7B,CAAS,SACNkB,oBAAoBlB,IAAI,KAK7B;AAAA,IAET,GAAG0B;AAAAA,EAAAA,CACJ;AACH;AChBA,eAAsBI,oBACpBC,SACAL,UAAuD,IACtC;AACX,QAAA;AAAA,IAACM;AAAAA,IAAWP;AAAAA,MAAUM,SACtB;AAAA,IAACtB;AAAAA,IAASwB;AAAAA,EAAAA,IAAiBP,SAC3BQ,SAASF,aAETG,WAAW,MAAMD,OAAOC,SAASC,KAAK,GACtCC,gBAAgBF,SAASG,KAAMC,aAAYA,QAAQvC,SAAS,YAAY,GACxEwC,iBAAiBL,SAASM,IAAKF,CAAa,aAAA;AAAA,IAACG,OAAOH,QAAQvC;AAAAA,EAAM,EAAA,GAClE2C,WAAW,MAAMlB,OAAOE,OAAO;AAAA,IACnClB,SAASA,WAAW;AAAA,IACpBmB,MAAM;AAAA,IACNgB,SAASX,gBACL,CAAC;AAAA,MAACS,OAAO;AAAA,MAAO1C,MAAM;AAAA,OAAuB,IAAIyB,OAAOoB,aAAa,GAAGL,cAAc,IACtFA;AAAAA,EAAAA,CACL;AAED,MAAIG,aAAa,OAAO;AACtB3B,YAAM,wDAAwD;AACxD8B,UAAAA,iBAAiB,MAAMtB,qBAAqBC,QAAQ;AAAA,MACxDhB,SAAS;AAAA,MACTsC,SAASV,gBAAgBW,SAAY;AAAA,IAAA,CACtC;AACD,WAAA,MAAMd,OAAOC,SAASc,OAAOH,cAAc,GACpCA;AAAAA,EAAAA;AAGFH,SAAAA;AACT;ACvBA,eAAeO,iBACbnB,SACAZ,aACAgC,YAC4B;AACtB,QAAA;AAAA,IAACnB;AAAAA,EAAAA,IAAaD;AAEpB,MAAIG,SAASF,UAAU;AACjB,QAAA;AAAA,IAACoB;AAAAA,IAAWC;AAAAA,EAAAA,IAASnB,OAAOoB,OAAO;AAEzC,MAAI,CAACF;AACG,UAAA,IAAIG,MAAM,wBAAwB;AAK1C,MAAIC,kBAA0BrC;AAC9B,SAAKqC,oBACHA,kBAAkB,MAAM1B,oBAAoBC,SAAS;AAAA,IACnDtB,SAAS;AAAA,EACV,CAAA,IAGHyB,SAASA,OAAOuB,WAAW;AAAA,IAAClB,SAASpB;AAAAA,IAAagC;AAAAA,EAAAA,CAAW,GAEtD;AAAA,IACLC;AAAAA,IACAjC,aAAaqC;AAAAA,IACbH;AAAAA,IACAnB;AAAAA,EACF;AACF;ACrCA,MAAMwB,aAAW;AAAA;AAAA;AAAA,GAKXC,8BAAoD;AAAA,EACxD3D,MAAM;AAAA,EACN4D,OAAO;AAAA,EACP3D,WAAW;AAAA,EACXC,aAAa;AAAA,EAAA,UACbwD;AAAAA,EACAG,QAAQ,OAAOC,MAAM/B,YAAY;AACzB,UAAA;AAAA,MAACgC;AAAAA,MAAQC;AAAAA,QAASjC,SAClB,CAACQ,OAAO,IAAIuB,KAAKG,oBACjB;AAAA,MAACb;AAAAA,MAAWjC;AAAAA,MAAakC;AAAAA,MAAOnB;AAAAA,IAAU,IAAA,MAAMgB,iBACpDnB,SACAQ,SACAzC,mBACF;AAEI,QAAA;AACF,YAAMoC,OAAOgC,QAAQ;AAAA,QACnBC,QAAQ;AAAA,QACRC,SAAS;AAAA,UAACC,eAAe,UAAUhB,KAAK;AAAA,QAAE;AAAA,QAC1CiB,KAAK,aAAalB,SAAS,aAAajC,WAAW;AAAA,QACnDP,MAAM;AAAA,UACJ2D,SAAS;AAAA,QAAA;AAAA,MACX,CACD,GACDR,OAAOS,MAAM,GAAGR,MAAMS,MAAM,sCAAsCtD,WAAW;AAAA,CAAI,CAAC,EAAE;AAAA,aAC7EuD,OAAO;AACR,YAAA;AAAA,QAACjE;AAAAA,MAAAA,IAAWL,YAAYsE,KAAK;AACnCX,aAAOS,MAAM,GAAGR,MAAMW,IAAI,oCAAoClE,OAAO,EAAE,CAAC;AAAA,CAAI;AAAA,IAAA;AAAA,EAC9E;AAEJ;ACzCA,IAAA,UAAemE,QAAQ,OAAO,EAAE,eAAe;ACO/C,MAAMC,WAAWD,QAAQ,UAAU;AAMnC,SAASE,WAAWC,WAAmBC,aAAqBC,YAAuC;AACjG,SAAO,IAAIC,QAAQ,CAACC,SAASC,WAAW;AAChCC,UAAAA,qBAAqBC,qBAAkBN,WAAW;AACrCO,uBAAAA,GAAG,SAAUlF,CAAe,QAAA;AAC7C+E,aAAO/E,GAAG;AAAA,IACX,CAAA,GAEDgF,mBAAmBE,GAAG,SAAS,MAAM;AAC3B,cAAA;AAAA,IAAA,CACT;AAEKC,UAAAA,UAAUX,SAAS,OAAO;AAAA,MAC9BY,MAAM;AAAA,MACNC,aAAa;AAAA,QAACC,OAAOC,sBAAKC,UAAUC;AAAAA,MAAAA;AAAAA,IAAqB,CAC1D;AAEOP,YAAAA,GAAG,SAAUlF,CAAe,QAAA;AAC5BW,cAAA;AAAA,KAA0BX,IAAI0F,KAAK,GACzCX,OAAO/E,GAAG;AAAA,IACX,CAAA,GAGDmF,QAAQD,GAAG,WAAYlF,CAAe,QAAA;AAC9BW,cAAA,uBAAuBX,IAAII,OAAO;AAAA,IACzC,CAAA,GAED+E,QAAQD,GAAG,YAAaS,CAA2BA,cAAA;AACtCA,iBAAAA,UAASC,GAAGC,cAAc;AAAA,IACtC,CAAA,GAGDV,QAAQW,KAAKd,kBAAkB,GAC/BG,QAAQY,UAAUrB,WAAW,EAAK,GAClCS,QAAQa,SAAS;AAAA,EAAA,CAClB;AACH;ACzCA,MAAMC,oBAAoB;AAE1B,eAAeC,qBACbxE,SACAZ,aACiB;AACX,QAAA;AAAA,IAACM;AAAAA,MAAUM,SAEX;AAAA,IAACqB;AAAAA,IAAWC;AAAAA,IAAOnB;AAAAA,EAAU,IAAA,MAAMgB,iBAAiBnB,SAASZ,aAAarB,mBAAiB;AAE7F,MAAA;AAGIa,UAAAA,WAAW,MAAMuB,OAAOgC,QAAQ;AAAA,MACpCE,SAAS;AAAA,QAACC,eAAe,UAAUhB,KAAK;AAAA,MAAE;AAAA,MAC1CiB,KAAK,aAAalB,SAAS,aAAajC,WAAW;AAAA,MACnDqF,OAAO;AAAA,QAACC,OAAOH,kBAAkBI,SAAS;AAAA,MAAA;AAAA,IAAC,CAC5C;AAEG/F,QAAAA,UAAUgG,SAAStF,SAAS,GAAG;AACjC,YAAMuF,kBAAkBjG,SAASgG,QAAQlE,IAAKoE,CAA0B,YAAA;AAAA,QACtEnE,OAAOmE,OAAOC;AAAAA,MAAAA,EACd;AACe,aAAA,MAAMrF,OAAOE,OAAO;AAAA,QACnClB,SAAS,sCAAsC6F,iBAAiB;AAAA,QAChE1E,MAAM;AAAA,QACNgB,SAASgE;AAAAA,MAAAA,CACV;AAAA,IAAA;AAAA,WAIIvG,KAAK;AACZ,UAAM,IAAIkD,MAAM,uCAAuCpC,WAAW,KAAKd,IAAII,OAAO,EAAE;AAAA,EAAA;AAGhF,QAAA,IAAI8C,MAAM,kBAAkB;AACpC;ACvCA,eAAewD,cAAcC,QAA+B;AACtD,MAAA;AACF,UAAMC,OAAAA,OAAOD,MAAM;AAAA,WACZ3G,KAAK;AACNW,YAAA,sCAAsCX,IAAII,OAAO,EAAE;AAAA,EAAA;AAE7D;ACRA,MAAMyG,cAAc,GACdC,qBAAqB,KAErBC,qBAAsBC,gBAAuBC,KAAKC,IAAI,GAAGF,UAAU,IAAIF;AAE7E,eAAeK,UACbC,WACAC,aAAqBR,aACT;AACHG,WAAAA,aAAa,GAAGA,aAAaK,YAAYL;AAC5C,QAAA;AACF,aAAO,MAAMI,UAAU;AAAA,aAChBpH,KAAK;AAEZ,UAAIA,IAAIM,YAAYN,IAAIM,SAASH,cAAcH,IAAIM,SAASH,aAAa;AACjEH,cAAAA;AAGFsH,YAAAA,aAAaP,mBAAmBC,UAAU;AAChDrG,cAAM,qCAAqC2G,UAAU,UAAUtH,IAAII,OAAO,GAC1E,MAAM,IAAIyE,QAASC,CAAAA,YAAYyC,WAAWzC,SAASwC,UAAU,CAAC;AAAA,IAAA;AAI5D,QAAA,IAAIpE,MAAM,oCAAoC;AACtD;AChBA,MAAMsE,uBAAqB,KAAK,KAC1BC,iBAAe,IAAI,KAAK,KAExB5D,YAAU6D,MAAAA,MAAM,CAACC,WAAAA,UAAAA,GAAaC,WAAAA,QAAS,CAAA,CAAC;AAE9C,eAAeC,cACbC,MACAC,UACAC,UACAC,QACe;AAITC,QAAAA,qBAAqBC,sBAAKC,SAASL,QAAQ,GAE3CM,gBAAgBC,iBAAiBJ,oBAAoBF,UAAUC,MAAM;AAC3E,QAAMd,UAAU,YAAY;AACpB7G,UAAAA,WAAW,MAAMuD,UAAQ;AAAA,MAC7BiE,KAAAA;AAAAA,MACAS,cAAc;AAAA,MACdC,SAAS;AAAA,QAACC,SAASjB;AAAAA,QAAoBkB,QAAQjB;AAAAA,MAAY;AAAA,MAC3DkB,QAAQ;AAAA,IAAA,CACT;AAEKhI,YAAA,yCAAyCuH,oBAAoB5H,UAAUH,UAAU,GAEvF,MAAMyI,SAAAA,SAAStI,SAASC,MAAM0E,GAAkBoD,kBAAAA,aAAa,CAAC;AAAA,EAAA,CAC/D;AACH;AAEA,SAASC,iBAAiBP,UAAkBC,UAAkBC,QAAwB;AAGpF,MAAII,gBAAgB;AACpB,SAAIL,aAAa,UACfK,gBAAgBF,cAAAA,QAAKU,KAAKZ,QAAQ,UAAUF,QAAQ,IAC3CC,aAAa,WACtBK,gBAAgBF,cAAAA,QAAKU,KAAKZ,QAAQ,SAASF,QAAQ,IAG9CM;AACT;AC9CA,MAAMb,qBAAqB,KAAK,KAC1BC,eAAe,IAAI,KAAK,KAExB5D,UAAU6D,MAAAA,MAAM,CAACC,WAAAA,UAAAA,GAAaC,WAAAA,QAAS,CAAA,CAAC;AAG9C,eAAekB,iBAAiBhB,MAA2B;AACzD,QAAMxH,WAAW,MAAM6G,UAA8B,MACnDtD,QAAQ;AAAA,IACNiE,KAAAA;AAAAA,IACAS,cAAc;AAAA,IACdC,SAAS;AAAA,MAACC,SAASjB;AAAAA,MAAoBkB,QAAQjB;AAAAA,IAAAA;AAAAA,EAAY,CAC5D,CACH;AAEA9G,SAAAA,QAAM,iDAAiDmH,MAAKxH,UAAUH,UAAU,GAEzEG,SAASC;AAClB;ACRA,MAAMwI,iCAAiCC,YAAAA,SAAS;AAAA,EACtCC,SAAS;AAAA,EAMVC,aAAa;AAAA,EAEpBC,YACEtH,QACAkB,WACAjC,aACAsI,UACApG,OACA;AACM,UAAA;AAAA,MAACqG,YAAY;AAAA,IAAA,CAAK,GACxB,KAAKxH,SAASA,QACd,KAAKkB,YAAYA,WACjB,KAAKjC,cAAcA,aACnB,KAAKsI,WAAWA,UAChB,KAAKpG,QAAQA;AAAAA,EAAAA;AAAAA,EAGf,MAAMsG,QAAuB;AACvB,QAAA;AACI9I,YAAAA,OAAO,MAAM,KAAK+I,oBAAoB;AAGxC,WAAKL,eAAe,MACtB,KAAKA,aAAa1I,KAAK0I,aAGzB1I,KAAKgJ,MAAMC,QAASC,CAAe,SAAA,KAAKC,KAAKD,IAAI,CAAC,GAE9C,OAAOlJ,KAAKoJ,cAAe,YAAYpJ,KAAKoJ,eAAe,KAC7D,KAAKX,SAASzI,KAAKoJ,aAGnB,KAAKD,KAAK,IAAI;AAAA,aAET3J,KAAK;AACZ,WAAK6J,QAAQ7J,GAAY;AAAA,IAAA;AAAA,EAC3B;AAAA;AAAA,EAIF,MAAMuJ,sBAAkD;AACtD,UAAMpD,QAAqB,KAAK8C,WAAW,KAAK,CAAA,IAAK;AAAA,MAACW,YAAY,KAAKX;AAAAA,IAAM;AAEzE,QAAA;AACK,aAAA,MAAM,KAAKpH,OAAOgC,QAAQ;AAAA,QAC/BE,SAAS;AAAA,UAACC,eAAe,UAAU,KAAKhB,KAAK;AAAA,QAAE;AAAA,QAC/CiB,KAAK,aAAa,KAAKlB,SAAS,aAAa,KAAKjC,WAAW,YAAY,KAAKsI,QAAQ;AAAA,QACtFjD;AAAAA,MAAAA,CACD;AAAA,aACM9B,OAAO;AAEd,UAAIyF,MAAMzF,MAAMlE,aAAakE,MAAM/D,SAASC,KAAKH,UAAUiE,MAAMjE;AAG7D0J,YAAAA,QAAQnH,WACVmH,MAAMC,OAAO1F,KAAK,IAEd,IAAInB,MAAM,sCAAsC4G,GAAG,EAAE;AAAA,IAAA;AAAA,EAC7D;AAEJ;ACnEA,MAAME,cAAcA,CAACtG,QAAsBuG,cAAuC;AAChF,MAAIC,UAAUxG,OAAOwG,QAAQD,SAAS,EAAEE,SACpCC,eAA8B;AAAA,IAACC,MAAMJ;AAAAA,EAAAA,GACrCE,QAAQG,KAAKC,IAAI;AAErB,QAAMpG,QAASwB,CAA4BA,cAAA;AACzC,UAAM6E,UAAUC,kBAAAA,QAASH,KAAKC,IAAAA,IAAQJ,KAAK;AACvCxE,IAAAA,UAAS+E,WAAW/E,UAAS+E,UAAU,KAAK/E,UAASgF,SAAShF,UAASgF,QAAQ,IACjFT,QAAQU,OAAO,GAAGjF,UAAS0E,IAAI,KAAK1E,UAAS+E,OAAO,IAAI/E,UAASgF,KAAK,MAAMH,OAAO,MAEnFN,QAAQU,OAAO,GAAGjF,UAAS0E,IAAI,KAAKG,OAAO;AAAA,EAE/C;AAEO,SAAA;AAAA,IACLK,KAAMlF,CAA4BA,cAAA;AAC5BA,MAAAA,UAAS0E,SAASD,aAAaC,QACjClG,MAAMiG,YAAY,GAClBF,QAAQY,QAAQ,GAChBZ,UAAUxG,OAAOwG,QAAQvE,UAAS0E,IAAI,EAAEF,MACxCA,GAAAA,QAAQG,KAAKC,IAAAA,KACJ5E,UAAS0E,SAASD,aAAaC,QAAQ1E,UAASoF,UACzD5G,MAAMwB,SAAQ,GAEhByE,eAAezE;AAAAA,IACjB;AAAA,IACAoF,QAASpF,CAA4BA,cAAA;AAC7BA,YAAAA,SAAQ,GACdyE,eAAezE;AAAAA,IACjB;AAAA,IACAmF,SAASA,MAAM;AACbZ,cAAQY,QAAQ,GAChBX,QAAQG,KAAKC,IAAI;AAAA,IACnB;AAAA,IACAS,MAAMA,MAAM;AACVd,cAAQc,KAAK,GACbb,QAAQG,KAAKC,IAAI;AAAA,IAAA;AAAA,EAErB;AACF;ACxDA,SAASU,cAAcC,OAAsB;AAC3C,QAAMC,IAAID,SAAQ,IAAI,IAAIjE,KAAKmE,MAAMnE,KAAKoE,IAAIH,KAAI,IAAIjE,KAAKoE,IAAI,IAAI,CAAC;AACpE,SAAO,IAAIH,QAAOjE,KAAKC,IAAI,MAAMiE,CAAC,GAAGG,QAAQ,CAAC,CAAC,IAAI,CAAC,KAAK,MAAM,MAAM,MAAM,IAAI,EAAEH,CAAC,CAAC;AACrF;ACHA,SAASI,cAAcC,UAA2B;AAEzC,SAAA,CAAC,SAAStK,KAAKsK,QAAQ;AAChC;AC8BA,MAAM7K,QAAQ8K,eAAAA,QAAY,eAAe,GAEnCC,+BAA+B,IAC/BC,2BAA2B,IAa3BtI,aAAW;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAajB,SAASuI,gBAAcnI,MAAyB;AAC9C,SAAOoI,uBAAMC,QAAAA,QAAQrI,KAAKsI,QAAQC,QAAQD,IAAI,EAAEE,MAAM,CAAC,CAAC,EACrD5K,QAAQ,aAAa;AAAA,IAACE,MAAM;AAAA,EAAA,CAAS,EACrCF,QAAQ,OAAO;AAAA,IAACE,MAAM;AAAA,EAAA,CAAS,EAC/BF,QAAQ,eAAe;AAAA,IAACE,MAAM;AAAA,IAAUmB,SAASgJ;AAAAA,EAAAA,CAA6B,EAC9ErK,QAAQ,aAAa;AAAA,IAACE,MAAM;AAAA,IAAWmB,SAAS;AAAA,EAAM,CAAA,EAAEqJ;AAC7D;AAEA,MAAMG,wBAA8C;AAAA,EAClDvM,MAAM;AAAA,EACN4D,OAAO;AAAA,EACP3D,WAAW;AAAA,EACXC,aAAa;AAAA,EAAA,UACbwD;AAAAA;AAAAA,EAEAG,QAAQ,OAAOC,MAAM/B,YAAY;AACzB,UAAA;AAAA,MAACgC;AAAAA,MAAQC;AAAAA,IAAAA,IAASjC,SAClB,CAACG,QAAQsK,IAAI,IAAI,MAAMC,qBAAqB1K,SAAS+B,IAAI,GACzD;AAAA,MAACV;AAAAA,MAAWjC;AAAAA,MAAasI;AAAAA,MAAUnB;AAAAA,MAAQoE;AAAAA,IAAAA,IAAeF;AAG5DlE,QAAAA,WAAW,MAAMoE,gBAAgB,IAAI;AACvC3I,aAAOS,MAAM,sBAAsB;AACnC;AAAA,IAAA;AAEF,UAAMQ,cAAcwD,cAAAA,QAAKU,KAAKZ,QAAQoE,WAAW;AAEjD3I,WAAOS,MAAM,gXAA+D,GAC5ET,OAAOS,MAAM,yEAA+D,GAC5ET,OAAOS,MAAM,yEAA+D,GAC5ET,OAAOS,MAAM,UAAKR,MAAM2I,KAAK,WAAW,CAAC,KAAK3I,MAAM4I,KAAKxJ,SAAS,EAAEyJ,OAAO,EAAE,CAAC,SAAI,GAClF9I,OAAOS,MAAM,UAAKR,MAAM2I,KAAK,SAAS,CAAC,KAAK3I,MAAM4I,KAAKzL,WAAW,EAAE0L,OAAO,EAAE,CAAC,SAAI,GAClF9I,OAAOS,MAAM,UAAKR,MAAM2I,KAAK,UAAU,CAAC,KAAK3I,MAAM4I,KAAKnD,QAAQ,EAAEoD,OAAO,EAAE,CAAC,SAAI,GAChF9I,OAAOS,MAAM,yEAA+D,GAC5ET,OAAOS,MAAM,gXAA+D,GAC5ET,OAAOS,MAAM,EAAE,GACfT,OAAOS,MAAM,0BAA0BR,MAAM4I,KAAK5H,WAAW,CAAC,GAAG;AAEjE,UAAMwF,QAAQG,KAAKC,IACbkC,GAAAA,kBAAkBzC,YAAYtG,QAAQ,kCAAkC,GAKxEgB,YAAY,MAAMgI,KAAAA,QAAQvE,cAAAA,QAAKU,KAAK8D,GAAO,OAAA,GAAG,gBAAgB,CAAC;AAGrE,eAAWC,OAAO,CAAC3E,QAAQE,cAAAA,QAAKU,KAAKnE,WAAW,QAAQ,GAAGyD,cAAAA,QAAKU,KAAKnE,WAAW,OAAO,CAAC;AACtFmI,SAAAA,UAAUD,KAAK;AAAA,QAACE,WAAW;AAAA,MAAA,CAAK;AAGlCnM,UAAM,qCAAqC+D,SAAS;AACpD,UAAMqI,sBAAsB5E,cAAAA,QAAKU,KAAKnE,WAAW,aAAa,GAGxDsI,eAAe/H,GAAAA,kBAAkB8H,mBAAmB,GACpDE,gBAAgB,IAAIC,WAAAA,MAAM;AAE5B,QAAA;AACF,YAAMC,mBAAmB,IAAIpE,yBAC3BlH,QACAsK,KAAKpJ,WACLoJ,KAAKrL,aACLqL,KAAK/C,UACL+C,KAAKnJ,KACP,GAEMwG,QAAgB,CAAE;AACxB,UAAI2B,IAAI;AACR,uBAAiBzB,QAAQyD;AACvB3D,cAAMG,KAAKD,IAAI,GACfyB,KACAsB,gBAAgB5B,IAAI;AAAA,UAClBR,MAAM;AAAA,UACNU,QAAQ;AAAA,UACRL,SAASS;AAAAA,UACTR,OAAOwC,iBAAiBjE;AAAAA,QAAAA,CACzB;AAGH,UAAIkE,uBAAuB;AAErB,YAAA;AAAA,QAAC1K,SAAS2K;AAAAA,MAAAA,IAAQ,MAAM,OAAO,OAAO;AACtCA,YAAAA,KACJ7D,OACA,OAAOE,SAAe;AACpB,YAAIA,KAAKnI,SAAS,UAAUmI,KAAKnI,SAAS;AACxC,gBAAMsG,cAAc6B,KAAK5B,KAAK4B,KAAK/J,MAAM+J,KAAKnI,MAAMmD,SAAS;AAAA,aACxD;AACL,gBAAM4I,MAAM,MAAMxE,iBAAiBY,KAAK5B,GAAG;AACrCmF,gBAAAA,cAAcM,aAAa,MAAM;AACxBC,yBAAAA,MAAM,GAAGF,GAAG;AAAA,CAAI;AAAA,UAAA,CAC9B;AAAA,QAAA;AAGqB,gCAAA,GACxBb,gBAAgB5B,IAAI;AAAA,UAClBR,MAAM;AAAA,UACNU,QAAQ;AAAA,UACRL,SAAS0C;AAAAA,UACTzC,OAAOwC,iBAAiBjE;AAAAA,QAAAA,CACzB;AAAA,MAAA,GAEH;AAAA,QAACuE,aAAatB,KAAKsB;AAAAA,MAAAA,CACrB;AAAA,aACOpJ,OAAO;AACdoI,sBAAgBzB,KAAK;AACf,YAAA;AAAA,QAAC5K;AAAAA,MAAAA,IAAWL,YAAYsE,KAAK;AACnC,YAAM,IAAInB,MAAM,sCAAsC9C,OAAO,EAAE;AAAA,IAAA;AAGjE4M,iBAAaU,OACb,MAAMC,SAAAA,SAASX,YAAY,GAE3BP,gBAAgB5B,IAAI;AAAA,MAACR,MAAM;AAAA,MAAqCU,QAAQ;AAAA,IAAA,CAAK;AACzE,QAAA;AACItG,YAAAA,WAAWC,WAAWC,aAAckB,CAA2B,mBAAA;AACnE4G,wBAAgB1B,OAAO;AAAA,UACrBV,MAAM,mCAAmCY,cAAcpF,cAAc,CAAC;AAAA,QAAA,CACvE;AAAA,MAAA,CACF;AAAA,aACM7F,KAAK;AACZyM,YAAAA,gBAAgBzB,QACV,IAAI9H,MAAM,4BAA4BlD,IAAII,OAAO,EAAE;AAAA,IAAA;AAG3DqM,oBAAgB5B,IAAI;AAAA,MAClBR,MAAM,kCAAkC1G,MAAM4I,KAAK,GAAG7H,SAAS,EAAE,CAAC;AAAA,IACnE,CAAA,GACD,MAAMgC,cAAchC,SAAS,GAE7B+H,gBAAgB5B,IAAI;AAAA,MAClBR,MAAM,6BAA6BI,kBAAAA,QAASH,KAAKC,IAAI,IAAIJ,KAAK,CAAC;AAAA,IAAA,CAChE,GACDsC,gBAAgB3B,QAAQ;AAAA,EAAA;AAE5B;AAGA,eAAesB,qBACb1K,SACA+B,MACgD;AAC1CmK,QAAAA,QAAQ,MAAMhC,gBAAcnI,IAAI,GAChC,CAACvB,OAAO,IAAIuB,KAAKG,oBACjB;AAAA,IAACxC;AAAAA,IAAQyM;AAAAA,MAAWnM,SACpB;AAAA,IAACqB;AAAAA,IAAWjC;AAAAA,IAAae;AAAAA,MAAU,MAAMgB,iBAC7CnB,SACAQ,SACAzC,mBACF,GAEM;AAAA,IAACuD;AAAAA,EAAAA,IAASnB,OAAOoB,OAAO;AAC9B,MAAI,CAAC6K,kBAAAA,QAAS9K,KAAK,KAAKA,MAAMhC,SAAS;AAC/B,UAAA,IAAIkC,MAAM,kBAAkB;AAGpC,MAAI,CAAC4K,kBAAAA,QAAShN,WAAW,KAAKA,YAAYE,SAAS;AACjD,UAAM,IAAIkC,MAAM,WAAWpC,WAAW,+BAA+B;AAGjEsI,QAAAA,WAAWW,OAAO6D,MAAM,WAAW,KAAM,MAAM1H,qBAAqBxE,SAASZ,WAAW,CAAE;AAChG,MAAIsI,SAASpI,SAAS;AACpB,UAAM,IAAIkC,MAAM,aAAa0K,MAAM,WAAW,CAAC,2BAA2B;AAG5E,MAAI,iBAAiBA,UACfA,MAAMH,cAAc,KAAKG,MAAMH,cAAc9B;AAC/C,UAAM,IAAIzI,MAAM,iCAAiCyI,wBAAwB,QAAQ;AAIrF,QAAMoC,qBAAqB,GAAGjN,WAAW,WAAWsI,QAAQ;AAC5D,MAAI4E,MAAM,OAAO,YACXJ,MAAMI,QAAQrL,SAETsL,KAAWL,WAAAA,MAAMI,GAAG,IAGf,MAAM5M,OAAOE,OAAO;AAAA,IAChCC,MAAM;AAAA,IACNnB,SAAS;AAAA,IACTsC,SAASyF,cAAAA,QAAKU,KAAKgF,SAASE,kBAAkB;AAAA,IAC9CG,QAAQD,KAAAA;AAAAA,EAAAA,CACT,GAEA;AAGH,SAAI1C,cAAcyC,GAAG,MACnBA,MAAM7F,cAAAA,QAAKU,KAAKmF,KAAKD,kBAAkB,IAIrC,CAACH,MAAMO,aAAaC,GAAAA,WAAWJ,GAAG,MACZ,MAAM5M,OAAOE,OAAO;AAAA,IAC1CC,MAAM;AAAA,IACNnB,SAAS,SAAS4N,GAAG;AAAA,IACrBtL,SAAS;AAAA,EACV,CAAA,MAKCsL,MAAM,MAIH,CACLnM,QACA;AAAA,IACEkB;AAAAA,IACAjC;AAAAA,IACAsI;AAAAA,IACApG;AAAAA,IACAiF,QAAQE,cAAAA,QAAKkG,QAAQL,GAAG;AAAA,IACxB3B,aAAalE,cAAAA,QAAKC,SAAS4F,GAAG;AAAA,IAC9BG,WAAWP,MAAMO;AAAAA,IACjBV,aAAaG,MAAMH,eAAe/B;AAAAA,EAAAA,CACnC;AAEL;ACrRA,MAAMrI,aAAW;AAAA;AAAA;AAAA,GAKXiL,6BAAmD;AAAA,EACvD3O,MAAM;AAAA,EACN4D,OAAO;AAAA,EACP3D,WAAW;AAAA,EACXC,aAAa;AAAA,EAAA,UACbwD;AAAAA,EACAG,QAAQ,OAAOC,MAAM/B,YAAY;AACzB,UAAA;AAAA,MAACgC;AAAAA,MAAQC;AAAAA,QAASjC,SAClB,CAACQ,OAAO,IAAIuB,KAAKG,oBACjB;AAAA,MAACb;AAAAA,MAAWjC;AAAAA,MAAakC;AAAAA,MAAOnB;AAAAA,IAAU,IAAA,MAAMgB,iBACpDnB,SACAQ,SACAzC,mBACF;AAEI,QAAA;AACF,YAAMoC,OAAOgC,QAAQ;AAAA,QACnBC,QAAQ;AAAA,QACRC,SAAS;AAAA,UAACC,eAAe,UAAUhB,KAAK;AAAA,QAAE;AAAA,QAC1CiB,KAAK,aAAalB,SAAS,aAAajC,WAAW;AAAA,QACnDP,MAAM;AAAA,UACJ2D,SAAS;AAAA,QAAA;AAAA,MACX,CACD,GAEDR,OAAOS,MACL,GAAGR,MAAMS,MACP,+BAA+BtD,WAAW;AAAA;AAAA,CAC5C,CAAC,EACH,GAEA4C,OAAOS,MACL,GAAGR,MAAM2I,KAAK;AAAA,CAAsE,CAAC,EACvF;AAAA,aACOjI,OAAO;AACR,YAAA;AAAA,QAACjE;AAAAA,MAAAA,IAAWL,YAAYsE,KAAK;AACnCX,aAAOS,MAAM,GAAGR,MAAMW,IAAI,mCAAmClE,OAAO,EAAE,CAAC;AAAA,CAAI;AAAA,IAAA;AAAA,EAC7E;AAEJ,GCxCMmO,4BAA4B,IAuB5BlL,aAAW;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAajB,SAASuI,gBAAcnI,MAAyB;AAC9C,SAAOoI,uBAAMC,QAAAA,QAAQrI,KAAKsI,QAAQC,QAAQD,IAAI,EAAEE,MAAM,CAAC,CAAC,EACrD5K,QAAQ,SAAS;AAAA,IAACE,MAAM;AAAA,EAAA,CAAS,EACjCF,QAAQ,UAAU;AAAA,IAACE,MAAM;AAAA,EAAA,CAAS,EAClCF,QAAQ,SAAS;AAAA,IAACE,MAAM;AAAA,IAAUmB,SAAS6L;AAAAA,IAA2BC,OAAO;AAAA,EAAI,CAAA,EAAEzC;AACxF;AAEA,MAAM0C,2BAAyE;AAAA,EAC7E9O,MAAM;AAAA,EACN4D,OAAO;AAAA,EACP3D,WAAW;AAAA,EACXC,aAAa;AAAA,EAAA,UACbwD;AAAAA,EACAG,QAAQ,OAAOC,MAAM/B,YAAY;AACzB,UAAA;AAAA,MAACgC;AAAAA,MAAQC;AAAAA,IAAAA,IAASjC,SAClBkM,QAAQ,MAAMhC,gBAAcnI,IAAI,GAChC,CAACvB,OAAO,IAAIuB,KAAKG,oBAEjB;AAAA,MAACb;AAAAA,MAAWjC;AAAAA,MAAakC;AAAAA,MAAOnB;AAAAA,IAAAA,IAAU,MAAMgB,iBACpDnB,SACAQ,SACAzC,mBACF,GAEM0G,QAAsC;AAAA,MAACC,OAAOmI,0BAA0BlI,SAAS;AAAA,IAAC;AACxF,QAAIuH,MAAMxH,OAAO;AAGf,UAAIwH,MAAMxH,QAAQ,KAAKwH,MAAMxH,QAAQsI,OAAOC;AAC1C,cAAM,IAAIzL,MACR,qDAAqDwL,OAAOC,gBAAgB,EAC9E;AAEIvI,YAAAA,QAAQwH,MAAMxH,MAAMC,SAAS;AAAA,IAAA;AAGjCuH,QAAAA,MAAMgB,UAAUhB,MAAMiB;AACpB,UAAA;AACIC,cAAAA,eAAeC,iBAAiBnB,MAAMgB,MAAM,GAC5CI,cAAcD,iBAAiBnB,MAAMiB,KAAK;AAEhD,YAAIG,eAAeF,gBAAgBG,gBAAQD,aAAaF,YAAY;AAC5D,gBAAA,IAAI5L,MAAM,sCAAsC;AAGxDiD,cAAMyI,SAAShB,MAAMgB,QACrBzI,MAAM0I,QAAQjB,MAAMiB;AAAAA,eACb7O,KAAK;AACZ,cAAM,IAAIkD,MAAM,uBAAuBlD,GAAG,EAAE;AAAA,MAAA;AAI5CM,QAAAA;AACA,QAAA;AACS,iBAAA,MAAMuB,OAAOgC,QAA4B;AAAA,QAClDE,SAAS;AAAA,UAACC,eAAe,UAAUhB,KAAK;AAAA,QAAE;AAAA,QAC1CiB,KAAK,aAAalB,SAAS,aAAajC,WAAW;AAAA,QACnDqF,OAAO;AAAA,UAAC,GAAGA;AAAAA,QAAAA;AAAAA,MAAK,CACjB;AAAA,aACM9B,OAAO;AACR,YAAA;AAAA,QAACjE;AAAAA,MAAAA,IAAWL,YAAYsE,KAAK;AACnCX,aAAOW,MAAM,GAAGV,MAAMW,IAAI,+BAA+BlE,OAAO,EAAE,CAAC;AAAA,CAAI;AAAA,IAAA;AAGrEE,QAAAA,YAAYA,SAASgG,SAAS;AAC5BhG,UAAAA,SAASgG,QAAQtF,WAAW,GAAG;AACjC0C,eAAOS,MAAM,mBAAmB;AAChC;AAAA,MAAA;AAGI+K,YAAAA,QAAQ,IAAIC,0BAAM;AAAA,QACtBC,SAAS,CACP;AAAA,UAACzP,MAAM;AAAA,UAAY0P,OAAO;AAAA,UAAYC,WAAW;AAAA,QAAA,GACjD;AAAA,UAAC3P,MAAM;AAAA,UAAa0P,OAAO;AAAA,UAAcC,WAAW;AAAA,QAAA,GACpD;AAAA,UAAC3P,MAAM;AAAA,UAAY0P,OAAO;AAAA,UAAaC,WAAW;AAAA,QAAO,CAAA;AAAA,MAAA,CAE5D;AAEQhJ,eAAAA,QAAQmD,QAASjD,CAAmC,WAAA;AACrD,cAAA;AAAA,UAACC;AAAAA,UAAI8I;AAAAA,QAAAA,IAAa/I;AACxB0I,cAAMM,OAAO;AAAA,UACXC,UAAU;AAAA,UACVF,WAAWG,QAAYpF,YAAAA,KAAKqF,MAAMJ,SAAS,GAAG,qBAAqB;AAAA,UACnEnG,UAAU3C;AAAAA,QAAAA,CACX;AAAA,MAAA,CACF,GAEDyI,MAAMU,WAAW;AAAA,IAAA;AAAA,EACnB;AAEJ;AAEA,SAASb,iBAAiBc,MAA4C;AACpE,MAAI,CAACA,KAAM;AACX,QAAMC,aAAaH,QAAAA,MAAME,MAAM,cAAc,oBAAIvF,MAAM;AACvD,MAAIyF,QAAAA,QAAQD,UAAU;AACbA,WAAAA;AAGT,QAAM,IAAI5M,MAAM,WAAW2M,IAAI,8BAA8B;AAC/D;AC/IA,MAAMxM,aAAW;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA,GAYX2M,eAAqC;AAAA,EACzCrQ,MAAM;AAAA,EACNC,WAAW;AAAA,EACXC,aAAa;AAAA,EACb2D,QAAQ,OACNC,MACA/B,SACAuO,eAEoB,MAAMC,kBAEPzM,MAAM/B,SAASuO,SAAS;AAAA,EAE7C5M,UAAAA;AACF;AAEA,eAAe6M,iBAAiB;AAUlB,UAAA,MAAM;mBAAO,kBAAiC;AAAA,EAAA,CAAA,EAAA,KAAA,SAAA,GAAA;AAAA,WAAA,EAAA;AAAA,EAAA,CAAA,GAE/CxN;AACb;ACtCA,MAAMyN,sBAAsB,6BACtBC,kBAAkB;AAMFC,eAAAA,cACpBC,aACA1C,OACAlM,SACkB;AACZ,QAAA;AAAA,IAACC;AAAAA,IAAWP;AAAAA,IAAQsC;AAAAA,EAAUhC,IAAAA,SAC9B6O,SAAS,OAAOD,cAClBE,wBAAwBF,WAAW,IACnCG,kBAAgBrP,MAAM,IAEpBsP,cAAcH,OAAOI,SAAS,GAAG;AACvC,MAAID,eAAe,CAAE,MAAME,8BAA8BL,QAAQ7O,OAAO;AAC/D,WAAA;AAEHmP,QAAAA,mBACJ,OAAOjD,MAAMkD,cAAgB,MACzB,MAAMC,qBAAqBL,aAAahP,OAAO,IAC/CsP,CAAAA,CAAQpD,MAAMkD;AAEhBR,SAAAA,gBAAgBC,UAClB7M,OAAOS,MAAM,wBAAwBoM,MAAM,EAAE,GAQ/C,MALe5O,UAAU;AAAA,IACvBsP,aAAa;AAAA,IACbC,gBAAgB;AAAA,EACjB,CAAA,EAEYrN,QAAQ;AAAA,IACnBC,QAAQ;AAAA,IACRgE,KAAK;AAAA,IACLvH,MAAM;AAAA,MAACgQ;AAAAA,MAAQM;AAAAA,IAAgB;AAAA,IAC/BtI,cAAc;AAAA,EACf,CAAA,GAEM;AACT;AAEA,SAASwI,qBAAqBL,aAAsBhP,SAA6C;AACzF,QAAA;AAAA,IAACN;AAAAA,IAAQsC;AAAAA,IAAQC;AAAAA,EAAAA,IAASjC;AAEhCgC,SAAAA,OAAOS,MAAM,EAAE,GACXuM,cACFhN,OAAOS,MAAMgN,iBAAAA;AAAAA,QACTxN,MAAMyN,OAAO,GAAGC,oBAAAA,QAAWC,OAAO,WAAW,CAAC;AAAA,WAC3C3N,MAAMW,IAAIX,MAAM4N,UAAU,QAAQ,CAAC,CAAC;AAAA;AAAA,iCAEd5N,MAAM4N,UAAU,gBAAgB,CAAC;AAAA;AAAA,KAE7D,IAED7N,OAAOS,MAAMgN,iBAAAA;AAAAA,QACTxN,MAAMyN,OAAO,GAAGC,oBAAAA,QAAWC,OAAO,WAAW,CAAC;AAAA;AAAA;AAAA,iBAGrC3N,MAAM4N,UAAU,gBAAgB,CAAC;AAAA;AAAA;AAAA,KAG7C,GAGH7N,OAAOS,MAAM,EAAE,GAER/C,OAAOE,OAAO;AAAA,IACnBC,MAAM;AAAA,IACNnB,SAAS+Q,iBAAAA;AAAAA;AAAAA;AAAAA,IAGTzO,SAAS;AAAA,EAAA,CACV;AACH;AAEA,SAASkO,8BACPL,QACA7O,SACkB;AACZ,QAAA;AAAA,IAACN;AAAAA,IAAQsC;AAAAA,IAAQC;AAAAA,EAAAA,IAASjC;AAEhCgC,SAAAA,OAAOS,MAAM,EAAE,GACfT,OAAOS,MAAMR,MAAMyN,OAAO,GAAGC,oBAAAA,QAAWC,OAAO,wCAAwC,CAAC,GAEpFf,WAAW,OACb7M,OAAOS,MAAM,kCAAkC,GAC/CT,OAAOS,MAAM,2CAA2C,GACxDT,OAAOS,MAAM,iCAAiC,GAC9CT,OAAOS,MAAM,2BAA2B,MAExCT,OAAOS,MAAM,KAAKoM,OAAOiB,QAAQ,OAAO,OAAO,EAAEA,QAAQ,OAAO,KAAK,CAAC,EAAE,GACxE9N,OAAOS,MAAM,KAAKoM,OAAOiB,QAAQ,OAAO,OAAO,EAAEA,QAAQ,OAAO,SAAS,CAAC,EAAE,IAG9E9N,OAAOS,MAAM,EAAE,GAER/C,OAAOE,OAAO;AAAA,IACnBC,MAAM;AAAA,IACNnB,SAAS+Q,iBAAAA;AAAAA,+BACkBxN,MAAMW,IAAI,OAAO,CAAC;AAAA,gBACjCX,MAAM4N,UAAU,iBAAiB,CAAC;AAAA,IAC9C7O,SAAS;AAAA,EAAA,CACV;AACH;AAEA,SAAS+N,kBAAgBrP,QAAsC;AAC7D,SAAOA,OAAOE,OAAO;AAAA,IACnBC,MAAM;AAAA,IACNnB,SAAS;AAAA,IACT8N,QAAQuD;AAAAA,IACRjQ,UAAW+O,CAAAA,WAAWmB,eAAenB,QAAQA,MAAM;AAAA,EAAA,CACpD;AACH;AAEA,SAASkB,aAAalB,QAA+B;AACnD,MAAIA,WAAW,OAAOA,WAAW,eAAeA,WAAW;AAClDA,WAAAA;AAGL,MAAA;AACF,UAAMoB,UAAUpB,OACbiB,QAAQ,aAAa,KAAKrB,mBAAmB,EAAE,EAC/CqB,QAAQ,OAAOpB,eAAe,GAE3BwB,SAAS9J,aAAAA,QAAI6H,MAAMgC,OAAO;AAC5BE,QAAAA,OAAOD,OAAOC,QAAQ;AAC1B,WAAI,YAAY3Q,KAAK0Q,OAAOE,YAAY,EAAE,MACxCD,OAAOA,KAAKL,QAAQ,cAAc,EAAE,IAGtCK,OAAOA,KAAKL,QAAQpB,iBAAiB,IAAI,EAAEoB,QAAQ,IAAIO,OAAO5B,qBAAqB,GAAG,GAAG,GAAG,GAErF,GAAGyB,OAAOE,QAAQ,KAAKD,IAAI;AAAA,EAAA,QACtB;AACL,WAAA;AAAA,EAAA;AAEX;AAEA,SAASH,eAAenB,QAAuBD,aAAoC;AACjF,MAAIC,WAAW,OAAOA,WAAW,eAAeA,WAAW;AAClD,WAAA;AAGL,MAAA;AACEZ,WAAAA,aAAAA,QAAAA,MAAMY,UAAW,CAAmB,GACjC;AAAA,EAAA,QACK;AAAA,EAAA;AAId,SAAI,aAAarP,KAAKoP,WAAW,IACxB,+DAGF,mBAAmBA,WAAW;AACvC;AAEA,SAASE,wBAAwBF,aAA6B;AAC5D,QAAMC,SAASkB,aAAanB,WAAW,GACjC0B,SAASN,eAAenB,QAAQD,WAAW;AACjD,MAAI0B,WAAW;AACP,UAAA,IAAI9O,MAAM8O,MAAM;AAGxB,MAAI,CAACzB;AACG,UAAA,IAAIrN,MAAM,gBAAgB;AAG3BqN,SAAAA;AACT;AC5KA,MAAMlN,aAAW;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA,GAUX4O,uBAA6C;AAAA,EACjDtS,MAAM;AAAA,EACN4D,OAAO;AAAA,EACP3D,WAAW;AAAA,EAAA,UACXyD;AAAAA,EACAxD,aAAa;AAAA,EACb2D,QAAQ,OAAOC,MAAM/B,YAAY;AACzB,UAAA;AAAA,MAACgC;AAAAA,IAAUhC,IAAAA,SACX,CAAC6O,MAAM,IAAI9M,KAAKG;AAEtB,QAAI,CAAC2M;AACG,YAAA,IAAIrN,MAAM,yDAAyD;AAG3E,UAAM0K,QAAQnK,KAAKyO;AAGJtM,gBAAAA,QAAGwI,WAAWjG,sBAAKU,KAAKmD,QAAQmG,IAAO5B,GAAAA,MAAM,CAAC,KAE3D7M,OAAO0O,KAAK,WAAW7B,MAAM,mDAAmD,GAGlE,MAAMF,cAAcE,QAAQ3C,OAAOlM,OAAO,KAExDgC,OAAOS,MAAM,gCAAgC;AAAA,EAAA;AAGnD,GC1CMkO,YAAuC;AAAA,EAC3C1S,MAAM;AAAA,EACNC,WAAW;AAAA,EACXE,aAAa;AAAA,EACbD,aAAa;AACf,GCHMwD,aAAW;AAAA;AAAA;AAAA;AAAA,GAMXiP,0BAAgD;AAAA,EACpD3S,MAAM;AAAA,EACN4D,OAAO;AAAA,EACP3D,WAAW;AAAA,EAAA,UACXyD;AAAAA,EACAxD,aAAa;AAAA,EACb2D,QAAQ,OAAOC,MAAM/B,YAAY;AACzB,UAAA;AAAA,MAACgC;AAAAA,MAAQ/B;AAAAA,IAAAA,IAAaD,SACtB,CAAC6O,MAAM,IAAI9M,KAAKG,oBAChB/B,SAASF,UAAU;AAAA,MAACsP,aAAa;AAAA,MAAMC,gBAAgB;AAAA,IAAK,CAAA,GAC5DqB,WAAW,MAAM9B,gBAAgBF,QAAQ7O,OAAO;AAClD,QAAA;AACF,YAAMG,OAAOgC,QAAQ;AAAA,QAACC,QAAQ;AAAA,QAAUG,KAAK,SAASsO,QAAQ;AAAA,MAAA,CAAG,GACjE7O,OAAOS,MAAM,gBAAgB;AAAA,aACtBnE,KAAK;AACZ,YAAM,IAAIkD,MAAM;AAAA,EAA4BlD,IAAII,OAAO,EAAE;AAAA,IAAA;AAAA,EAC3D;AAEJ;AAIA,eAAeqQ,gBAAgB+B,WAA+B9Q,SAA4B;AACxF,QAAM+Q,kBAAkBD,aAAaA,UAAUzR,YAAAA,GACzC;AAAA,IAACK;AAAAA,IAAQO;AAAAA,EAAAA,IAAaD,SAGtBgR,UAAU,MAFD/Q,UAAU;AAAA,IAACsP,aAAa;AAAA,IAAMC,gBAAgB;AAAA,EAAK,CAAA,EAErCrN,QAAsB;AAAA,IAACiE,KAAK;AAAA,EAAA,CAAQ;AACjE,MAAI2K,iBAAiB;AACbnQ,UAAAA,WAAWoQ,QAAQxE,OAAQqC,CAAWA,WAAAA,OAAOA,OAAOxP,YAAY,MAAM0R,eAAe,EAAE,CAAC;AAC9F,QAAI,CAACnQ;AACH,YAAM,IAAIY,MAAM,WAAWsP,SAAS,aAAa;AAGnD,WAAOlQ,SAASmE;AAAAA,EAAAA;AAGZlE,QAAAA,UAAUmQ,QAAQtQ,IAAKmO,CAAY,YAAA;AAAA,IAAClO,OAAOkO,OAAO9J;AAAAA,IAAI9G,MAAM4Q,OAAOA;AAAAA,EAAAA,EAAQ;AACjF,SAAOnP,OAAOE,OAAO;AAAA,IACnBlB,SAAS;AAAA,IACTmB,MAAM;AAAA,IACNgB;AAAAA,EAAAA,CACD;AACH;ACjDA,MAAMc,aAAW;AAAA;AAAA;AAAA,GAKXsP,yBAA+C;AAAA,EACnDhT,MAAM;AAAA,EACN4D,OAAO;AAAA,EACP3D,WAAW;AAAA,EAAA,UACXyD;AAAAA,EACAxD,aAAa;AAAA,EACb2D,QAAQ,OAAOC,MAAM/B,YAAY;AACzB,UAAA;AAAA,MAACgC;AAAAA,QAAUhC,SACX;AAAA,MAACC;AAAAA,IAAAA,IAAaD,SAEdgR,UAAU,MADD/Q,UAAU;AAAA,MAACsP,aAAa;AAAA,MAAMC,gBAAgB;AAAA,IAAK,CAAA,EACrCrN,QAAsB;AAAA,MAACiE,KAAK;AAAA,IAAA,CAAQ;AACjEpE,WAAOS,MAAMuO,QAAQtQ,IAAKmO,YAAWA,OAAOA,MAAM,EAAE1H,KAAK;AAAA,CAAI,CAAC;AAAA,EAAA;AAElE;ACpBO,SAAS+J,yBAAyB9R,aAAqC;AAC5E,MAAI,CAACA;AACI,WAAA;AAGHnB,QAAAA,OAAO,GAAGmB,WAAW;AAEvBnB,SAAAA,KAAKoB,YAAY,MAAMpB,OAClB,gDAGLA,KAAKqB,SAAS,IACT,oDAGLrB,KAAKqB,SAASC,KACT,6CAGJ,aAAaC,KAAKvB,IAAI,IAItB,yBAAyBuB,KAAKvB,IAAI,IAInC,QAAQuB,KAAKvB,IAAI,IACZ,yDAGF,KAPE,0EAJA;AAYX;AC9BO,SAASkT,0BACdzR,QACAC,UAAgD,IAC/B;AACjB,SAAOD,OAAOE,OAAO;AAAA,IACnBC,MAAM;AAAA,IACNnB,SAAS;AAAA,IACToB,UAAW7B,CAAS,SACNiT,yBAAyBjT,IAAI,KAKlC;AAAA,IAET,GAAG0B;AAAAA,EAAAA,CACJ;AACH;AChBO,MAAMyR,eAAe;AAErB,SAASC,YAAYlR,QAAyD;AACnF,SAAOA,OAAOgC,QAAkC;AAAA,IAACI,KAAK;AAAA,EAAA,CAAW;AACnE;AAEgB+O,SAAAA,YACdnR,QACAoR,WACAnS,aACsC;AACtC,SAAOoS,OAAOrR,QAAQ,OAAOoR,WAAWnS,cAAc;AAAA,IAACA;AAAAA,MAAe6B,MAAS;AACjF;AAEgBwQ,SAAAA,YACdtR,QACAoR,WACAnS,aACsC;AACtC,SAAOoS,OAAOrR,QAAQ,SAASoR,WAAWnS,cAAc;AAAA,IAACA;AAAAA,MAAe6B,MAAS;AACnF;AAEgByQ,SAAAA,YACdvR,QACAoR,WACsC;AACbA,SAClBC,OAAOrR,QAAQ,SAAS,GAAGoR,SAAS,WAAW,EAAE;AAC1D;AAEgBI,SAAAA,YAAYxR,QAAsBoR,WAAgD;AACzFC,SAAAA,OAAOrR,QAAQ,UAAUoR,SAAS;AAC3C;AAEA,SAASC,OACPrR,QACAiC,QACAmP,WACA1S,MACA;AACA,SAAOsB,OAAOgC,QAAQ;AAAA,IAACC;AAAAA,IAAQG,KAAK,YAAYgP,SAAS;AAAA,IAAI1S;AAAAA,EAAAA,CAAK;AACpE;ACrCa+S,MAAAA,qBAAuC,OAAO7P,MAAM/B,YAAY;AACrE,QAAA;AAAA,IAACC;AAAAA,IAAW+B;AAAAA,IAAQtC;AAAAA,EAAUM,IAAAA,SAC9B,CAAG8M,EAAAA,OAAO+E,aAAa,IAAI9P,KAAKG,oBAChC/B,SAASF,UAAU,GAEnB6R,YAAYhF,SAASoE,yBAAyBpE,KAAK;AACrDgF,MAAAA;AACI,UAAA,IAAItQ,MAAMsQ,SAAS;AAG3B,QAAM,CAAC1R,UAAU2R,SAASC,eAAe,IAAI,MAAM7O,QAAQ8O,IAAI,CAC7D9R,OAAOC,SAASC,KAAK,EAAE6R,KAAMC,CAAAA,SAASA,KAAKzR,IAAK0R,CAAAA,OAAOA,GAAGnU,IAAI,CAAC,GAC/DoU,YAAwBlS,MAAM,EAAE+R,KAAMC,CAAAA,SAASA,KAAKzR,IAAK0R,QAAOA,GAAGnU,IAAI,CAAC,GACxEkC,OAAOgC,QAAQ;AAAA,IAACI,KAAK;AAAA,EAAY,CAAA,CAAC,CACnC;AAED,MAAIgP,YAAY,OAAOzE,SAASqE,0BAA0BzR,MAAM,IAC5D4S,kBAAkBf;AAQtB,MANIA,UAAUgB,WAAWnB,YAAY,IACnCG,YAAYA,UAAUhH,MAAM,CAAC,IAE7B+H,kBAAkB,GAAGlB,YAAY,GAAGG,SAAS,IAG3CQ,QAAQ9C,SAASsC,SAAS;AAC5B,UAAM,IAAI/P,MAAM,kBAAkB8Q,eAAe,kBAAkB;AAGrE,MAAIT,eAAe;AACXW,UAAAA,aAAarT,oBAAoB0S,aAAa;AAChDW,QAAAA;AACI,YAAA,IAAIhR,MAAMgR,UAAU;AAAA,EAAA;AAI9B,QAAMpT,cAAc,OAAOyS,iBAAiBpS,qBAAqBC,MAAM;AACvE,MAAIN,eAAe,CAACgB,SAAS6O,SAAS7P,WAAW;AAC/C,UAAM,IAAIoC,MAAM,YAAYpC,WAAW,mBAAmB;AAIxD,MAAA,CADmB4S,gBAAgB/C,SAAS,2BAA2B;AAEnE,UAAA,IAAIzN,MAAM,4CAA4C;AAG1D,MAAA;AACF,UAAM6Q,YAAwBlS,QAAQoR,WAAWnS,WAAW,GAC5D4C,OAAOS,MACL,iBAAiB6P,eAAe,YAC9BlT,eAAe,iBAAiBA,WAAW,EAAE,eAEjD;AAAA,WACOd,KAAK;AACZ,UAAM,IAAIkD,MAAM;AAAA,EAAmClD,IAAII,OAAO,EAAE;AAAA,EAAA;AAEpE;ACzDA,SAASwL,gBAAcnI,MAAyB;AAC9C,SAAOoI,uBAAMC,QAAAA,QAAQrI,KAAKsI,QAAQC,QAAQD,IAAI,EAAEE,MAAM,CAAC,CAAC,EAAEkI,OAAO,SAAS;AAAA,IAAC5S,MAAM;AAAA,EAAU,CAAA,EAAEwK;AAC/F;AAMaqI,MAAAA,qBAAyD,OAAO3Q,MAAM/B,YAAY;AACvF,QAAA;AAAA,IAACC;AAAAA,IAAWP;AAAAA,IAAQsC;AAAAA,MAAUhC,SAC9B,CAAGoS,EAAAA,EAAE,IAAIrQ,KAAKG,oBACd;AAAA,IAACyQ;AAAAA,MAAS,MAAMzI,gBAAcnI,IAAI,GAClC5B,SAASF,UAAU;AACzB,MAAI,CAACmS;AACG,UAAA,IAAI5Q,MAAM,qCAAqC;AAGnD+P,MAAAA,YAAY,GAAGa,EAAE;AACfQ,QAAAA,UAAU1B,yBAAyBK,SAAS;AAC9CqB,MAAAA;AACIA,UAAAA;AAERrB,cAAYA,UAAUgB,WAAWnB,YAAY,IAAIG,UAAUhH,MAAM,CAAC,IAAIgH;AAEtE,QAAM,CAACsB,cAAc,IAAI,MAAM1P,QAAQ8O,IAAI,CAACI,YAAwBlS,MAAM,CAAC,CAAC,GACtE2S,cAAcD,eAAetS,KAAMwS,CAASA,SAAAA,KAAK9U,SAASsT,SAAS,GACnE7S,UACJoU,eAAeA,YAAY1T,cACvB,mCAAmC0T,YAAY1T,WAAW,OAC1D;AAEFuT,SAAAA,QACF3Q,OAAO0O,KAAK,0DAA0Da,SAAS,GAAG,IAElF,MAAM7R,OAAOE,OAAO;AAAA,IAClBC,MAAM;AAAA,IACNnB,SAAS,GAAGA,OAAO;AAAA;AAAA,IACnB8N,QAASwG,CAAAA,UAAU,GAAGA,KAAK,GAAGC,KAAK;AAAA,IACnCnT,UAAWkT,CACFA,UAAAA,UAAUzB,aAAa;AAAA,EAEjC,CAAA,GAGIc,YAAwBlS,QAAQoR,SAAS,EAAEW,KAAK,MAAM;AAC3DlQ,WAAOS,MAAM,oCAAoC;AAAA,EAAA,CAClD;AACH,GC9CayQ,mBAAqC,OAAOnR,MAAM/B,YAAY;AACnE,QAAA;AAAA,IAACC;AAAAA,IAAW+B;AAAAA,IAAQtC;AAAAA,EAAAA,IAAUM,SAC9B,CAAA,EAAG8M,OAAO+E,aAAa,IAAI9P,KAAKG,oBAChCgK,QAAQnK,KAAKyO,YACbrQ,SAASF,aAET6R,YAAYhF,SAASoE,yBAAyBpE,KAAK;AACrDgF,MAAAA;AACI,UAAA,IAAItQ,MAAMsQ,SAAS;AAG3B,QAAM,CAAC1R,UAAUyS,cAAc,IAAI,MAAM1P,QAAQ8O,IAAI,CACnD9R,OAAOC,SAASC,KAAO6R,EAAAA,KAAMC,UAASA,KAAKzR,IAAK0R,CAAOA,OAAAA,GAAGnU,IAAI,CAAC,GAC/DoU,YAAwBlS,MAAM,CAAC,CAChC,GACK4R,UAAUc,eAAenS,IAAKyS,CAAAA,OAAOA,GAAGlV,IAAI;AAElD,MAAIsT,YAAY,OAAOzE,SAASqE,0BAA0BzR,MAAM,IAC5D4S,kBAAkBf;AAQtB,MANIA,UAAUgB,WAAWnB,YAAY,IACnCG,YAAYA,UAAUhH,MAAM,CAAC,IAE7B+H,kBAAkB,GAAGlB,YAAY,GAAGG,SAAS,IAG3C,CAACQ,QAAQ9C,SAASsC,SAAS;AAC7B,UAAM,IAAI/P,MAAM,kBAAkB8Q,eAAe,mBAAmB;AAGhElT,QAAAA,cAAc,OAAOyS,iBAAiBpS,qBAAqBC,MAAM,IACjE8S,aAAarT,oBAAoBC,WAAW;AAC9CoT,MAAAA;AACI,UAAA,IAAIhR,MAAMgR,UAAU;AAGxB,MAAA,CAACpS,SAAS6O,SAAS7P,WAAW;AAChC,UAAM,IAAIoC,MAAM,YAAYpC,WAAW,mBAAmB;AAG5D,QAAM0T,cAAcD,eAAetS,KAAMwS,CAASA,SAAAA,KAAK9U,SAASsT,SAAS;AAErEuB,MAAAA,eAAeA,YAAY1T,aAAa;AAC1C,QAAI0T,YAAY1T,gBAAgBA;AAC9B,YAAM,IAAIoC,MAAM,iBAAiB8Q,eAAe,sBAAsBlT,WAAW,EAAE;AAGhF8M,UAAMyG,SACT,MAAMjT,OAAOE,OAAO;AAAA,MAClBC,MAAM;AAAA,MACNnB,SAAS,oCAAoCoU,YAAY1T,WAAW;AAAA;AAAA;AAAA,MAEpEoN,QAASwG,CAAAA,UAAU,GAAGA,KAAK,GAAG3T,YAAY;AAAA,MAC1CS,UAAWkT,CACFA,UAAAA,UAAU,SAAS;AAAA,IAAA,CAE7B;AAAA,EAAA;AAID,MAAA;AACF,UAAMX,YAAwBlS,QAAQoR,WAAWnS,WAAW,GAC5D4C,OAAOS,MAAM,iBAAiB6P,eAAe,cAAclT,WAAW,eAAe;AAAA,WAC9Ed,KAAK;AACZ,UAAM,IAAIkD,MAAM;AAAA,EAA+BlD,IAAII,OAAO,EAAE;AAAA,EAAA;AAEhE;AC9DA,SAASwL,gBAAcnI,MAAyB;AAC9C,SAAOoI,uBAAMC,QAAAA,QAAQrI,KAAKsI,QAAQC,QAAQD,IAAI,EAAEE,MAAM,CAAC,CAAC,EAAEkI,OAAO,SAAS;AAAA,IAAC5S,MAAM;AAAA,EAAU,CAAA,EAAEwK;AAC/F;AAEa+I,MAAAA,qBAAoD,OAAOrR,MAAM/B,YAAY;AAClF,QAAA;AAAA,IAACC;AAAAA,IAAW+B;AAAAA,IAAQtC;AAAAA,MAAUM,SAC9B,CAAG8M,EAAAA,KAAK,IAAI/K,KAAKG,oBACjB;AAAA,IAACyQ;AAAAA,EAAAA,IAAS,MAAMzI,gBAAcnI,IAAI,GAClC5B,SAASF,UAET6R,GAAAA,YAAYhF,SAASoE,yBAAyBpE,KAAK;AACrDgF,MAAAA;AACI,UAAA,IAAItQ,MAAMsQ,SAAS;AAG3B,QAAMe,iBAAiB,MAAMR,YAAwBlS,MAAM;AAE3D,MAAIoR,YAAY,OAAOzE,SAASqE,0BAA0BzR,MAAM,IAC5D4S,kBAAkBf;AAElBA,YAAUgB,WAAWnB,YAAY,IACnCG,YAAYA,UAAUhH,MAAM,CAAC,IAE7B+H,kBAAkB,GAAGlB,YAAY,GAAGG,SAAS;AAI/C,QAAMuB,cAAcD,eAAetS,KAAMwS,CAASA,SAAAA,KAAK9U,SAASsT,SAAS;AACzE,MAAI,CAACuB;AACH,UAAM,IAAItR,MAAM,kBAAkB8Q,eAAe,kBAAkB;AAGrE,MAAI,CAACQ,YAAY1T;AACf,UAAM,IAAIoC,MAAM,kBAAkB8Q,eAAe,8BAA8B;AAG7EK,UACF3Q,OAAO0O,KAAK,2DAA2D4B,eAAe,GAAG,IAEzF,MAAM5S,OAAOE,OAAO;AAAA,IAClBC,MAAM;AAAA,IACNnB,SAAS,mEAAmEoU,YAAY1T,WAAW;AAAA;AAAA;AAAA,IAEnGoN,QAASwG,CAAAA,UAAU,GAAGA,KAAK,GAAG3T,YAAY;AAAA,IAC1CS,UAAWkT,CACFA,UAAAA,UAAU,SAAS;AAAA,EAAA,CAE7B;AAGC,MAAA;AACF,UAAM1C,SAAS,MAAM+B,YAAwBlS,QAAQoR,SAAS;AAC9DvP,WAAOS,MACL,iBAAiB6P,eAAe,kBAAkBhC,OAAOlR,WAAW,eACtE;AAAA,WACOd,KAAK;AACZ,UAAM,IAAIkD,MAAM;AAAA,EAAiClD,IAAII,OAAO,EAAE;AAAA,EAAA;AAElE,GC/DMiD,aAAW;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA,GAoCX0R,eAAqC;AAAA,EACzCpV,MAAM;AAAA,EACN4D,OAAO;AAAA,EACP3D,WAAW;AAAA,EAAA,UACXyD;AAAAA,EACAxD,aAAa;AAAA,EACb2D,QAAQ,OAAOC,MAAM/B,YAAY;AACzB,UAAA,CAACsT,IAAI,IAAIvR,KAAKG;AACpB,YAAQoR,MAAI;AAAA,MACV,KAAK;AACG1B,cAAAA,mBAAmB7P,MAAM/B,OAAO;AACtC;AAAA,MACF,KAAK;AACG0S,cAAAA,mBAAmB3Q,MAAM/B,OAAO;AACtC;AAAA,MACF,KAAK;AACGoT,cAAAA,mBAAmBrR,MAAM/B,OAAO;AACtC;AAAA,MACF,KAAK;AACGkT,cAAAA,iBAAiBnR,MAAM/B,OAAO;AACpC;AAAA,MACF;AACE,cAAM,IAAIwB,MAAMiO,iBAAAA;AAAAA;AAAAA;AAAAA,SAGf;AAAA,IAAA;AAAA,EACL;AAEJ;ACrDsB8D,eAAAA,oBACpBrH,OACAlM,SACe;AACT,QAAA;AAAA,IAACC;AAAAA,IAAW+B;AAAAA,IAAQC;AAAAA,EAAAA,IAASjC,SAC7BG,SAASF,aACToB,YAAYlB,OAAOoB,OAAO,EAAEF,WAC5BoD,QAA2C,CAAC;AAC9C7F,MAAAA;AAEAsN,QAAMsH,UAAUtH,MAAMsH,UAAU,MAClC/O,MAAM+O,SAAS,GAAGtH,MAAMsH,MAAM,KAE5BtH,MAAMxH,SAASwH,MAAMxH,QAAQ,MAC/BD,MAAMC,QAAQ,GAAGwH,MAAMxH,KAAK;AAG1B,MAAA;AACS,eAAA,MAAMvE,OAAOgC,QAAiC;AAAA,MACvDC,QAAQ;AAAA,MACRG,KAAK,aAAalB,SAAS;AAAA,MAC3BoD;AAAAA,IAAAA,CACD;AAAA,WACM9B,OAAO;AACVA,UAAMlE,aACRuD,OAAOW,MAAM,GAAGV,MAAMW,IAAI;AAAA,EAA8BD,MAAM/D,SAASC,KAAKH,OAAO,EAAE,CAAC;AAAA,CAAI,IAE1FsD,OAAOW,MAAM,GAAGV,MAAMW,IAAI;AAAA,EAA8BD,MAAMjE,OAAO,EAAE,CAAC;AAAA,CAAI;AAAA,EAAA;AAI5EE,MAAAA,YAAYA,SAASU,SAAS,GAAG;AAC7BkO,UAAAA,QAAQ,IAAIC,0BAAM;AAAA,MACtBE,OAAO;AAAA,MACPD,SAAS,CACP;AAAA,QAACzP,MAAM;AAAA,QAAM0P,OAAO;AAAA,QAAUC,WAAW;AAAA,MAAA,GACzC;AAAA,QAAC3P,MAAM;AAAA,QAAiB0P,OAAO;AAAA,QAAkBC,WAAW;AAAA,MAAA,GAC5D;AAAA,QAAC3P,MAAM;AAAA,QAAiB0P,OAAO;AAAA,QAAkBC,WAAW;AAAA,MAAA,GAC5D;AAAA,QAAC3P,MAAM;AAAA,QAAS0P,OAAO;AAAA,QAASC,WAAW;AAAA,MAAA,GAC3C;AAAA,QAAC3P,MAAM;AAAA,QAAe0P,OAAO;AAAA,QAAgBC,WAAW;AAAA,MAAA,GACxD;AAAA,QAAC3P,MAAM;AAAA,QAAe0P,OAAO;AAAA,QAAgBC,WAAW;AAAA,MAAA,GACxD;AAAA,QAAC3P,MAAM;AAAA,QAAa0P,OAAO;AAAA,QAAcC,WAAW;AAAA,MAAO,CAAA;AAAA,IAAA,CAE9D;AAEDhP,aAASmJ,QAAS0L,CAAQ,QAAA;AAClB,YAAA;AAAA,QAAC1O;AAAAA,QAAI2O;AAAAA,QAAO7F;AAAAA,QAAW8F;AAAAA,QAAWC;AAAAA,QAAe/B;AAAAA,QAAegC;AAAAA,MAAAA,IAAeJ;AAErF,UAAIK,cAAc;AACdjG,oBAAc,OAChBiG,cAAcC,QAAoBC,oBAAAA,QAAAA,SAASnG,SAAS,CAAC;AAGvD,UAAIoG,YAAY;AACZN,oBAAc,OAChBM,YAAYC,uBAAeF,QAAAA,SAASL,SAAS,GAAGK,QAAAA,SAASnG,SAAS,CAAC;AAGjEsG,UAAAA;AACJ,cAAQT,OAAK;AAAA,QACX,KAAK;AACK,kBAAA;AACR;AAAA,QACF,KAAK;AACK,kBAAA;AACR;AAAA,QACF,KAAK;AACK,kBAAA;AACR;AAAA,QACF;AACU,kBAAA;AAAA,MAAA;AAGZlG,YAAMM,OACJ;AAAA,QACE/I;AAAAA,QACA2O;AAAAA,QACAG;AAAAA,QACAC,aAAa,GAAGA,WAAW;AAAA,QAC3BG;AAAAA,QACAL;AAAAA,QACA/B;AAAAA,MAAAA,GAEF;AAAA,QAACsC;AAAAA,MAAAA,CACH;AAAA,IAAA,CACD,GAED3G,MAAMU,WAAW;AAAA,EACnB;AACElM,WAAOS,MAAM,iDAAiD;AAElE;AC5GO,MAAM2R,eAAeA,CAACjU,QAAsBoC,KAAa8R,SAAS,OAAkB;AACnF9S,QAAAA,SAASpB,OAAOoB,OAAO;AAEtB,SAAA,GADM8S,SAAS9S,OAAO+S,SAAS/S,OAAO6E,GAC/B,IAAI7D,IAAIuN,QAAQ,OAAO,EAAE,CAAC;AAC1C,GCOMnO,aAAW;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAuCjB,SAASuI,gBAAcnI,MAAyB;AAC9C,SAAOoI,uBAAMC,QAAAA,QAAQrI,KAAKsI,QAAQC,QAAQD,IAAI,EAAEE,MAAM,CAAC,CAAC,EACrDkI,OAAO,UAAU;AAAA,IAAC5S,MAAM;AAAA,EAAA,CAAS,EACjC4S,OAAO,QAAQ;AAAA,IAAC5S,MAAM;AAAA,EAAA,CAAU,EAChC4S,OAAO,SAAS;AAAA,IAAC5S,MAAM;AAAA,EAAA,CAAS,EAChC4S,OAAO,UAAU;AAAA,IAAC5S,MAAM;AAAA,EAAA,CAAS,EACjC4S,OAAO,gBAAgB;AAAA,IAAC5S,MAAM;AAAA,EAAA,CAAU,EACxC4S,OAAO,UAAU;AAAA,IAAC5S,MAAM;AAAA,EAAU,CAAA,EAAEwK;AACzC;AAEA,MAAMpG,WAAYmC,CAAAA,SACT,IAAImO,KAAAA,WAAqCC,CAAa,aAAA;AAC3D,MAAIC,iBAAiB,IAAIC,qBAAAA,QAAYtO,IAAG,GACpCuO,UAAU;AAEd,WAASC,QAAQjS,OAAgB;AAC3B8R,sBACFA,eAAeI,MAGjB5V,GAAAA,QAAM,mBAAmB0D,KAAK,EAAE,GAC5BgS,CAGJH,YAAAA,SAASM,KAAK;AAAA,MAACjV,MAAM;AAAA,IAAY,CAAA,GACjC4U,iBAAiB,IAAIC,6BAAYtO,IAAG;AAAA,EAAA;AAGtC,WAAS2O,eAAepS,OAAqB;AAC3CgS,cAAU,IACVF,eAAeI,MACfL,GAAAA,SAAS7R,MAAMA,KAAK;AAAA,EAAA;AAGtB,WAASqS,UAAUC,OAAqB;AACtC,UAAMnW,OAAOC,KAAKkP,MAAMgH,MAAMnW,IAAI;AAC9BA,SAAK4U,UAAU,YACjBzU,QAAM,wBAAwBgW,KAAK,GACnCT,SAAS7R,MAAMsS,KAAK,KACXnW,KAAK4U,UAAU,eACxBzU,QAAM,2BAA2BgW,KAAK,GACtCC,WAAW,MAEXjW,QAAM,4BAA4BgW,KAAK,GACvCT,SAASM,KAAKhW,IAAI;AAAA,EAAA;AAItB,WAASoW,aAAa;AACLC,mBAAAA,oBAAoB,SAASP,OAAO,GACnDH,eAAeU,oBAAoB,iBAAiBJ,cAAc,GAClEN,eAAeU,oBAAoB,OAAOH,SAAS,GACnDP,eAAeU,oBAAoB,QAAQD,UAAU,GACrDT,eAAeI,MAAAA,GACfL,SAASY,SAAS;AAAA,EAAA;AAGpBX,iBAAeY,iBAAiB,SAAST,OAAO,GAChDH,eAAeY,iBAAiB,iBAAiBN,cAAc,GAC/DN,eAAeY,iBAAiB,OAAOL,SAAS,GAChDP,eAAeY,iBAAiB,QAAQH,UAAU;AACpD,CAAC,GAGGI,iBAAiBA,CACrBC,OACApV,QACA6B,WACkB;AAClB,MAAIwT,kBAAkB;AAEtB,QAAMhN,UAAUxG,OAAOwG,QAAQ,CAAE,CAAA,EAAEC,MAAM,GACnCgN,YAAYrB,aAAajU,QAAQ,QAAQoV,KAAK,SAAS;AAEvD,SAAAtW,QAAA,gBAAgBwW,SAAS,EAAE,GAE1B,IAAItS,QAAQ,CAACC,SAASC,WAAW;AAC7BoS,aAAAA,SAAS,EAAEC,UAAU;AAAA,MAC5BZ,MAAOG,CAAU,UAAA;AACX,eAAOA,MAAMhR,YAAa,aAC5BuR,kBAAkBP,MAAMhR,WAG1BuE,QAAQU,OAAO,qBAAqBsM,eAAe;AAAA,MACrD;AAAA,MACA7S,OAAQrE,CAAQ,QAAA;AACNgL,gBAAAA,QACRjG,OAAO,IAAI7B,MAAM,GAAGlD,IAAIQ,IAAI,EAAE,CAAC;AAAA,MACjC;AAAA,MACAsW,UAAUA,MAAM;AACNhM,gBAAAA,QAAQ,gBAAgB,GAChChG,QAAQ;AAAA,MAAA;AAAA,IACV,CACD;AAAA,EAAA,CACF;AACH,GAEMuS,qBAA6D;AAAA,EACjE1X,MAAM;AAAA,EACN4D,OAAO;AAAA,EACP3D,WAAW;AAAA,EAAA,UACXyD;AAAAA,EACAxD,aACE;AAAA,EACF2D,QAAQ,OAAOC,MAAM/B,YAAY;AACzB,UAAA;AAAA,MAACC;AAAAA,MAAW+B;AAAAA,MAAQtC;AAAAA,MAAQuC;AAAAA,IAAAA,IAASjC,SAErCkM,QAA0B,MAAMhC,gBAAcnI,IAAI,GAClD5B,SAASF,UAAU;AAEzB,QAAIiM,MAAM7L,MAAM;AACRkT,YAAAA,oBAAoBrH,OAAOlM,OAAO;AACxC;AAAA,IAAA;AAGF,QAAIkM,MAAM0J,QAAQ;AAChB,YAAML,QAAQrJ,MAAM0J;AAEpB,UAAI,CAACL;AACG,cAAA,IAAI/T,MAAM,uBAAuB;AAGnC8T,YAAAA,eAAeC,OAAOpV,QAAQ6B,MAAM;AAC1C;AAAA,IAAA;AAGF,UAAM,CAAC4R,eAAe/B,aAAa,IAAI9P,KAAKG,oBACtC2T,oBAAoBvG,CAAQpD,CAAAA,MAAM,cAAc,GAEhD4F,YAAY8B,iBAAiBzU,oBAAoByU,aAAa;AAChE9B,QAAAA;AACI,YAAA,IAAItQ,MAAMsQ,SAAS;AAG3B,UAAMgE,mBAAmB,MAAM3V,OAAOC,SACnCC,KAAK,EACL6R,KAAM9R,CAAaA,aAAAA,SAASM,IAAK0R,CAAOA,OAAAA,GAAGnU,IAAI,CAAC,GAE7C8X,oBAAoB,OAAOnC,iBAC/BnU,qBAAqBC,QAAQ;AAAA,MAAChB,SAAS;AAAA,IAAA,CAAuB;AAC5D,QAAA,CAACoX,iBAAiB7G,SAAS8G,iBAAiB;AAC9C,YAAM,IAAIvU,MAAM,mBAAmBuU,iBAAiB,iBAAiB;AAGvE,UAAMC,oBAAoB,OAAOnE,iBAC/BpS,qBAAqBC,QAAQ;AAAA,MAAChB,SAAS;AAAA,IAAA,CAAuB;AAC5DoX,QAAAA,iBAAiB7G,SAAS+G,iBAAiB;AAC7C,YAAM,IAAIxU,MAAM,mBAAmBwU,iBAAiB,kBAAkB;AAGlE1X,UAAAA,MAAMa,oBAAoB6W,iBAAiB;AAC7C1X,QAAAA;AACI,YAAA,IAAIkD,MAAMlD,GAAG;AAGjB,QAAA;AACIM,YAAAA,WAAW,MAAMuB,OAAOgC,QAA6B;AAAA,QACzDC,QAAQ;AAAA,QACRG,KAAK,aAAawT,iBAAiB;AAAA,QACnClX,MAAM;AAAA,UACJgT,eAAemE;AAAAA,UACfC,aAAaJ;AAAAA,QAAAA;AAAAA,MACf,CACD;AAcD,UAZA7T,OAAOS,MACL,mBAAmBR,MAAMS,MAAMqT,iBAAiB,CAAC,OAAO9T,MAAMS,MAAMsT,iBAAiB,CAAC,KACxF,GAEKH,qBACH7T,OAAOS,MACL,+GACF,GAGFT,OAAOS,MAAM,OAAOR,MAAMS,MAAM9D,SAAS2W,KAAK,CAAC,UAAU,GAErDrJ,MAAMgK;AACR;AAGF,YAAMZ,eAAe1W,SAAS2W,OAAOpV,QAAQ6B,MAAM,GACnDA,OAAOS,MAAM,OAAOR,MAAMS,MAAM9D,SAAS2W,KAAK,CAAC,YAAY;AAAA,aACpD5S,OAAO;AACVA,YAAMlE,aACRuD,OAAOS,MAAM,GAAGR,MAAMW,IAAI;AAAA,EAA4BD,MAAM/D,SAASC,KAAKH,OAAO,EAAE,CAAC;AAAA,CAAI,IAExFsD,OAAOS,MAAM,GAAGR,MAAMW,IAAI;AAAA,EAA4BD,MAAMjE,OAAO,EAAE,CAAC;AAAA,CAAI;AAAA,IAAA;AAAA,EAE9E;AAEJ,GC7OMiD,aAAW;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA,GAUXwU,eAAe,CAAC,WAAW,UAAU,QAAQ,GAM7CC,uBAA0D;AAAA,EAC9DnY,MAAM;AAAA,EACN4D,OAAO;AAAA,EACP3D,WAAW;AAAA,EAAA,UACXyD;AAAAA,EACAxD,aAAa;AAAA,EACb2D,QAAQ,OAAOC,MAAM/B,YAAY;AACzB,UAAA;AAAA,MAACC;AAAAA,MAAW+B;AAAAA,MAAQtC;AAAAA,IAAAA,IAAUM,SAC9BkM,QAAQnK,KAAKyO,YACb,CAAChQ,OAAO,IAAIuB,KAAKG,oBACjB/B,SAASF,UAAU,GAEnB6R,YAAYtR,WAAWrB,oBAAoBqB,OAAO;AACpDsR,QAAAA;AACI,YAAA,IAAItQ,MAAMsQ,SAAS;AAGrB,UAAA,CAAC1R,UAAU4R,eAAe,IAAI,MAAM7O,QAAQ8O,IAAI,CACpD9R,OAAOC,SAASC,OAAO6R,KAAMC,CAAAA,SAASA,KAAKzR,IAAK0R,CAAAA,OAAOA,GAAGnU,IAAI,CAAC,GAC/DkC,OAAOgC,QAAQ;AAAA,MAACI,KAAK;AAAA,IAAY,CAAA,CAAC,CACnC;AAED,QAAI2J,MAAMmK,cAAc,CAACF,aAAalH,SAAS/C,MAAMmK,UAAU;AAC7D,YAAM,IAAI7U,MAAM,oBAAoB0K,MAAMmK,UAAU,eAAe;AAGrE,UAAMjX,cAAc,OAAOoB,WAAWf,qBAAqBC,MAAM;AAC7DU,QAAAA,SAAS6O,SAAS7P,WAAW;AAC/B,YAAM,IAAIoC,MAAM,YAAYpC,WAAW,kBAAkB;AAGrDkX,UAAAA,mBAAmBtE,gBAAgB/C,SAAS,gBAAgB;AAC5DhQ,YAAA,8BAA8BqX,mBAAmB,QAAQ,QAAQ;AAGjEC,UAAAA,UAAU,QADOD,mBAAmBpK,MAAMmK,aAAa,aACpBG,2BAA2B9W,QAAQsC,MAAM;AAE9E,QAAA;AACI7B,YAAAA,OAAOC,SAASc,OAAO9B,aAAa;AAAA,QAACmX;AAAAA,MAAAA,CAAQ,GACnDvU,OAAOS,MAAM,8BAA8B;AAAA,aACpCnE,KAAK;AACZ,YAAM,IAAIkD,MAAM;AAAA,EAA6BlD,IAAII,OAAO,EAAE;AAAA,IAAA;AAAA,EAC5D;AAEJ;AAEA,eAAe8X,2BAA2B9W,QAAqBsC,QAAsB;AAC7EyU,QAAAA,OAAO,MAAM/W,OAAOE,OAA6B;AAAA,IACrDC,MAAM;AAAA,IACNnB,SAAS;AAAA,IACTmC,SAAS,CACP;AAAA,MACEF,OAAO;AAAA,MACP1C,MAAM;AAAA,IAAA,GAER;AAAA,MACE0C,OAAO;AAAA,MACP1C,MAAM;AAAA,IACP,CAAA;AAAA,EAAA,CAEJ;AAEGwY,SAAAA,SAAS,aACXzU,OAAOS,MACL;AAAA,CACF,GAGKgU;AACT;AC3FA,IAAe,eAAA;AAAA,EACbxY,MAAM;AAAA,EACNC,WAAW;AAAA,EACXE,aAAa;AAAA,EACbD,aAAa;AACf;ACDA,MAAMuY,2BAAiD;AAAA,EACrDzY,MAAM;AAAA,EACN4D,OAAO;AAAA,EACPF,UAAU;AAAA,EACVzD,WAAW;AAAA,EACXC,aAAa;AAAA,EACb2D,QAAQ,OAAOC,MAAM/B,YAAY;AACzB,UAAA;AAAA,MAACC;AAAAA,MAAW+B;AAAAA,IAAAA,IAAUhC,SACtB,CAAC8B,QAAQsQ,IAAImE,OAAO,IAAIxU,KAAKG,oBAC7B/B,SAASF,UAAU;AAErB,QAAA,CAACE,OAAOC,SAASuW;AACnB,YAAM,IAAInV,MAAM;AAAA,6BAAmE;AAGrF,QAAI,CAACM;AACG,YAAA,IAAIN,MAAM,mCAAmC;AAGrD,QAAI,CAAC,CAAC,OAAO,KAAK,EAAEyN,SAASnN,MAAM;AAC3B,YAAA,IAAIN,MAAM,uCAAuC;AAGzD,QAAI,CAAC4Q;AACG,YAAA,IAAI5Q,MAAM,+BAA+B;AAG7CM,QAAAA,WAAW,SAAS,CAACyU;AACjB,YAAA,IAAI/U,MAAM,mDAAmD;AAGrE,UAAMhB,UAAU,GAAG4R,EAAE,IACfQ,UAAUzT,oBAAoBqB,OAAO;AACvCoS,QAAAA;AACI,YAAA,IAAIpR,MAAMoR,OAAO;AAGnB5J,UAAAA,WAAW,MAAM7I,OAAOC,SAASC,KAAAA,GAAQE,KAAMqW,CAAAA,SAASA,KAAK3Y,SAASuC,OAAO;AAEnF,QAAI,CAACwI;AACG,YAAA,IAAIxH,MAAM,mBAAmB;AAGrC,QAAIM,WAAW,OAAO;AACbW,aAAAA,MAAMuG,QAAQuN,OAAO;AAC5B;AAAA,IAAA;AAGEvN,QAAAA,QAAQuN,YAAYA,SAAS;AACxB9T,aAAAA,MAAM,uBAAuB8T,OAAO,QAAQ;AACnD;AAAA,IAAA;AAGEA,gBAAY,aACdvU,OAAOS,MACL;AAAA,CACF,GAGF,MAAMtC,OAAOC,SAASuW,KAAKnW,SAAS;AAAA,MAAC+V;AAAAA,IAAAA,CAAyC,GAC9EvU,OAAOS,MAAM,4BAA4B;AAAA,EAAA;AAE7C,GC5DMd,aAAW;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAUjB,SAASuI,gBAAcnI,MAAyB;AAC9C,SAAOoI,uBAAMC,QAAAA,QAAQrI,KAAKsI,QAAQC,QAAQD,IAAI,EAAEE,MAAM,CAAC,CAAC,EAAEkI,OAAO,SAAS;AAAA,IAAC5S,MAAM;AAAA,EAAU,CAAA,EAAEwK;AAC/F;AAMA,MAAMwM,uBAAiE;AAAA,EACrE5Y,MAAM;AAAA,EACN4D,OAAO;AAAA,EAAA,UACPF;AAAAA,EACAzD,WAAW;AAAA,EACXC,aAAa;AAAA,EACb2D,QAAQ,OAAOC,MAAM/B,YAAY;AACzB,UAAA;AAAA,MAACC;AAAAA,MAAWP;AAAAA,MAAQsC;AAAAA,QAAUhC,SAC9B;AAAA,MAAC2S;AAAAA,IAAAA,IAAS,MAAMzI,gBAAcnI,IAAI,GAClC,CAACqQ,EAAE,IAAIrQ,KAAKG;AAClB,QAAI,CAACkQ;AACG,YAAA,IAAI5Q,MAAM,+BAA+B;AAGjD,UAAMhB,UAAU,GAAG4R,EAAE,IACfQ,UAAUzT,oBAAoBqB,OAAO;AACvCoS,QAAAA;AACIA,YAAAA;AAGJD,YACF3Q,OAAO0O,KAAK,4DAA4DlQ,OAAO,GAAG,IAElF,MAAMd,OAAOE,OAAO;AAAA,MAClBC,MAAM;AAAA,MACNnB,SACE;AAAA;AAAA,MACF8N,QAASwG,CAAAA,UAAU,GAAGA,KAAK,GAAGC,KAAK;AAAA,MACnCnT,UAAWkT,CACFA,UAAAA,UAAUxS,WAAW;AAAA,IAAA,CAE/B,GAGH,MAAMP,UAAU,EAAEG,SAAS0W,OAAOtW,OAAO,GACzCwB,OAAOS,MAAM,8BAA8B;AAAA,EAAA;AAE/C,GClDMsU,OAAOA,MAAM,MAEbpV,aAAW;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAwCjB,SAASqV,aAAWC,UAA0C;AAC5D,QAAM/K,QAA2B,CAAC;AAClC,SAAI+K,SAASC,UACXhL,MAAMgL,QAAQ,GAAGD,SAASC,KAAK,GAAGC,MAAM,GAAG,IAGzCF,SAAS,mBAAmB,MAC9B/K,MAAMkL,mBAAmBC,SAASJ,SAAS,mBAAmB,GAAG,EAAE,IAGjE,OAAOA,SAASK,MAAQ,QAC1BpL,MAAMoL,MAAMhI,CAAAA,CAAQ2H,SAASK,MAG3B,OAAOL,SAASM,SAAW,QAC7BrL,MAAMqL,SAASjI,CAAQ2H,CAAAA,SAASM,SAG9B,OAAON,SAASO,SAAW,QAC7BtL,MAAMsL,SAASlI,CAAQ2H,CAAAA,SAASO,SAG9B,OAAOP,SAASQ,WAAa,QAC/BvL,MAAMuL,WAAWnI,CAAAA,CAAQ2H,SAASQ,WAGhC,OAAOR,SAASxK,YAAc,QAChCP,MAAMO,YAAY6C,CAAQ2H,CAAAA,SAASxK,YAGjC,OAAOwK,SAASR,OAAS,QAC3BvK,MAAMuK,OAAOQ,SAASR,OAGjBvK;AACT;AASA,MAAMwL,uBAA0D;AAAA,EAC9DzZ,MAAM;AAAA,EACN4D,OAAO;AAAA,EACP3D,WAAW;AAAA,EACXC,aAAa;AAAA,EAAA,UACbwD;AAAAA,EACAG,QAAQ,OAAOC,MAAM/B,YAAY;AACzB,UAAA;AAAA,MAACC;AAAAA,MAAW+B;AAAAA,MAAQC;AAAAA,MAAOkK;AAAAA,MAASzM;AAAAA,IAAUM,IAAAA,SAC9CG,SAASF,aACT,CAAC4R,eAAe8F,iBAAiB,IAAI5V,KAAKG,oBAC1CgK,QAAQ8K,aAAWjV,KAAKyO,UAAU;AAExC,QAAIhQ,UAAUqR,gBAAgB,GAAGA,aAAa,KAAK;AAC9CrR,gBACHA,UAAU,MAAMT,oBAAoBC,SAAS;AAAA,MAACtB,SAAS;AAAA,IAAA,CAA2B;AAG9EkU,UAAAA,UAAUzT,oBAAoBqB,OAAO;AACvCoS,QAAAA;AACIA,YAAAA;AAKJ,QAAA,EADa,MAAMzS,OAAOC,SAASC,KAAAA,GACzBE,KAAM4I,CAAAA,QAAQA,IAAIlL,SAASuC,OAAO;AAC9C,YAAM,IAAIgB,MAAM,sBAAsBhB,OAAO,aAAa;AAItD,UAAA;AAAA,MAACa;AAAAA,IAAAA,IAAalB,OAAOoB,OAAO;AAE3BkB,WAAAA,MAAM,wSAAmD,GAChET,OAAOS,MAAM,6DAAmD,GAChET,OAAOS,MAAM,6DAAmD,GAChET,OAAOS,MAAM,UAAKR,MAAM2I,KAAK,WAAW,CAAC,KAAK3I,MAAM4I,KAAKxJ,SAAS,EAAEyJ,OAAO,EAAE,CAAC,SAAI,GAClF9I,OAAOS,MAAM,UAAKR,MAAM2I,KAAK,SAAS,CAAC,KAAK3I,MAAM4I,KAAKrK,OAAO,EAAEsK,OAAO,EAAE,CAAC,SAAI,GAC9E9I,OAAOS,MAAM,6DAAmD,GAChET,OAAOS,MAAM,wSAAmD,GAChET,OAAOS,MAAM,EAAE;AAEf,QAAImV,kBAAkBD;AACjBC,wBACHA,kBAAkB,MAAMlY,OAAOE,OAAO;AAAA,MACpCC,MAAM;AAAA,MACNnB,SAAS;AAAA,MACTsC,SAASyF,cAAKU,QAAAA,KAAKgF,SAAS,GAAG3L,OAAO,SAAS;AAAA,MAC/CgM,QAAQD,KAAAA;AAAAA,IAAAA,CACT;AAGH,UAAMsL,aAAa,MAAMC,cAAcF,iBAAiBpX,SAASd,QAAQwM,KAAK;AAC9E,QAAI,CAAC2L,YAAY;AACf7V,aAAOS,MAAM,WAAW;AACxB;AAAA,IAAA;AAIEoV,mBAAe,OACjB7V,OAAOS,MAAM,sBAAsBR,MAAM4I,KAAKrK,OAAO,CAAC,SAASyB,MAAM4I,KAAKgN,UAAU,CAAC,GAAG;AAG1F,QAAIE,cAAc,0BACdvP,UAAUxG,OAAOwG,QAAQuP,WAAW,EAAEtP,MAAM;AAChD,UAAMuP,aAAc/T,CAA4BA,cAAA;AAC1CA,MAAAA,UAAS0E,SAASoP,eACpBvP,QAAQY,WACRZ,UAAUxG,OAAOwG,QAAQvE,UAAS0E,IAAI,EAAEF,WAC/BxE,UAAS0E,SAASoP,eAAe9T,UAASoF,WACnDb,QAAQU,OAAO,GAAGjF,UAAS0E,IAAI,KAAK1E,UAAS+E,OAAO,IAAI/E,UAASgF,KAAK,MAGxE8O,cAAc9T,UAAS0E;AAAAA,IAAAA,GAGnBF,QAAQG,KAAKC,IAAI;AACnB,QAAA;AACF,YAAMoP,+BAAc;AAAA,QAClB9X;AAAAA,QACAK;AAAAA,QACAqX;AAAAA,QACAG;AAAAA,QACA,GAAG9L;AAAAA,MAAAA,CACJ,GACD1D,QAAQY,QAAQ;AAAA,aACT9K,KAAK;AACZkK,YAAAA,QAAQc,QACFhL;AAAAA,IAAAA;AAGDmE,WAAAA,MAAM,oBAAoBsG,kBAASH,QAAAA,KAAKC,QAAQJ,KAAK,CAAC,GAAG;AAAA,EAAA;AAEpE;AAGA,eAAeqP,cACbI,aACA1X,SACAd,QACAwM,OACA;AACA,MAAIgM,gBAAgB;AACX,WAAA;AAGHC,QAAAA,UAAU1R,cAAAA,QAAK2R,WAAWF,WAAW,IACvCA,cACAzR,cAAAA,QAAKrD,QAAQkH,QAAQmG,IAAI,GAAGyH,WAAW;AAE3C,MAAIG,WAAW,MAAMnU,sBAAGoU,KAAKH,OAAO,EAAEI,MAAMxB,IAAI;AAC1CyB,QAAAA,gBAAgBH,WAAWA,SAASI,OAAO,IAAIhS,cAAAA,QAAKC,SAASyR,OAAO,EAAEO,QAAQ,GAAG,MAAM;AAE7F,MAAI,CAACL,UAAU;AACb,UAAMM,aAAaH,gBAAgB/R,cAAAA,QAAKkG,QAAQwL,OAAO,IAAIA;AAErDjU,UAAAA,cAAAA,QAAG0U,MAAMD,YAAY;AAAA,MAACvN,WAAW;AAAA,IAAA,CAAK;AAAA,EAAA;AAGxCyN,QAAAA,YAAYL,gBAAgBL,UAAU1R,cAAAA,QAAKU,KAAKgR,SAAS,GAAG3X,OAAO,SAAS;AAGlF,SAFA6X,WAAW,MAAMnU,sBAAGoU,KAAKO,SAAS,EAAEN,MAAMxB,IAAI,GAE1C,CAAC7K,MAAMO,aAAa4L,YAAYA,SAASI,OAAAA,KAOvC,CANoB,MAAM/Y,OAAOE,OAAO;AAAA,IAC1CC,MAAM;AAAA,IACNnB,SAAS,SAASma,SAAS;AAAA,IAC3B7X,SAAS;AAAA,EAAA,CACV,IAGQ,KAIJ6X;AACT;ACtNA,MAAMnJ,SAAUoJ,CAAAA,QAAgB,WAAaA,GAAG,YAE1CnX,aAAW;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AA8DjB,SAASoX,YAAYC,MAAoC;AACvD,SAAO,OAAOA,OAAS,MAAc/X,SAAYqO,CAAQ0J,CAAAA;AAC3D;AAEA,SAAShC,WAAWC,UAA0C;AACtDgC,QAAAA,gCAAgCF,YAAY9B,SAAS,mCAAmC,CAAC,GACzFiC,qBAAqBH,YAAY9B,SAAS,sBAAsB,CAAC,GACjEG,mBAAmB2B,YAAY9B,SAAS,mBAAmB,CAAC,GAC5DkC,gBAAgBJ,YAAY9B,SAAS,gBAAgB,CAAC,GACtDmC,6BAA6BL,YAAY9B,SAAS,+BAA+B,CAAC,GAClFoC,uBAAuBN,YAAY9B,SAAS,wBAAwB,CAAC,GACrEnH,UAAUiJ,YAAY9B,SAASnH,OAAO,GACtCwJ,UAAUP,YAAY9B,SAASqC,OAAO;AACrC,SAAA;AAAA,IACLL;AAAAA,IACAC;AAAAA,IACA9B;AAAAA,IACAgC;AAAAA,IACAC;AAAAA,IACAF;AAAAA,IACArJ;AAAAA,IACAwJ;AAAAA,EACF;AACF;AAEA,MAAMC,uBAA6C;AAAA,EACjDtb,MAAM;AAAA,EACN4D,OAAO;AAAA,EACP3D,WAAW;AAAA,EACXC,aAAa;AAAA,EAAA,UACbwD;AAAAA;AAAAA,EAEAG,QAAQ,OAAOC,MAAM/B,YAAY;AACzB,UAAA;AAAA,MAACC;AAAAA,MAAW+B;AAAAA,MAAQC;AAAAA,MAAOuX;AAAAA,QAAmBxZ,SAC9CkM,QAAQ8K,WAAWjV,KAAKyO,UAAU,GAClC;AAAA,MACJyI;AAAAA,MACAC;AAAAA,MACA9B;AAAAA,MACAgC;AAAAA,MACAC;AAAAA,MACAF;AAAAA,IACEjN,IAAAA,OAEExG,YAAY+T,qBAAqB1X,KAAKyO,UAAU,GAChDrQ,SAASF,UAET,GAAA,CAAC+H,MAAM0R,MAAM,IAAI3X,KAAKG;AAC5B,QAAI,CAAC8F;AACH,YAAM,IAAIxG,MACR,iFAAiFS,MAAM2I,KACrF,QACF,CAAC,cACH;AAGF,UAAMiH,gBAAgB,MAAM8H,uBAAuBD,QAAQ1Z,OAAO;AAC5Df,YAAA,mCAAmC4S,aAAa,GAAG;AAEnD+H,UAAAA,QAAQ,gBAAgBpa,KAAKwI,IAAI;AACnC6R,QAAAA,aACAC,YACAC,iBAAiB;AAEjBH,QAAAA;AACF3a,cAAM,2CAA2C,GACjD4a,cAAc,MAAMG,aAAahS,IAAI;AAAA,SAChC;AACL,YAAMiS,aAAaxT,cAAAA,QAAKrD,QAAQkH,QAAQmG,OAAOzI,IAAI,GAC7CkS,YAAY,MAAMhW,sBAAGoU,KAAK2B,UAAU,EAAE1B,MAAM,MAAM,IAAI;AAC5D,UAAI,CAAC2B;AACH,cAAM,IAAI1Y,MAAM,GAAGyY,UAAU,oCAAoC;AAGnEF,uBAAiBG,UAAUC,YAAAA,GACvBJ,iBACFF,cAAcI,cAEdH,aAAarT,cAAAA,QAAKkG,QAAQsN,UAAU,GACpCJ,cAAc,MAAMO,GAAAA,iBAAiBH,UAAU;AAAA,IAAA;AAInD,UAAMI,eAAela,OAAOma,MAAM,EAAE/Y,OAAO;AAAA,MAACf,SAASqR;AAAAA,IAAAA,CAAc,GAG7D;AAAA,MAACxQ;AAAAA,MAAWb;AAAAA,IAAAA,IAAW6Z,aAAa9Y,OAAO;AAE1CkB,WAAAA,MAAM,wSAAmD,GAChET,OAAOS,MAAM,6DAAmD,GAChET,OAAOS,MAAM,6DAAmD,GAChET,OAAOS,MAAM,UAAKR,MAAM2I,KAAK,WAAW,CAAC,KAAK3I,MAAM4I,KAAKxJ,SAAS,EAAEyJ,OAAO,EAAE,CAAC,SAAI,GAClF9I,OAAOS,MAAM,UAAKR,MAAM2I,KAAK,SAAS,CAAC,KAAK3I,MAAM4I,KAAKrK,OAAO,EAAEsK,OAAO,EAAE,CAAC,SAAI,GAC9E9I,OAAOS,MAAM,6DAAmD,GAChET,OAAOS,MAAM,wSAAmD,GAChET,OAAOS,MAAM,EAAE;AAEf,QAAIsV,aACAvC,iBACA+E,WACAC,eAAsD,MACtDC;AAEJ,aAASzC,WAAWvN,MAAqB;AACvC,YAAMiQ,mBAAmBjQ,KAAKxB,OACxB0R,WAAWlQ,KAAK9B,QAAQoP;AAU9B,UATA0C,UAAUG,cAAcnQ,IAAI,GAExBiQ,oBAAoBjQ,KAAKxB,UAAUwB,KAAKzB,YACtCwR,gBACFK,cAAcL,YAAY,GAE5BA,eAAe,OAGbG;AACF;AAIF,YAAMG,WAAW/C,aACXgD,gBAAgBR,aAAa3R,KAAKC,IAAI;AAC5C0R,UAAAA,YAAY3R,KAAKC,OACjBkP,cAActN,KAAK9B,MAEf6M,mBAAmBA,gBAAgBpM,SAAS;AAC9C,cAAM4R,YAAYjS,kBAAAA,QAASH,KAAKC,IAAAA,IAAQkS,eAAe;AAAA,UACrDE,sBAAsB;AAAA,QAAA,CACvB;AACDzF,wBAAgBtM,OAAO,UAAU4R,QAAQ,KAAKE,SAAS,KACvDxF,gBAAgBpM,QAAQ;AAAA,MAAA;AAG1BoM,wBAAkBxT,OAAOwG,QAAQ,QAAQiC,KAAK9B,IAAI,UAAU,EAAEF,MAE1D+R,GAAAA,iBACFK,cAAcL,YAAY,GAC1BA,eAAe,OAGjBA,eAAeU,YAAY,MAAM;AAC/B,cAAMF,YAAYjS,kBAAAA,QAASH,KAAKC,IAAAA,IAAQkS,eAAe;AAAA,UACrDE,sBAAsB;AAAA,QAAA,CACvB;AAEGzF,4BACFA,gBAAgBtM,OAAO,GAAGuR,OAAO,GAAGhQ,KAAK9B,IAAI,KAAKqS,SAAS;AAAA,SAE5D,EAAE;AAAA,IAAA;AAGP,aAASG,QAAQ;AAAA,MAACC;AAAAA,IAAAA,GAA8B;AAC1CZ,UAAAA,gBACFK,cAAcL,YAAY,GAG5BA,eAAe,MAEXY,WAAWb,aAAa/E,iBAAiB;AAC3C,cAAMwF,YAAYjS,kBAAAA,QAASH,KAAKC,IAAAA,IAAQ0R,WAAW;AAAA,UACjDU,sBAAsB;AAAA,QAAA,CACvB;AACDzF,wBAAgBtM,OAAO,UAAU6O,WAAW,KAAKiD,SAAS,KAC1DxF,gBAAgBpM,QAAQ;AAAA,MAAA,MACfoM,oBACTA,gBAAgBlM,KAAK;AAAA,IAAA;AAKrB,QAAA;AACI,YAAA;AAAA,QAAC+R;AAAAA,QAASC;AAAAA,MAAAA,IAAY,MAAMC,sBAAAA,QAAa1B,aAAa;AAAA,QAC1D1Z,QAAQka;AAAAA,QACRP;AAAAA,QACApU;AAAAA,QACAsS;AAAAA,QACAkB;AAAAA,QACAD;AAAAA,QACAG;AAAAA,QACAC;AAAAA,QACAjC;AAAAA,QACA+B;AAAAA,MAAAA,CACD;AAEO,cAAA;AAAA,QAACiC,SAAS;AAAA,MAAA,CAAK,GAEvBpZ,OAAOS,MAAM;AAAA,GAAiD4Y,SAASxJ,aAAa,GACpF2J,cAAcF,UAAUtZ,MAAM;AAAA,aACvB1D,KAAK;AASZ,UARA6c,QAAQ;AAAA,QAACC,SAAS;AAAA,MAAM,CAAA,GAQpB,EALF,CAAC5B,mBACDlb,IAAIM,YACJN,IAAIM,SAASH,eAAe,OAC5BH,IAAIqK,SAAS;AAGPrK,cAAAA;AAGFI,YAAAA,UAAU,CACdJ,IAAII,SACJ,IACA,6BACA,yDACA,gEACA,EAAE,EACFyI,KAAK;AAAA,CAAI,GAGLxE,QAAQ,IAAInB,MAAM9C,OAAO;AACzB+c,YAAAA,MAAAA,UAAUnd,IAAImd,SACpB9Y,MAAM/D,WAAWN,IAAIM,UACrB+D,MAAM+Y,eAAepd,IAAIod,cAEnB/Y;AAAAA,IAAAA;AAAAA,EACR;AAEJ;AAEA,eAAegX,uBAAuBD,QAAgB1Z,SAA4B;AAC1E,QAAA;AAAA,IAACC;AAAAA,IAAW+B;AAAAA,IAAQtC;AAAAA,EAAAA,IAAUM,SAC9BG,SAASF,UAAU;AAEzB,MAAIyZ,QAAQ;AACJ9G,UAAAA,UAAUzT,oBAAoBua,MAAM;AACtC9G,QAAAA;AACI,YAAA,IAAIpR,MAAMoR,OAAO;AAAA,EAAA;AAI3B3T,UAAM,6BAA6B;AAC7BuJ,QAAAA,UAAUxG,OAAOwG,QAAQ,6BAA6B,EAAEC,MAAM,GAC9DrI,WAAW,MAAMD,OAAOC,SAASC,KAAK;AAC5CmI,UAAQY,QAAQ,oCAAoC;AAEpD,MAAIyI,gBAAgB6H,SAAS,GAAGA,MAAM,KAAK;AAC3C,MAAI,CAAC7H;AACa,oBAAA,MAAM9R,oBAAoBC,SAAS;AAAA,MACjDtB,SAAS;AAAA,MACTwB,eAAe;AAAA,IAAA,CAChB;AAAA,WACQ,CAACE,SAASG,KAAMC,aAAYA,QAAQvC,SAAS4T,aAAa,GAAG;AAQtE,QAPA5S,QAAM,uDAAuD,GAOzD,CANiB,MAAMS,OAAOE,OAAO;AAAA,MACvCC,MAAM;AAAA,MACNnB,SAAS,YAAYmT,aAAa;AAAA,MAClC7Q,SAAS;AAAA,IAAA,CACV;AAGC,YAAM,IAAIQ,MAAM,YAAYqQ,aAAa,kBAAkB;AAGvD1R,UAAAA,OAAOC,SAASc,OAAO2Q,aAAa;AAAA,EAAA;AAGrCA,SAAAA;AACT;AAEA,SAAS4H,qBAAqBvN,OAA0B;AAChD,QAAA;AAAA,IAAC4D;AAAAA,IAASwJ;AAAAA,EAAAA,IAAWpN;AAC3B,MAAI4D,WAAWwJ;AACP,UAAA,IAAI9X,MAAM,yCAAyC;AAG3D,SAAI0K,MAAM4D,UACD,oBAGL5D,MAAMoN,UACD,sBAGF;AACT;AAEA,SAASsB,cAAcnQ,MAAqB;AAC1C,MAAI,CAACA,KAAKxB,SAAS,OAAOwB,KAAKzB,UAAY;AAClC,WAAA;AAGT,QAAMyR,UAAUlV,KAAKmE,MAAOe,KAAKzB,UAAUyB,KAAKxB,QAAS,GAAG;AAC5D,SAAO,IAAI0S,kBAAS,QAAA,GAAGlB,OAAO,IAAI,GAAG,GAAG,CAAC;AAC3C;AAEA,SAAST,aAAa5T,MAAa;AACjBJ,SAAAA,MAAAA,MAAM,CAACE,mBAAQ;AAAA,IAAC0V,UAAU;AAAA,EAAK,CAAA,CAAC,CAAC,EAClC;AAAA,IAACxV,KAAAA;AAAAA,IAAKa,QAAQ;AAAA,EAAA,CAAK;AACpC;AAEA,SAASuU,cAAcF,UAA2BtZ,QAAsB;AACtE,QAAM6Z,aAAaP,SAAS9O,OAAQkE,CAAAA,UAASA,MAAK7Q,SAAS,OAAO;AAElE,MAAI,CAACgc,WAAWvc;AACd;AAGF,QAAMoR,QAAQ1O,OAAO0O,QAAQ1O,OAAOS,OAAOqZ,KAAK9Z,MAAM;AAEjD0N,OAAAA,OAAO,2CAAsC,GAAGmM,WAAWvc,SAAS,IAAI,WAAW,OAAO,GAE/Fgc,SAASvT,QAAS6H,CAAY,YAAA;AACvB,SAAA,KAAKA,QAAQxJ,GAAG,EAAE;AAAA,EAAA,CACxB;AACH;AC7Xa2V,MAAAA,qBAAuC,OAAOha,MAAM/B,YAAY;AACrE,QAAA;AAAA,IAACC;AAAAA,IAAW+B;AAAAA,EAAAA,IAAUhC,SACtBG,SAASF,UAAAA,GAET8R,UAAU,MAAMM,YAAwBlS,MAAM;AACpD6B,SAAOS,MACLsP,QACGrR,IAAKyI,CAAAA,QAAQ,GAAGiI,YAAY,GAAGjI,IAAIlL,IAAI,OAAOkL,IAAI/J,eAAe,YAAY,EAAE,EAC/E+H,KAAK;AAAA,CAAI,CACd;AACF,GCXM6U,sBAA4C;AAAA,EAChD/d,MAAM;AAAA,EACN4D,OAAO;AAAA,EACPF,UAAU;AAAA,EACVzD,WAAW;AAAA,EACXC,aAAa;AAAA,EACb2D,QAAQ,OAAOC,MAAM/B,YAAY;AACzB,UAAA;AAAA,MAACC;AAAAA,MAAW+B;AAAAA,IAAAA,IAAUhC,SAEtBI,WAAW,MADFH,UAAU,EACKG,SAASC,KAAK;AAC5C2B,WAAOS,MAAMrC,SAASM,IAAKyI,SAAQA,IAAIlL,IAAI,EAAEkJ,KAAK;AAAA,CAAI,CAAC,GAGvD,MAAM4U,mBAAmBha,MAAM/B,OAAO;AAAA,EAAA;AAE1C;ACjBO,SAASic,mBAAmBC,WAAgC;AAC1D5M,SAAAA,CAAAA,EAAQ4M,aAAa,yCAAyCA;AACvE;ACKA,MAAMva,aAAW;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA,GAaXwa,gBAAsC;AAAA,EAC1Cle,MAAM;AAAA,EACNC,WAAW;AAAA,EACXC,aAAa;AAAA,EACb2D,QAAQ,OACNC,MACA/B,YACG;AACCoc,QAAAA;AASJ,WAFkBH,mBAAmBjc,QAAQkc,SAAS,IAGpDE,MAAM,MAAM,QAAA,QAAA,EAAA,KAAA,WAAA;AAAA,aAAA,QAAO,mBAAgC;AAAA,IAAA,CAAA,IAEnDA,MAAM,MAAM,QAAO,QAAA,EAAA,KAAA,WAAA;AAAA,aAAA,QAAA,oBAAmC;AAAA,QAGjDA,IAAIpb,QAAQe,MAAM/B,OAAO;AAAA,EAClC;AAAA,EACA2B,UAAAA;AACF,GCvCMA,aAAW;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA,GASX0a,kBAAwC;AAAA,EAC5Cpe,MAAM;AAAA,EACNC,WAAW;AAAA,EACXC,aAAa;AAAA,EACb2D,QAAQ,OACNC,MACA/B,YACG;AACCoc,QAAAA;AASJ,WAFkBH,mBAAmBjc,QAAQkc,SAAS,IAGpDE,MAAM,MAAM,QAAA,QAAA,EAAA,KAAA,WAAA;AAAA,aAAA,QAAO,qBAAkC;AAAA,IAAA,CAAA,IAErDA,MAAM,MAAM,QAAO,QAAA,EAAA,KAAA,WAAA;AAAA,aAAA,QAAA,sBAAqC;AAAA,QAGnDA,IAAIpb,QAAQe,MAAM/B,OAAO;AAAA,EAClC;AAAA,EACA2B,UAAAA;AACF,GCnCMA,aAAW;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA,GAaX2a,aAAmC;AAAA,EACvCre,MAAM;AAAA,EACNC,WAAW;AAAA,EACXC,aAAa;AAAA,EACb2D,QAAQ,OACNC,MACA/B,aAEkB,MAAMuc,aAAavc,OAAO,GAE3B+B,MAAM/B,OAAO;AAAA,EAEhC2B,UAAAA;AACF;AAEA,eAAsB4a,aACpBvc,SAMA;AAcA,SAbkBic,mBAAmBjc,QAAQkc,SAAS,KAcxC,MAAM,QAAA,QAAA,EAAA,KAAA,WAAA;AAAA,WAAA,QAAO,gBAA6B;AAAA,EAAA,CAAA,GAC3Clb,WAED,MAAM,QAAO,QAAA,EAAA,KAAA,WAAA;AAAA,WAAA,QAAA,iBAA6B;AAAA,EAC3CA,CAAAA,EAAAA,KAAAA,SAAAA,GAAAA;AAAAA,WAAAA,EAAAA;AAAAA,EAAAA,CAAAA,GAAAA;AACb;ACpCA,MAAMW,aAAW;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA,GA0BX6a,yBAA4D;AAAA,EAChEve,MAAM;AAAA,EACN4D,OAAO;AAAA,EACP3D,WAAW;AAAA,EAAA,UACXyD;AAAAA,EACAxD,aAAa;AAAA;AAAA,EAEb2D,QAAQ,OAAOC,MAAM/B,YAAY;AACzB,UAAA;AAAA,MAACC;AAAAA,MAAW+B;AAAAA,QAAUhC,SACtB;AAAA,MAAC8P;AAAAA,MAASwJ;AAAAA,MAASmD;AAAAA,MAAO1X;AAAAA,MAAIvE;AAAAA,IAAAA,IAAWuB,KAAKyO,YAC9C,CAACxI,IAAI,IAAIjG,KAAKG,oBACdwa,WAAW3a,KAAKyO,WAAWmM,OAC3Bxc,SAASK,UAAUP,YAAYqa,QAAQ/Y,OAAO;AAAA,MAACf;AAAAA,IAAQ,CAAA,IAAIP,UAAU;AAE3E,QAAI6P,WAAWwJ;AACP,YAAA,IAAI9X,MAAM,yCAAyC;AAG3D,QAAIuD,MAAMiD;AACF,YAAA,IAAIxG,MAAM,6CAA6C;AAG/D,QAAIkE,YAAmC;AAKvC,SAJIoK,WAAWwJ,aACb5T,YAAYoK,UAAU,oBAAoB,sBAGxC9H,MAAM;AACF4U,YAAAA,cAAcnW,sBAAKrD,QAAQkH,QAAQmG,IAAOzI,GAAAA,IAAI,GAC9C6U,UAAUF,eAAAA,QAAM1O,MAAM,MAAM/J,cAAAA,QAAG4Y,SAASF,aAAa,MAAM,CAAC,GAC5DtM,SAAS,MAAMyM,eAAeF,SAASnX,WAAWvF,MAAM;AAC9D6B,aAAOS,MAAMua,iBAAiB1M,QAAQ5K,SAAS,CAAC;AAChD;AAAA,IAAA;AAIF,UAAMuX,QAAQlY,MAAMmY,KAAAA,KAAK,GACnBC,MAAMT,WAAW,UAAU,QAC3BU,UAAU3W,cAAKU,QAAAA,KAAKkW,YAAGpS,QAAAA,OAAAA,GAAU,cAAc,GAAGgS,KAAK,IAAIE,GAAG,EAAE,GAChEne,YAAY0d,WAAWC,eAAAA,QAAM3d,YAAYD,KAAKC,WAC9Cse,eAAgBvY,MAAO,MAAM5E,OAAOod,YAAYxY,EAAE,KAAO;AAAA,MAACyY,KAAKP;AAAAA,MAAOQ,OAAO;AAAA,IAAY;AACzFvZ,UAAAA,cAAAA,QAAG0U,MAAMnS,sBAAKU,KAAKkW,YAAAA,QAAGpS,OAAO,GAAG,YAAY,GAAG;AAAA,MAACG,WAAW;AAAA,IAAA,CAAK,GACtE,MAAMlH,sBAAGwZ,UAAUN,SAASpe,UAAUse,cAAc,MAAM,CAAC,GAAG,MAAM;AAEpE,UAAMK,SAASC,UAAU;AACrBnB,aAEFoB,uBAAuBT,OAAO,GAC9Bpb,OAAOS,MAAM,eAAe2a,OAAO,EAAE,GACrCpb,OAAOS,MAAM,gDAAgD,GAC7DT,OAAOS,MAAM,kDAAkD,GAC/Dqb,0BAASrB,MAAMW,OAAO,EAAE5Z,GAAG,UAAU,OACnCxB,OAAOS,MAAM,EAAE,GACRsb,8BAA8BX,OAAO,EAC7C,GACDY,eAAAA,QAAML,OAAOM,KAAKN,OAAO5b,KAAKmc,OAAOd,OAAO,GAAG;AAAA,MAACe,OAAO;AAAA,IAAA,CAAU,MAGjEH,eAAAA,QAAMI,KAAKT,OAAOM,KAAKN,OAAO5b,KAAKmc,OAAOd,OAAO,GAAG;AAAA,MAACe,OAAO;AAAA,IAAU,CAAA,GACtE,MAAMJ,8BAA8BX,OAAO,GAC3C,MAAMlZ,cAAAA,QAAGma,OAAOjB,OAAO,EAAE7E,MAAMxB,cAAAA,OAAI;AAGrC,mBAAegH,8BAA8BO,UAAkB;AACzDzB,UAAAA;AACA,UAAA;AACFA,kBAAUF,uBAAM1O,MAAM,MAAM/J,sBAAG4Y,SAASwB,UAAU,MAAM,CAAC;AAAA,eAClDhgB,KAAK;AACZ0D,eAAOW,MAAM,yBAAyBrE,IAAII,OAAO,EAAE;AACnD;AAAA,MAAA;AAGE6f,UAAAA,iBAAAA,QAAQ1B,SAASS,YAAY,GAAG;AAClCtb,eAAOS,MAAM,oCAAoC,GACjDT,OAAOS,MAAM,sCAAsC;AACnD;AAAA,MAAA;AAGE,UAAA;AACF,cAAM+b,cAAc,MAAMzB,eAAeF,SAASnX,WAAWvF,MAAM;AACnE6B,eAAOS,MAAMua,iBAAiBwB,aAAa9Y,SAAS,CAAC;AAAA,eAC9CpH,KAAK;AACZ0D,eAAOW,MAAM,8BAA8BrE,IAAII,OAAO,EAAE,GACpDJ,IAAII,QAAQuQ,SAAS,gBAAgB,KACvCjN,OAAOW,MAAM,qDAAqD;AAAA,MAAA;AAAA,IAEtE;AAAA,EACF;AAEJ;AAEA,SAASkb,uBAAuBT,SAAiB;AACvC5Z,UAAAA,GAAG,UAAU,YAAY;AACzBU,UAAAA,cAAAA,QAAGma,OAAOjB,OAAO,EAAE7E,MAAMxB,cAAAA,OAAI,GAEnCzM,QAAQmU,KAAK,GAAG;AAAA,EAAA,CACjB;AACH;AAEA,SAAS1B,eACP2B,WACAhZ,WACAvF,QACA;AACA,QAAMwe,OAAOC,MAAMC,QAAQH,SAAS,IAAIA,YAAY,CAACA,SAAS;AAC9D,MAAIC,KAAKrf,WAAW;AACZ,UAAA,IAAIkC,MAAM,uBAAuB;AAGzC,QAAMsd,YAAYH,KAAKje,IAAI,CAACkL,KAAKmT,UAAoB;AAEnD,QADAC,iBAAiBpT,KAAKmT,OAAOJ,IAAI,GAC7BjZ,cAAc;AACT,aAAA;AAAA,QAACxE,QAAQ0K;AAAAA,MAAG;AAGrB,QAAIlG,cAAc,qBAAqB;AACrC,UAAIuZ,2BAA2BrT,GAAG;AACzB,eAAA;AAAA,UAACsT,mBAAmBtT;AAAAA,QAAG;AAGhC,YAAM,IAAIpK,MAAM,sCAAsCkE,SAAS,EAAE;AAAA,IAAA;AAGnE,QAAIA,cAAc,mBAAmB;AACnC,UAAIuZ,2BAA2BrT,GAAG;AACzB,eAAA;AAAA,UAACuT,iBAAiBvT;AAAAA,QAAG;AAG9B,YAAM,IAAIpK,MAAM,sCAAsCkE,SAAS,EAAE;AAAA,IAAA;AAGnE,UAAM,IAAIlE,MAAM,yBAAyBkE,SAAS,EAAE;AAAA,EAAA,CACrD;AAED,SAAOvF,OAAOif,YAAYN,SAAS,EAAEO,OAAO;AAC9C;AAEA,SAASL,iBAAiBpT,KAAcmT,OAAeO,KAAgB;AAC/DC,QAAAA,WAAWD,IAAIhgB,WAAW;AAE5B,MAAA,CAACkgB,+BAAc5T,GAAG;AACpB,UAAM,IAAIpK,MAAMie,gBAAgB,qBAAqBV,OAAOQ,QAAQ,CAAC;AAGnE,MAAA,CAACG,oBAAoB9T,GAAG;AAC1B,UAAM,IAAIpK,MAAMie,gBAAgB,+CAA+CV,OAAOQ,QAAQ,CAAC;AAEnG;AAEA,SAASG,oBAAoB9T,KAAsC;AAE/DA,SAAAA,QAAQ,QACR,OAAOA,OAAQ,YACf,WAAWA,OACX,OAAQA,IAAY6R,SAAU;AAElC;AAEA,SAASwB,2BAA2BrT,KAAmD;AAC9E8T,SAAAA,oBAAoB9T,GAAG,KAAK,SAASA;AAC9C;AAEA,SAAS6T,gBAAgB/gB,SAAiBqgB,OAAeQ,UAA2B;AAClF,SAAOA,WAAW,YAAY7gB,OAAO,KAAK,qBAAqBqgB,KAAK,IAAIrgB,OAAO;AACjF;AAEA,SAASse,iBACP1M,QACA5K,WACQ;AACR,QAAMia,SAAS;AAAA;AACf,MAAIja,cAAc;AACT,WAAA;AAAA,MAAkB4K,OAAOsP,QAAQlf,IAAKmf,CAAAA,QAAQA,IAAI9a,EAAE,EAAEoC,KAAKwY,MAAM,CAAC;AAG3E,MAAIja,cAAc;AACT,WAAA;AAAA,MAAiB4K,OAAOsP,QAAQlf,IAAKmf,CAAAA,QAAQA,IAAI9a,EAAE,EAAEoC,KAAKwY,MAAM,CAAC;AAI1E,QAAMG,UAAoB,IACpBC,UAAoB,CAAE;AAC5B,aAAWF,OAAOvP,OAAOsP;AACnBC,QAAIna,cAAc,WACpBqa,QAAQ9X,KAAK4X,IAAI9a,EAAE,IAEnB+a,QAAQ7X,KAAK4X,IAAI9a,EAAE;AAIvB,SAAI+a,QAAQxgB,SAAS,KAAKygB,QAAQzgB,SAAS,IAClC,CACL;AAAA,MAAiBwgB,QAAQ3Y,KAAKwY,MAAM,CAAC,IACrC,4BAA4BA,MAAM,GAAGI,QAAQ5Y,KAAKwY,MAAM,CAAC,EAAE,EAC3DxY,KAAK;AAAA;AAAA,CAAM,IACJ2Y,QAAQxgB,SAAS,IACnB;AAAA,MAAiBwgB,QAAQ3Y,KAAKwY,MAAM,CAAC,KAGvC;AAAA,MAAkCI,QAAQ5Y,KAAKwY,MAAM,CAAC;AAC/D;AAEA,SAAS/B,YAAY;AACnB,QAAMoC,gBAAgB,OAAOxgB,KAAK8K,QAAQ2V,QAAQ,IAAI,YAAY,OAG5Dle,QADSuI,QAAQ4V,IAAIC,UAAU7V,QAAQ4V,IAAIE,UAAUJ,eACvC7I,MAAM,KAAK;AAExB,SAAA;AAAA,IAAC8G,KADIlc,KAAKse,MAAAA,KAAW;AAAA,IACfte;AAAAA,EAAI;AACnB;ACpQA,MAAMJ,aAAW;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA,GAwBX2e,yBAA4D;AAAA,EAChEriB,MAAM;AAAA,EACN4D,OAAO;AAAA,EACP3D,WAAW;AAAA,EAAA,UACXyD;AAAAA,EACAxD,aAAa;AAAA,EACb2D,QAAQ,OAAOC,MAAM/B,YAAY;AACzB,UAAA;AAAA,MAACC;AAAAA,MAAW+B;AAAAA,MAAQC;AAAAA,QAASjC,SAC7B;AAAA,MAACQ;AAAAA,IAAO,IAAIuB,KAAKyO,YACjB+P,MAAMxe,KAAKG,mBAAmBxB,IAAKoY,CAAAA,QAAQ,GAAGA,GAAG,EAAE;AAEzD,QAAI,CAACyH,IAAIjhB;AACD,YAAA,IAAIkC,MAAM,+BAA+B;AAGjD,UAAMrB,SAASK,UAAUP,UAAYqa,EAAAA,MAAAA,EAAQ/Y,OAAO;AAAA,MAACf;AAAAA,IAAQ,CAAA,IAAIP,UAE3Dmf,GAAAA,cAAcmB,IAAIC,OAAO,CAACC,KAAK1b,OAAO0b,IAAI3J,OAAO/R,EAAE,GAAG5E,OAAOif,aAAa;AAC5E,QAAA;AACI,YAAA;AAAA,QAACQ;AAAAA,MAAO,IAAI,MAAMR,YAAYC,OAAO,GACrCqB,UAAUd,QAAQpT,OAAQqT,CAAAA,QAAQA,IAAIna,cAAc,QAAQ,EAAEhF,IAAKmf,CAAQA,QAAAA,IAAI9a,EAAE,GACjF4b,WAAWJ,IAAI/T,OAAQzH,CAAAA,OAAO,CAAC2b,QAAQzR,SAASlK,EAAE,CAAC;AACrD2b,cAAQphB,SAAS,KACnB0C,OAAOS,MAAM,WAAWie,QAAQphB,MAAM,IAAIshB,2BAAU,YAAYF,QAAQphB,MAAM,CAAC,EAAE,GAG/EqhB,SAASrhB,SAAS,KACpB0C,OAAOW,MACLV,MAAMW,IAAI,GAAGge,mBAAAA,QAAU,YAAYD,SAASrhB,MAAM,CAAC,eAAeqhB,SAASxZ,KAAK,IAAI,CAAC,EAAE,CACzF;AAAA,aAEK7I,KAAK;AACZ,YAAM,IAAIkD,MAAM,oBAAoBof,2BAAU,YAAYL,IAAIjhB,MAAM,CAAC;AAAA,EAAMhB,IAAII,OAAO,EAAE;AAAA,IAAA;AAAA,EAC1F;AAEJ,GC5DMmiB,iBAA4C;AAAA,EAChD5iB,MAAM;AAAA,EACNC,WAAW;AAAA,EACXE,aAAa;AAAA,EACbD,aAAa;AACf,GCIM2iB,WAAYC,CAAwBA,QAAAA;AAE1BC,SAAAA,aAAahO,OAAgB/Q,OAA2C;AACtF,QAAMgf,aAA0E;AAAA,IAC9EC,YAAYjf,MAAMkf;AAAAA,IAClBC,KAAKnf,MAAMkf;AAAAA,IACXE,QAAQpf,MAAMS;AAAAA,IACd4e,QAAQrf,MAAMyN;AAAAA,IACd6R,SAAStf,MAAM2I;AAAAA,IACf4W,YAAYV;AAAAA,EAAAA,GAGRW,OAAO1iB,KAAKC,UAAUgU,OAAO,MAAM,CAAC;AAE1C,SAAO0O,kBAAAA,QAASD,IAAI,EACjB/gB,IAAI,CAACY,OAAOmI,GAAG6V,QAA4B;AAE1C,UAAMqC,YAAYlY,MAAM,IAAInI,QAAQge,IAAI7V,IAAI,CAAC;AAE3CnI,WAAAA,MAAMzB,SAAS,YACf8hB,UAAU9hB,SAAS,gBACnB,UAAUL,KAAKmiB,UAAUhhB,KAAK,IAEvB;AAAA,MAAC,GAAGW;AAAAA,MAAOzB,MAAM;AAAA,IAAA,IAGnByB;AAAAA,EACR,CAAA,EACAZ,IAAKY,CAAAA,WACc2f,WAAW3f,MAAMzB,IAAI,KAAKihB,UAC3Bxf,MAAMgW,GAAG,CAC3B,EACAnQ,KAAK,EAAE;AACZ;ACxCA,MAAMxF,aAAW;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA,GAoBXigB,sBAA8D;AAAA,EAClE3jB,MAAM;AAAA,EACN4D,OAAO;AAAA,EACP3D,WAAW;AAAA,EAAA,UACXyD;AAAAA,EACAxD,aAAa;AAAA,EACb2D,QAAQ,OAAOC,MAAM/B,YAAY;AACzB,UAAA;AAAA,MAACC;AAAAA,MAAW+B;AAAAA,MAAQC;AAAAA,QAASjC,SAC7B;AAAA,MAAC6hB;AAAAA,MAAQrhB;AAAAA,IAAWuB,IAAAA,KAAKyO,YACzB,CAACyM,KAAK,IAAIlb,KAAKG,mBAAmBxB,IAAKoY,CAAAA,QAAQ,GAAGA,GAAG,EAAE;AAE7D,QAAI,CAACmE;AACG,YAAA,IAAIzb,MAAM,+BAA+B;AAGjD,UAAMrB,SAASK,UAAUP,UAAYqa,EAAAA,MAAAA,EAAQ/Y,OAAO;AAAA,MAACf;AAAAA,IAAQ,CAAA,IAAIP,UAAU;AAEvE,QAAA;AACF,YAAM2L,MAAM,MAAMzL,OAAOod,YAAYN,KAAK;AAC1C,UAAI,CAACrR;AACH,cAAM,IAAIpK,MAAM,YAAYyb,KAAK,YAAY;AAGxCxa,aAAAA,MAAMof,SAASb,aAAapV,KAAK3J,KAAK,IAAIlD,KAAKC,UAAU4M,KAAK,MAAM,CAAC,CAAC;AAAA,aACtEtN,KAAK;AACZ,YAAM,IAAIkD,MAAM;AAAA,EAA8BlD,IAAII,OAAO,EAAE;AAAA,IAAA;AAAA,EAC7D;AAEJ,GC9CMX,oBAAoB,eAEpB4D,aAAW;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA,oDAQmC5D,iBAAiB;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAyBrE,IAAe,wBAAA;AAAA,EACbE,MAAM;AAAA,EACN4D,OAAO;AAAA,EACP3D,WAAW;AAAA,EAAA,UACXyD;AAAAA,EACAxD,aAAa;AAAA,EACb2D,QAAQ,OACNC,MACA/B,YACkB;AAEZ,UAAA;AAAA,MACJ6hB;AAAAA,MACArhB;AAAAA,MACAshB;AAAAA,MACAC;AAAAA,MACA,eAAe3gB;AAAAA,IAAAA,IACb,MAAM8I,gBAAcnI,IAAI,GACtB;AAAA,MAAC9B;AAAAA,MAAW+B;AAAAA,MAAQC;AAAAA,MAAOia;AAAAA,IAAalc,IAAAA,SACxC,CAACyE,KAAK,IAAI1C,KAAKG;AAErB,QAAI,CAACuC;AACG,YAAA,IAAIjD,MAAM,yBAAyB;AAGtCJ,kBACHY,OAAO0O,KAAKzO,MAAMyN,OAAO,wCAAwC3R,iBAAiB,IAAI,CAAC;AAGzF,UAAMikB,iBAAiB,CAACxhB,SAClBgP,iBAAiB,CAACsS,SAClBvS,cAAc,CAACwS;AAEjBvS,QAAAA,kBAAkB,CAAC0M,WAAW+F,KAAK5gB;AAC/B,YAAA,IAAIG,MACR,qFACF;AAGEwgB,QAAAA,kBAAkB,CAAC9F,WAAW+F,KAAKzhB;AAC/B,YAAA,IAAIgB,MACR,qFACF;AAGF,UAAM0gB,aAAajiB,UAAU;AAAA,MAACuP;AAAAA,MAAgBD;AAAAA,IAAAA,CAAY,EAAE+K,MAAAA,GACtD;AAAA,MAAC9Z,SAAS2hB;AAAAA,MAAiB9gB,WAAW+gB;AAAAA,QAAqBF,WAAW3gB,OAAAA,GAEtEpB,SAAS+hB,WAAW3gB,OAAO;AAAA,MAC/BF,WAAWygB,WAAWM;AAAAA,MACtB5hB,SAASA,WAAW2hB;AAAAA,MACpB/gB,YAAYA,cAAcrD;AAAAA,IAAAA,CAC3B;AAEG,QAAA;AACF,YAAM4gB,OAAO,MAAMxe,OAAOkiB,MAAM5d,KAAK;AACrC,UAAI,CAACka;AACG,cAAA,IAAInd,MAAM,2BAA2B;AAGtCiB,aAAAA,MAAMof,SAASb,aAAarC,MAAM1c,KAAK,IAAIlD,KAAKC,UAAU2f,MAAM,MAAM,CAAC,CAAC;AAAA,aACxErgB,KAAK;AACZ,YAAM,IAAIkD,MAAM;AAAA,EAAyBlD,IAAII,OAAO,EAAE;AAAA,IAAA;AAAA,EACxD;AAEJ;AAEA,SAASwL,gBAAcnI,MAAiD;AAEhEugB,QAAAA,qBAAqBhY,QAAQ4V,IAAIqC;AACvC,SAAOpY,uBAAMC,QAAAA,QAAQrI,KAAKsI,QAAQC,QAAQD,IAAI,EAAEE,MAAM,CAAC,CAAC,EACrDkI,OAAO,UAAU;AAAA,IAAC5S,MAAM;AAAA,IAAWmB,SAAS;AAAA,EAAA,CAAM,EAClDyR,OAAO,WAAW;AAAA,IAAC5S,MAAM;AAAA,EAAA,CAAS,EAClC4S,OAAO,WAAW;AAAA,IAAC5S,MAAM;AAAA,EAAA,CAAS,EAClC4S,OAAO,aAAa;AAAA,IAAC5S,MAAM;AAAA,IAAWmB,SAAS;AAAA,EAAA,CAAM,EACrDyR,OAAO,eAAe;AAAA,IAAC5S,MAAM;AAAA,IAAUmB,SAASshB;AAAAA,EAAmB,CAAA,EAAEjY;AAC1E;ACnHA,MAAMlM,gBAAc,iEAEdwD,aAAW;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA,GAyBX6gB,6BAAiD;AAAA,EACrDvkB,MAAM;AAAA,EACN4D,OAAO;AAAA,EACP3D,WAAW;AAAA,EAAA,aACXC;AAAAA,EAAAA,UACAwD;AAAAA,EACAG,QAAQ,OAAOC,MAAM/B,aACP,MAAM,QAAA,QAAA,EAAA,KAAA,WAAA;AAAA,WAAA,QAAO,sBAAyC;AAAA,EAAA,CAAA,GAEvDgB,QAAQe,MAAM/B,OAAO;AAEpC,GCtCM2B,aAAW;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA,GAuBJ8gB,cAAoC;AAAA,EAC/CxkB,MAAM;AAAA,EACNC,WAAW;AAAA,EACXC,aAAa;AAAA,EAAA,UACbwD;AAAAA,EACAG,QAAQ,OAAOC,MAAM/B,aACP,MAAM,QAAA,QAAA,EAAA,KAAA,WAAA;AAAA,WAAA,QAAO,iBAA+B;AAAA,EAAA,CAAA,GAE7CgB,QAAQe,MAAM/B,OAAO;AAEpC,GC3BM2B,aAAW;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA,GAeX+gB,0BAAgD;AAAA,EACpDzkB,MAAM;AAAA,EACN4D,OAAO;AAAA,EACP3D,WAAW;AAAA,EACXC,aAAa;AAAA,EACb2D,QAAQ,OAAOC,MAAkD/B,aACnD,MAAM,QAAO,QAAA,EAAA,KAAA,WAAA;AAAA,WAAA,QAAA,sBAAuC;AAAA,MAErDgB,QAAQe,MAAM/B,OAAO;AAAA,EAElC2B,UAAAA;AACF,GChCMA,aAAW;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA,GAgCXghB,0BAAgD;AAAA,EACpD1kB,MAAM;AAAA,EACNC,WAAW;AAAA,EACX2D,OAAO;AAAA,EACP1D,aAAa;AAAA,EACb2D,QAAQ,OAAOC,MAAyB/B,aAC1B,MAAM,QAAO,QAAA,EAAA,KAAA,WAAA;AAAA,WAAA,QAAA,sBAAuC;AAAA,MAErDgB,QAAQe,MAAM/B,OAAO;AAAA,EAElC2B,UAAAA;AACF,GC3CMihB,eAA0C;AAAA,EAC9C3kB,MAAM;AAAA,EACNC,WAAW;AAAA,EACXE,aAAa;AAAA,EACbD,aAAa;AACf,GCDMwD,aAAW;AAAA;AAAA;AAAA,GAKXkhB,yBAA+C;AAAA,EACnD5kB,MAAM;AAAA,EACNC,WAAW;AAAA,EACX2D,OAAO;AAAA,EACP1D,aAAa;AAAA,EACb2D,QAAQ,OACNC,MACA/B,aAEY,MAAM,QAAO,QAAA,EAAA,KAAA,WAAA;AAAA,WAAA,QAAA,qBAAsC;AAAA,MAEpDgB,QAAQe,MAAM/B,OAAO;AAAA,EAElC2B,UAAAA;AACF,GCtBMmhB,oBAA0C;AAAA,EAC9C7kB,MAAM;AAAA,EACN4D,OAAO;AAAA,EACP3D,WAAW;AAAA,EACXyD,UAAU;AAAA,EACVxD,aAAa;AAAA,EACb2D,QAAQ,OAAOC,MAAM/B,YAAY;AACzB,UAAA;AAAA,MAACC;AAAAA,MAAW+B;AAAAA,IAAAA,IAAUhC,SACtBG,SAASF,aAET;AAAA,MAACoB;AAAAA,IAAAA,IAAalB,OAAOoB,OAAO;AAClC,QAAI,CAACF;AACG,YAAA,IAAIG,MAAM,qBAAqB;AAKvC,UAAMuhB,YAAY,wCAFG,MAAM5iB,OAAO6iB,SAASC,QAAQ5hB,SAAS,KAAM,CAAA,GAC/B6hB,kBAAkB,UACkB,YAAY7hB,SAAS;AAE5FW,WAAOS,MAAM,WAAWsgB,SAAS,EAAE,GACnCI,sBAAKJ,SAAS;AAAA,EAAA;AAElB,GCrBMK,oBAA0C;AAAA,EAC9CnlB,MAAM;AAAA,EACN4D,OAAO;AAAA,EACP3D,WAAW;AAAA,EACXyD,UAAU;AAAA,EACVxD,aAAa;AAAA,EACb2D,QAAQ,OAAOC,MAAM/B,YAAY;AACzB,UAAA;AAAA,MAACC;AAAAA,IAAaD,IAAAA,SACd,CAAC/B,IAAI,IAAI8D,KAAKG,oBACd/B,SAASF,UAAAA,GAETojB,SAAS,MAAMC,gBAAcrlB,MAAM+B,OAAO;AAC5C,QAAA;AACIG,YAAAA,OACHma,MAAM,EACN/Y,OAAO;AAAA,QAACH,YAAY;AAAA,MAAa,CAAA,EACjCe,QAAQ;AAAA,QAACC,QAAQ;AAAA,QAAUG,KAAK,UAAU8gB,MAAM;AAAA,MAAA,CAAG;AAAA,aAC/C/kB,KAAK;AACZ,YAAM,IAAIkD,MAAM;AAAA,EAA0BlD,IAAII,OAAO,EAAE;AAAA,IAAA;AAAA,EACzD;AAEJ;AAEA,eAAe4kB,gBAAcxS,WAA+B9Q,SAA4B;AACtF,QAAMujB,gBAAgBzS,aAAaA,UAAUzR,YAAAA,GACvC;AAAA,IAACK;AAAAA,IAAQO;AAAAA,EAAAA,IAAaD,SAGtBwjB,QAAQ,MAFCvjB,YAGZqa,QACA/Y,OAAO;AAAA,IAACH,YAAY;AAAA,EAAa,CAAA,EACjCe,QAAgB;AAAA,IAACI,KAAK;AAAA,IAAUkf,MAAM;AAAA,EAAA,CAAK;AAE9C,MAAI8B,eAAe;AACX3iB,UAAAA,WAAW4iB,MAAMhX,OAAQiX,CAASA,SAAAA,KAAKxlB,KAAKoB,YAAY,MAAMkkB,aAAa,EAAE,CAAC;AACpF,QAAI,CAAC3iB;AACH,YAAM,IAAIY,MAAM,mBAAmBsP,SAAS,aAAa;AAG3D,WAAOlQ,SAASmE;AAAAA,EAAAA;AAGZlE,QAAAA,UAAU2iB,MAAM9iB,IAAK+iB,CAAU,UAAA;AAAA,IAAC9iB,OAAO8iB,KAAK1e;AAAAA,IAAI9G,MAAMwlB,KAAKxlB;AAAAA,EAAAA,EAAM;AACvE,SAAOyB,OAAOE,OAAO;AAAA,IACnBlB,SAAS;AAAA,IACTmB,MAAM;AAAA,IACNgB;AAAAA,EAAAA,CACD;AACH;AClDA,MAAM6iB,YAAuC;AAAA,EAC3CzlB,MAAM;AAAA,EACNC,WAAW;AAAA,EACXE,aAAa;AAAA,EACbD,aAAa;AACf,GCHMwlB,0BAAgD;AAAA,EACpD1lB,MAAM;AAAA,EACN4D,OAAO;AAAA,EACP3D,WAAW;AAAA,EACXyD,UAAU;AAAA,EACVxD,aAAa;AAAA,EACb2D,QAAQ,OAAOC,MAAM/B,YAAY;AACzB,UAAA;AAAA,MAACC;AAAAA,MAAW+B;AAAAA,IAAAA,IAAUhC,SACtB,CAAC4jB,SAAS,IAAI7hB,KAAKG,oBACnB/B,SAASF,UAAU;AAErB4jB,QAAAA;AACA,QAAA;AACQ,gBAAA,MAAM1jB,OAAOgC,QAAyB;AAAA,QAACI,KAAK,mBAAmBqhB,SAAS;AAAA,MAAA,CAAG;AAAA,aAC9EtlB,KAAK;AACZ,YAAM,IAAIkD,MAAM;AAAA,EAAmClD,IAAII,OAAO,EAAE;AAAA,IAAA;AAG5D,UAAA;AAAA,MAACmP;AAAAA,MAAWiW;AAAAA,MAAYC;AAAAA,MAAYC;AAAAA,MAAeC;AAAAA,IAAAA,IAAcJ;AAUvE,QARA7hB,OAAOS,MAAM,SAASoL,SAAS,EAAE,GACjC7L,OAAOS,MAAM,WAAWyhB,UAAUL,OAAO,CAAC,EAAE,GAC5C7hB,OAAOS,MAAM,gBAAgBqhB,UAAU,EAAE,GAErCD,QAAQM,aACVniB,OAAOS,MAAM,YAAY2hB,cAAcP,OAAO,CAAC,EAAE,GAG/C,CAACI,eAAe,CAACD,iBAAiBA,kBAAkB,SAAS;AAC/D,YAAMnlB,OAAOklB,aAAa;AAAA;AAAA,EAAUA,UAAU;AAAA;AAAA,IAAY;AACnDthB,aAAAA,MAAM,kBAAkB5D,IAAI,EAAE;AAAA,IAAA;AAAA,EACvC;AAEJ;AAIO,SAASulB,cACdP,SACAlkB,UAAmC,IAC3B;AACF,QAAA;AAAA,IAAC0kB;AAAAA,MAAe1kB,SAChB;AAAA,IAACoF;AAAAA,IAAIif;AAAAA,IAAeF;AAAAA,EAAAA,IAAcD,SAClCS,OAAOD,cAAc,8BAA8Btf,EAAE,oBAAoB;AAC/E,UAAQif,eAAa;AAAA,IACnB,KAAK;AACI,aAAA,QAAQF,UAAU,IAAIQ,IAAI;AAAA,IACnC,KAAK;AACI,aAAA;AAAA,IACT,KAAK;AACI,aAAA;AAAA,EAET;AAGK,SAAA;AACT;AAEO,SAASJ,UAAUL,SAAkC;AAC1D,SAAIA,QAAQM,YACH,WAGLN,QAAQI,aACH,gBAGF;AACT;AC5DA,MAAMM,sBAA2D;AAAA,EAC/DtmB,MAAM;AAAA,EACN4D,OAAO;AAAA,EACP3D,WAAW;AAAA,EACXyD,UAAU;AAAA,EACVxD,aAAa;AAAA,EACb2D,QAAQ,OAAOC,MAAM/B,YAAY;AACzB,UAAA;AAAA,MAACC;AAAAA,IAAAA,IAAaD,SACdkM,QAAQnK,KAAKyO,YACb,CAACvS,IAAI,IAAI8D,KAAKG,oBACd/B,SAASF,UAAU,GAEnBojB,SAAS,MAAMC,cAAcrlB,MAAM+B,OAAO;AAChD,QAAIwkB,UACAC;AACA,QAAA;AACS,iBAAA,MAAMtkB,OAAOgC,QAAuB;AAAA,QAACI,KAAK,UAAU8gB,MAAM;AAAA,MAAY,CAAA,GACjFoB,WAAW,MAAMtkB,OAAOgC,QAA2B;AAAA,QAACI,KAAK,UAAU8gB,MAAM;AAAA,MAAA,CAAY;AAAA,aAC9E/kB,KAAK;AACZ,YAAM,IAAIkD,MAAM;AAAA,EAAgClD,IAAII,OAAO,EAAE;AAAA,IAAA;AAGzDgmB,UAAAA,kBAAkBC,yBAAQF,UAAU,WAAW,GAC/CG,YAAYJ,SAAS9jB,IAAK0H,CAAsD,SAAA;AAAA,MACpF,GAAGA;AAAAA,MACHqc,UAAUC,gBAAgBtc,IAAIrD,EAAE;AAAA,IAChC,EAAA,GAEI8f,gBAAgBL,SAASllB,SAAS;AAC9ByI,cAAAA,QAAQ,CAACrJ,SAAS+K,MAAM;AAChCqb,mBAAapmB,SAASsB,SAAS;AAAA,QAAC+kB,UAAU7Y,MAAM6Y;AAAAA,MAAS,CAAA,GACzDC,eAAehlB,SAAS6kB,kBAAkBpb,CAAC;AAAA,IAAA,CAC5C;AAAA,EAAA;AAEL;AAIA,eAAe6Z,cAAcxS,WAA+B9Q,SAA4B;AACtF,QAAMujB,gBAAgBzS,aAAaA,UAAUzR,YAAAA,GACvC;AAAA,IAACK;AAAAA,IAAQO;AAAAA,EAAAA,IAAaD,SAGtBwjB,QAAQ,MAFCvjB,YAGZqa,QACA/Y,OAAO;AAAA,IAACH,YAAY;AAAA,EAAa,CAAA,EACjCe,QAAgB;AAAA,IAACI,KAAK;AAAA,IAAUkf,MAAM;AAAA,EAAA,CAAK;AAE9C,MAAI8B,eAAe;AACX3iB,UAAAA,WAAW4iB,MAAMhX,OAAQiX,CAASA,SAAAA,KAAKxlB,KAAKoB,YAAY,MAAMkkB,aAAa,EAAE,CAAC;AACpF,QAAI,CAAC3iB;AACH,YAAM,IAAIY,MAAM,mBAAmBsP,SAAS,aAAa;AAG3D,WAAOlQ,SAASmE;AAAAA,EAAAA;AAGlB,MAAIye,MAAMlkB,WAAW;AACb,UAAA,IAAIkC,MAAM,+BAA+B;AAGjD,MAAIgiB,MAAMlkB,WAAW;AACZkkB,WAAAA,MAAM,CAAC,EAAEze;AAGZlE,QAAAA,UAAU2iB,MAAM9iB,IAAK+iB,CAAU,UAAA;AAAA,IAAC9iB,OAAO8iB,KAAK1e;AAAAA,IAAI9G,MAAMwlB,KAAKxlB;AAAAA,EAAAA,EAAM;AACvE,SAAOyB,OAAOE,OAAO;AAAA,IACnBlB,SAAS;AAAA,IACTmB,MAAM;AAAA,IACNgB;AAAAA,EAAAA,CACD;AACH;AAEA,SAASmkB,eAAehlB,SAA4BilB,MAAe;AAC5DA,UACHjlB,QAAQgC,OAAOS,MAAM;AAAA,CAAO;AAEhC;AAEA,SAASqiB,aACPpmB,SACAsB,SACAL,SACA;AACM,QAAA;AAAA,IAAColB;AAAAA,MAAYplB,SACb;AAAA,IAACqC;AAAAA,IAAQC;AAAAA,EAAAA,IAASjC;AAExBgC,SAAOS,MAAM,SAAS/D,QAAQmP,SAAS,EAAE,GACzC7L,OAAOS,MAAM,WAAW/D,QAAQwmB,MAAM,EAAE,GACxCljB,OAAOS,MAAM,gBAAgB/D,QAAQolB,UAAU,EAAE,GAE7CplB,QAAQymB,eAAe,KACzBnjB,OAAOS,MAAM,aAAa/D,QAAQymB,YAAY,EAAE,GAG9CJ,aACF/iB,OAAOS,MAAM,UAAU,GACvBT,OAAOS,MAAM2iB,kBAAQrmB,KAAKkP,MAAMvP,QAAQ2mB,OAAO,GAAG;AAAA,IAACC,QAAQ;AAAA,EAAK,CAAA,CAAC,IAG/DP,YAAYrmB,QAAQ+lB,aACtBziB,OAAOS,MAAM,WAAW,GACxB/D,QAAQ+lB,SAAS1c,QAAS8b,CAAY,YAAA;AAEpC,UAAM0B,SAAS,MADF1B,QAAQhW,UAAUiC,QAAQ,WAAW,GAAG,CAC5B;AAEzB,QAAI+T,QAAQI;AACHxhB,aAAAA,MAAM,GAAG8iB,MAAM,IAAItjB,MAAMyN,OAAO,SAAS,CAAC,EAAE;AAAA,aAC1CmU,QAAQM,WAAW;AACtBqB,YAAAA,UAAUpB,cAAcP,SAAS;AAAA,QAACQ,aAAa;AAAA,MAAA,CAAK;AACnD5hB,aAAAA,MAAM,GAAG8iB,MAAM,IAAItjB,MAAMyN,OAAO,YAAY8V,OAAO,EAAE,CAAC,EAAE;AAAA,IACjE;AACS/iB,aAAAA,MAAM,GAAG8iB,MAAM,kBAAkB1B,QAAQC,UAAU,KAAKD,QAAQ4B,QAAQ,KAAK;AAAA,EAEvF,CAAA,IAIHzjB,OAAOS,MAAM,EAAE;AACjB;AC/HA,MAAMijB,mBAAyC;AAAA,EAC7CznB,MAAM;AAAA,EACN4D,OAAO;AAAA,EACP3D,WAAW;AAAA,EACXyD,UAAU;AAAA,EACVxD,aAAa;AAAA,EACb2D,QAAQ,OAAOC,MAAM/B,YAAY;AACzB,UAAA;AAAA,MAACC;AAAAA,MAAW+B;AAAAA,IAAAA,IAAUhC,SACtBG,SAASF,UAAU;AAErBujB,QAAAA;AACA,QAAA;AACFA,cAAQ,MAAMrjB,OACXma,MAAM,EACN/Y,OAAO;AAAA,QAACH,YAAY;AAAA,MAAa,CAAA,EACjCe,QAAgB;AAAA,QAACI,KAAK;AAAA,MAAA,CAAS;AAAA,aAC3BjE,KAAK;AACZ,YAAM,IAAIkD,MAAM;AAAA,EAAgClD,IAAII,OAAO,EAAE;AAAA,IAAA;AAG/D8kB,UAAMzb,QAAS0b,CAAS,SAAA;AACtBzhB,aAAOS,MAAM,SAASghB,KAAKxlB,IAAI,EAAE,GACjC+D,OAAOS,MAAM,YAAYghB,KAAKjjB,OAAO,EAAE,GACvCwB,OAAOS,MAAM,QAAQghB,KAAKrd,GAAG,EAAE,GAE3Bqd,KAAK5jB,SAAS,eAChBmC,OAAOS,MAAM,gBAAgBghB,KAAKkC,UAAU,EAAE,GAE1ClC,KAAKtlB,eACP6D,OAAOS,MAAM,gBAAgBghB,KAAKtlB,WAAW,EAAE,IAInD6D,OAAOS,MAAM,EAAE;AAAA,IAAA,CAChB;AAAA,EAAA;AAEL,GCtCMtE,gBAAc,yEAEdwD,aAAW;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA,GAcXikB,yBAA+C;AAAA,EACnD3nB,MAAM;AAAA,EACN4D,OAAO;AAAA,EACP3D,WAAW;AAAA,EAAA,aACXC;AAAAA,EAAAA,UACAwD;AAAAA,EACAG,QAAQ,OAAOC,MAAM/B,YAAY;AACzB,UAAA;AAAA,MAAC6lB;AAAAA,IAAAA,IAAuB,MAAM,QAAO,QAAA,EAAA,KAAA,WAAA;AAAA,aAAA,QAAA,4BAA8C;AAAA,QACnFC,eAAe,MAAMD,oBAAoB9jB,MAAM/B,OAAO;AACxD8lB,QAAAA;AACIA,YAAAA;AAEDA,WAAAA;AAAAA,EAAAA;AAEX;AChCA,IAAe,gBAAA;AAAA,EACb7nB,MAAM;AAAA,EACNC,WAAW;AAAA,EACXE,aAAa;AAAA,EACbD,aAAa;AACf;ACLa4nB,MAAAA,uBAAuB,cACvBC,8BAA8B,CAAC,OAAO,MAAM,MAAM,KAAK,GACvDC,sBAAsB,eCFtBC,kBAAkBA,CAAC;AAAA,EAC9BC;AAAAA,EACAC;AAIF,MAAM;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA,YAOMD,aAAa;AAAA,EAEvBC,cAAc9mB,SAAS,IACnB,qBAAqB8mB,cAAc1lB,IAAK2lB,CAAAA,MAAMtnB,KAAKC,UAAUqnB,CAAC,CAAC,EAAElf,KAAK,IAAI,CAAC;AAAA,IAC3E,EAAE;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA,GCjBKmf,gBAAgBA,CAAC;AAAA,EAC5BH;AAAAA,EACAC;AAIF,MAAM;AAAA;AAAA;AAAA,YAGMD,aAAa;AAAA,EAEvBC,cAAc9mB,SAAS,IACnB,qBAAqB8mB,cAAc1lB,IAAK2lB,CAAAA,MAAMtnB,KAAKC,UAAUqnB,CAAC,CAAC,EAAElf,KAAK,IAAI,CAAC;AAAA,IAC3E,EAAE;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA,GCbKof,cAAcA,CAAC;AAAA,EAC1BJ;AAAAA,EACAC;AAIF,MAAM;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA,YAMMD,aAAa;AAAA,EAEvBC,cAAc9mB,SAAS,IACnB,qBAAqB8mB,cAAc1lB,IAAK2lB,CAAAA,MAAMtnB,KAAKC,UAAUqnB,CAAC,CAAC,EAAElf,KAAK,IAAI,CAAC;AAAA,IAC3E,EAAE;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA,GChBKqf,aAAaA,CAAC;AAAA,EACzBL;AAAAA,EACAC;AAIF,MAAM;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA,YAMMD,aAAa;AAAA,EAEvBC,cAAc9mB,SAAS,IACnB,qBAAqB8mB,cAAc1lB,IAAK2lB,CAAAA,MAAMtnB,KAAKC,UAAUqnB,CAAC,CAAC,EAAElf,KAAK,IAAI,CAAC;AAAA,IAC3E,EAAE;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA,GChBKsf,cAAcA,CAAC;AAAA,EAC1BN;AAAAA,EACAC;AAIF,MAAM;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA,YAMMD,aAAa;AAAA,EAEvBC,cAAc9mB,SAAS,IACnB,qBAAqB8mB,cAAc1lB,IAAK2lB,CAAAA,MAAMtnB,KAAKC,UAAUqnB,CAAC,CAAC,EAAElf,KAAK,IAAI,CAAC;AAAA,IAC3E,EAAE;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA,GCFFxF,aAAW;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA,GAYX+kB,YAAY,CAChB;AAAA,EAACzoB,MAAM;AAAA,EAA6C0oB,UAAUL;AAAa,GAC3E;AAAA,EAACroB,MAAM;AAAA,EAAyB0oB,UAAUH;AAAU,GACpD;AAAA,EAACvoB,MAAM;AAAA,EAAkB0oB,UAAUJ;AAAW,GAC9C;AAAA,EAACtoB,MAAM;AAAA,EAAyC0oB,UAAUF;AAAW,GACrE;AAAA,EACExoB,MAAM;AAAA,EACN0oB,UAAUT;AACZ,CAAC,GAGGU,yBAAqE;AAAA,EACzE3oB,MAAM;AAAA,EACN4D,OAAO;AAAA,EACP3D,WAAW;AAAA,EAAA,UACXyD;AAAAA,EACAxD,aAAa;AAAA,EACb2D,QAAQ,OAAOC,MAAM/B,YAAY;AACzB,UAAA;AAAA,MAACgC;AAAAA,MAAQtC;AAAAA,MAAQyM;AAAAA,MAASlK;AAAAA,IAAAA,IAASjC;AAErC,QAAA,CAAC2N,KAAK,IAAI5L,KAAKG;AAEZ,WAAA,CAACyL,OAAOsF,KAAK;AACV,cAAA,MAAMvT,OAAOE,OAAO;AAAA,QAC1BC,MAAM;AAAA,QACNgnB,QAAQ;AAAA,QACRnoB,SAAS;AAAA,MAAA,CACV,GACIiP,MAAMsF,UACTjR,OAAOW,MAAMV,MAAMW,IAAI,sBAAsB,CAAC;AAG5CsU,UAAAA,SAAQ,MAAMxX,OAAOE,OAAO;AAAA,MAChCC,MAAM;AAAA,MACNgnB,QAAQ;AAAA,MACRnoB,SAAS;AAAA,IAAA,CACV,GAEKooB,kBAAkBC,OAAOC,YAAYN,UAAUhmB,IAAK2lB,CAAM,MAAA,CAACA,EAAEpoB,MAAMooB,CAAC,CAAC,CAAC,GACtEM,WAAW,MAAMjnB,OAAOE,OAAO;AAAA,MACnCC,MAAM;AAAA,MACNnB,SAAS;AAAA,MACTmC,SAAS6lB,UAAUhmB,IAAKumB,CAAqB,qBAAA;AAAA,QAC3ChpB,MAAMgpB,gBAAgBhpB;AAAAA,QACtB0C,OAAOsmB,gBAAgBhpB;AAAAA,MAAAA,EACvB;AAAA,IAAA,CACH,GAEKipB,cAAcC,gBAAAA,QAAOxZ,MAAMtO,YAAY,CAAC,EAC3CyQ,QAAQ,QAAQ,GAAG,EACnBA,QAAQ,eAAe,EAAE,GAEtBsX,UAAU3gB,cAAKU,QAAAA,KAAKgF,SAAS4Z,sBAAsBmB,WAAW;AACpE,QAAIxa,cAAW0a,OAAO,KAElB,CAAE,MAAM1nB,OAAOE,OAAO;AAAA,MACpBC,MAAM;AAAA,MACNnB,SAAS,uBAAuBuD,MAAM4I,KAAKuc,OAAO,CAAC;AAAA,MACnDpmB,SAAS;AAAA,IAAA,CACV;AAED;AAGJmK,OAAAA,UAAUic,SAAS;AAAA,MAAChc,WAAW;AAAA,IAAA,CAAK;AAEpC,UAAMic,oBAAoBP,gBAAgBH,QAAQ,EAAEA,YAAYL,eAAe;AAAA,MAC7EH,eAAexY;AAAAA,MACfyY,eAAelP,OACZC,MAAM,GAAG,EACTzW,IAAK2lB,CAAMA,MAAAA,EAAEpT,MAAM,EACnBzG,OAAO8C,OAAO;AAAA,IAClB,CAAA,GAEKgY,iBAAiB7gB,cAAAA,QAAKU,KAAKigB,SAAS,UAAU;AAEpD,UAAM1J,KAAAA,UAAU4J,gBAAgBD,gBAAgB,GAEhDrlB,OAAOS,MAAM,GACbT,OAAOS,MAAM,GAAGR,MAAMS,MAAM,QAAG,CAAC,qBAAqB,GACrDV,OAAOS,MAAAA,GACPT,OAAOS,MAAM,aAAa,GAC1BT,OAAOS,MACL,QAAQR,MAAM2I,KACZ0c,cACF,CAAC,6DACH,GACAtlB,OAAOS,MACL;AAAA,IAAkCR,MAAM2I,KACtC,wBAAwBsc,WAAW,6CACrC,CAAC,IACH,GACAllB,OAAOS,MACL;AAAA,KAAiDR,MAAM2I,KACrD,wBAAwBsc,WAAW,yDACrC,CAAC,IACH,GACAllB,OAAOS,SACPT,OAAOS,MACL,+DAAwDR,MAAM2I,KAC5D,0DACF,CAAC,EACH;AAAA,EAAA;AAEJ;AC3FgB2c,SAAAA,uBACdpb,SACAga,eAC2B;AAC3B,SAAO,CAACA,eAAe1f,cAAAA,QAAKU,KAAKgf,eAAe,OAAO,CAAC,EAAEqB,QAASC,CAAAA,aACjEzB,4BAA4BtlB,IAAKyc,CAAQ,QAAA;AACvC,UAAMuK,eAAejhB,cAAAA,QAAKU,KAAK4e,sBAAsB,GAAG0B,QAAQ,IAAItK,GAAG,EAAE,GACnEwK,eAAelhB,cAAKrD,QAAAA,QAAQ+I,SAASub,YAAY;AACnDtL,QAAAA;AACA,QAAA;AAEFA,YAAMvZ,QAAQ8kB,YAAY;AAAA,aACnBrpB,KAAK;AACZ,UAAIA,IAAIE,SAAS;AACf,cAAM,IAAIgD,MAAM,UAAUlD,IAAII,OAAO,GAAG;AAAA,IAAA;AAGrC,WAAA;AAAA,MAACgpB;AAAAA,MAAcC;AAAAA,MAAcvL;AAAAA,IAAG;AAAA,EAAA,CACxC,CACH;AACF;AASO,SAASwL,0BACdC,QAC6C;AACzC,MAAA,OAAOA,OAAOzL,MAAQ,OAAe,CAACoD,uBAAAA,QAAcqI,OAAOzL,IAAIpb,OAAO;AACjE,WAAA;AAGHob,QAAAA,MAAMyL,OAAOzL,IAAIpb;AACvB,SAAO,OAAOob,IAAIzO,SAAU,YAAYyO,IAAI0L,YAAY7mB;AAC1D;AClEA,MAAMU,aAAW,IAEXomB,uBAA6C;AAAA,EACjD9pB,MAAM;AAAA,EACN4D,OAAO;AAAA,EACP3D,WAAW;AAAA,EAAA,UACXyD;AAAAA,EACAxD,aAAa;AAAA,EACb2D,QAAQ,OAAOkmB,GAAGhoB,YAAY;AACtB,UAAA;AAAA,MAACmM;AAAAA,MAASnK;AAAAA,MAAQC;AAAAA,IAAAA,IAASjC;AAC7B,QAAA;AACIioB,YAAAA,aAAa,MAAMC,kBAAkB/b,OAAO;AAE9C8b,UAAAA,WAAW3oB,WAAW,GAAG;AAC3B0C,eAAOS,MAAM,yDAAyD,GACtET,OAAOS,MACL;AAAA,MAASR,MAAMS,MAAM,kCAAoC,CAAC,4BAC5D;AACA;AAAA,MAAA;AAGI8K,YAAAA,QAAQ,IAAIC,0BAAM;AAAA,QACtBE,OAAO,SAASsa,WAAW3oB,MAAM;AAAA,QACjCoO,SAAS,CACP;AAAA,UAACzP,MAAM;AAAA,UAAM0P,OAAO;AAAA,UAAMC,WAAW;AAAA,QAAA,GACrC;AAAA,UAAC3P,MAAM;AAAA,UAAS0P,OAAO;AAAA,UAASC,WAAW;AAAA,QAAO,CAAA;AAAA,MAAA,CAErD;AAEDqa,iBAAWlgB,QAASogB,CAAqB,qBAAA;AACvC3a,cAAMM,OAAO;AAAA,UAAC/I,IAAIojB,iBAAiBpjB;AAAAA,UAAI4I,OAAOwa,iBAAiBC,UAAUza;AAAAA,QAAAA,CAAM;AAAA,MAAA,CAChF,GACDH,MAAMU,cACNlM,OAAOS,MAAM,sDAAsD;AAAA,aAC5DE,OAAO;AACVA,UAAAA,MAAMnE,SAAS,UAAU;AAC3BwD,eAAOS,MAAM,2CAA2C,GACxDT,OAAOS,MACL;AAAA,MAASR,MAAMS,MAAM,kCAAoC,CAAC,4BAC5D;AACA;AAAA,MAAA;AAEF,YAAM,IAAIlB,MAAM,+CAA+CmB,MAAMjE,OAAO,EAAE;AAAA,IAAA;AAAA,EAChF;AAEJ;AAmBA,eAAsBwpB,kBAAkB/b,SAA+C;AACjFkc,MAAAA;AAEFA,eAAaC,KAAAA,SAAS;AAAA,IACpB5O,QAAQ,OAAOpP,QAAQie,QAAQhe,MAAM,CAAC,CAAC;AAAA,IACvCie,WAAW;AAAA,MAAC,kBAAkB;AAAA,IAAA;AAAA,EAC/B,CAAA,EAAEH;AAGCI,QAAAA,gBAAgBhiB,sBAAKU,KAAKgF,SAAS4Z,oBAAoB,GACvD2C,mBAAmB,MAAMC,KAAAA,QAAQF,eAAe;AAAA,IAACG,eAAe;AAAA,EAAA,CAAK,GAErEX,aAAkC,CAAC;AACzC,aAAWY,SAASH,kBAAkB;AACpC,UAAMI,YAAYD,MAAM1O,YAAgB0O,IAAAA,MAAM5qB,OAAO8qB,+BAA+BF,MAAM5qB,IAAI,GACxF+qB,aAAazB,uBAAuBpb,SAAS2c,SAAS,EAAEtc,OAAOob,yBAAyB;AAE9F,eAAWqB,aAAaD;AACtBf,iBAAWhgB,KAAK;AAAA,QACdlD,IAAI+jB;AAAAA,QACJV,WAAWa,UAAU7M,IAAIpb;AAAAA,MAAAA,CAC1B;AAAA,EAAA;AAIDqnB,SAAAA,cACFA,cAGKJ;AACT;AAEA,SAASc,+BAA+B1iB,UAAkB;AAExD,SAAO2f,4BAA4BxF,OACjC,CAACviB,MAAMkf,QAASlf,KAAKirB,SAAS,IAAI/L,GAAG,EAAE,IAAI1W,cAAAA,QAAKC,SAASzI,MAAM,IAAIkf,GAAG,EAAE,IAAIlf,MAC5EoI,QACF;AACF;ACjHA,IAAe,iBAAA;AAAA,EACbpI,MAAM;AAAA,EACNC,WAAW;AAAA,EACXE,aAAa;AAAA,EACbD,aAAa;AACf;ACDA,SAASgrB,aAAa1iB,OAAoB;AACpC,MAAA,CAACmY,MAAMC,QAAQpY,KAAI;AACf,UAAA,IAAIjF,MAAM,sBAAsB;AAGxC,SAAOiF,MAAK+Z,OAAe,CAAC9G,QAAQ0P,SAAS3f,MAAM;AACjD,QAAI4f,MAAAA,eAAeD,OAAO;AACjB,aAAA,GAAG1P,MAAM,IAAI0P,OAAO;AAGzBE,QAAAA,mBAAaF,OAAO,KAAKA,QAAQG;AACnC,aAAO,GAAG7P,MAAM,WAAW0P,QAAQG,IAAI;AAGrCC,QAAAA,MAAAA,aAAaJ,OAAO,GAAG;AACnB,YAAA,CAACK,MAAMC,EAAE,IAAIN;AACnB,aAAO,GAAG1P,MAAM,IAAI+P,IAAI,IAAIC,EAAE;AAAA,IAAA;AAGhC,QAAI,OAAON,WAAY;AAEd,aAAA,GAAG1P,MAAM,GADEjQ,MAAM,IAAI,KAAK,GACL,GAAG2f,OAAO;AAGxC,UAAM,IAAI5nB,MAAM,8BAA8BzC,KAAKC,UAAUoqB,OAAO,CAAC,IAAI;AAAA,KACxE,EAAE;AACP;AAgBO,MAAMO,eAAeA,CAACC,WAA2C,CAAIC,GAAAA,QAAQ,MAC3E9C,OAAO+C,QAAQF,QAAQ,EAC3BlpB,IAAI,CAAC,CAAC0gB,KAAK2I,KAAK,MACfxkB,KAAKykB,IAAI5I,IAAI9hB,SAASuqB,QAAQ,GAAGF,aAAaI,MAAMH,UAAUC,QAAQ,CAAC,CAAC,CAC1E,EACCrJ,OAAO,CAACwJ,KAAKlV,SAAUA,OAAOkV,MAAMlV,OAAOkV,KAAM,CAAC,GAc1CC,aAAaA,CAAwB;AAAA,EAChDC,MAAAA,QAAO,CAAC;AAAA,EACRC;AAAAA,EACAC,QAAAA,UAAS;AAAA,EACTC,UAAUC,YAAYA,CAAC;AAAA,IAACC;AAAAA,EAAAA,MAAWA;AAAAA,EACnCC;AACa,MAAc;AACrBV,QAAAA,UAAU/C,OAAO+C,QAAQI,KAAI;AAEnC,SAAOJ,QACJppB,IAAI,CAAC,CAAC0gB,KAAK2I,KAAK,GAAGhL,UAAU;AAC5B,UAAM0L,SAAS1L,UAAU+K,QAAQxqB,SAAS,GACpCorB,aAAa,GAAGN,OAAM,GAAGK,SAAS,OAAO,SAAI,IAC7CE,SAASL,UAAUP,KAAK,GAExBa,SAASX,WAAW;AAAA,MACxBC,MAAMH,MAAMH;AAAAA,MACZO;AAAAA,MACAC,QAAQM;AAAAA,MACRL,UAAUC;AAAAA,MACVE;AAAAA,IAAAA,CACD;AAED,QAAI,CAACG,QAAQrrB;AAEX,aAAO,CADS,GAAG8qB,OAAM,GAAGK,SAAS,WAAM,QAAG,UAAKrJ,GAAG,IACrCwJ,MAAM,EAAEpe,OAAO8C,OAAO,EAAEnI,KAAK;AAAA,CAAI;AAG9C,UAAA,CAAC0jB,OAAO,GAAGC,IAAI,IAAIH,QACnBI,eAAe,IAAIC,OAAOb,gBAAgBC,QAAO9qB,SAAS8hB,IAAI9hB,MAAM,GACpE2rB,QAAQR,SAAS,WAAM,UACvBS,oBAAoB,IAAIF,OAAOb,gBAAgBC,QAAO9qB,SAAS,CAAC,GAEhE6rB,eAAe,GAAGf,OAAM,GAAGa,KAAK,UAAK7J,GAAG,IAAI2J,YAAY,IAAIP,WAAWK,KAAK,CAAC,IAC7EO,qBAAqBN,KACxBpqB,IAAK2qB,CAAAA,WAAW,GAAGX,UAAU,GAAGQ,iBAAiB,IAAIV,WAAWa,MAAM,CAAC,EAAE,EACzElkB,KAAK;AAAA,CAAI;AAGL,WAAA,CADS,CAACgkB,cAAcC,kBAAkB,EAAE5e,OAAO8C,OAAO,EAAEnI,KAAK;AAAA,CAAI,GAC3DyjB,MAAM,EAAEpe,OAAO8C,OAAO,EAAEnI,KAAK;AAAA,CAAI;AAAA,EACnD,CAAA,EACAA,KAAK;AAAA,CAAI;AACd;AAMO,SAASmkB,cAA2Cf,OAA2B;AACpF,QAAMgB,OAAmB,CAAC;AAGjBC,WAAAA,QAAQtB,OAAYuB,OAAmBF,MAAM;AAEhD,QAAA,CAACrB,MAAKzjB,KAAKnH,QAAQ;AAChBmsB,WAAKlB,UAAOkB,KAAKlB,QAAQ,CAAA,IAG9BkB,KAAKlB,MAAMtiB,KAAKiiB,KAAI;AACpB;AAAA,IAAA;AAGI,UAAA,CAAClhB,SAAS,GAAG8hB,IAAI,IAAIZ,MAAKzjB,MAC1B2a,MAAM+H,aAAa,CAACngB,OAAO,CAAC;AAG7ByiB,SAAK7B,aAAU6B,KAAK7B,WAAW,CAC9BxI,IAAAA,OAAOqK,KAAK7B,aAAW6B,KAAK7B,SAASxI,GAAG,IAAI,KAElDoK,QAAQ;AAAA,MAAC,GAAGtB;AAAAA,MAAMzjB,MAAMqkB;AAAAA,IAAAA,GAAOW,KAAK7B,SAASxI,GAAG,CAAC;AAAA,EAAA;AAGxC8I,aAAAA,SAAQK,MAAOiB,SAAQtB,KAAI;AAC/BqB,SAAAA;AACT;AC/HA,MAAMG,QAAQC,gBAAO,CAAC;AASf,SAASC,aAAa;AAAA,EAC3B3pB;AAAAA,EACA4pB;AAAAA,EACAzD;AAAAA,EACA0D,aAAa;AACwD,GAAW;AAChF,UAAQlN,MAAMC,QAAQgN,OAAO,IAAIA,UAAU,CAACA,OAAO,GAChDnrB,IAAKqrB,CAAAA,iBACAA,aAAalsB,SAAS,gBACjB,CACL,CACEmsB,MAAM,eAAe,QAAQ/pB,KAAK,GAClC,OAAO8pB,aAAahnB,KAAO,MAAc,OAAO9C,MAAM4N,UAAUkc,aAAahnB,EAAE,CAAC,EAE/EyH,OAAO8C,OAAO,EACdnI,KAAK,GAAG,GACXijB,OACEwB,aAAa;AAAA,IACX3pB;AAAAA,IACA4pB,SAASE,aAAajN;AAAAA,IACtBsJ;AAAAA,IACA0D;AAAAA,EAAAA,CACD,CACH,CAAC,EACD3kB,KAAK;AAAA;AAAA,CAAM,IAER8kB,qBAAqB;AAAA,IAC1BhqB;AAAAA,IACA4pB,SAASE;AAAAA,IACT3D;AAAAA,IACA0D;AAAAA,EAAAA,CACD,CACF,EACA3kB,KAAK;AAAA;AAAA,CAAM;AAChB;AAEA,SAAS+kB,cAAcC,KAAqC;AAC1D,SAAO,OAAOA,OAAQ,WAAWA,MAAMA,IAAI5C;AAC7C;AAEA,SAAS6C,WAAWnqB,OAAcoqB,SAAyB;AAClB,SAAA;AAAA,IACrCC,MAAMrqB,MAAMsqB,QAAQC;AAAAA,IACpBC,aAAaxqB,MAAMyqB,QAAQF,MAAM5hB;AAAAA,IACjC+hB,kBAAkB1qB,MAAM2qB,SAASJ,MAAM5hB;AAAAA,IACvCiiB,aAAa5qB,MAAM6qB,MAAMN,MAAM5hB;AAAAA,IAGnByhB,OAAO;AACvB;AAEA,SAASL,MAAMe,OAAeV,SAAkBpqB,OAAsB;AAC/DypB,SAAAA,QAIEU,WAAWnqB,OAAOoqB,OAAO,EAAE,IAAIU,KAAK,GAAG,IAHrC,IAAIA,KAAK;AAIpB;AAEA,MAAMC,iBAAmD;AAAA,EACvD9rB,QAAQ;AAAA,EACRge,mBAAmB;AAAA,EACnBC,iBAAiB;AAAA,EACjBrI,QAAQ;AAAA,EACRmW,OAAO;AACT;AAEA,SAASC,WAAWC,UAAwC;AAC1D,MAAI,QAAQA;AACV,WAAOA,SAASpoB;AAGlB,MAAI,cAAcooB;AAChB,WAAOA,SAASC,SAAS5P;AAI7B;AAEA,MAAM6P,gBAAgB,IAAIC,KAAKC,WAAW,SAAS;AAAA,EACjD1tB,MAAM;AACR,CAAC;AAED,SAAS2tB,eAAevrB,OAAckrB,UAAoB/E,WAA8B;AACtF,QAAMqF,eAAezB,MAAMmB,SAASttB,MAAMmtB,eAAeG,SAASttB,IAAI,GAAGoC,KAAK,GAExEyrB,eACJ,cAAcP,YAAY/E,UAAUhC,gBAChC4F,MACE,cAAcmB,WACVA,SAASC,SAAS3P,QAClB4P,cAAcM,OAAOvF,UAAUhC,iBAAiB,CAAE,CAAA,GACtD,QACAnkB,KACF,IACA;AAGN,SAAO,CAACwrB,cAAcC,cAAczrB,MAAM4N,UAAUqd,WAAWC,QAAQ,CAAC,CAAC,EACtE3gB,OAAO8C,OAAO,EACdnI,KAAK,GAAG;AACb;AAEO,SAAS8kB,qBAAqB;AAAA,EACnChqB;AAAAA,EACA4pB;AAAAA,EACAzD;AAAAA,EACA0D,aAAa;AACa,GAAW;AAC/B8B,QAAAA,OACJ,aAAa/B,UAAU5pB,MAAM4I,KAAK,iBAAiBghB,QAAQlsB,SAASkuB,UAAU,GAAG,IAAI,IACjFC,SAAS,CAACN,eAAevrB,OAAO4pB,SAASzD,SAAS,GAAGwF,IAAI,EAAEzmB,KAAK,GAAG,GACnE4mB,UAAU,IAAI/C,OAAOc,UAAU;AAErC,MACED,QAAQhsB,SAAS,YACjBgsB,QAAQhsB,SAAS,uBACjBgsB,QAAQhsB,SAAS;AAEjB,WAAO,CAACiuB,QAAQ;AAAA,GAAM1D,OAAOrrB,KAAKC,UAAU6sB,QAAQuB,UAAU,MAAM,CAAC,GAAGtB,UAAU,CAAC,EAAE3kB,KAAK,EAAE;AAG1F0kB,MAAAA,QAAQhsB,SAAS,SAAS;AAC5B,UAAM4rB,OAAOH,cAAyBO,QAAQmC,QAAQC,KAAM,CAAA,GACtD9D,gBAAgB5kB,KAAKykB,IAAIL,aAAa8B,KAAK7B,QAAQ,IAAI,GAAG,EAAE;AAElE,WAAO,CACLkE,QACA;AAAA,GACA7D,WAAsB;AAAA,MACpBC,MAAMuB,KAAK7B;AAAAA,MACXO;AAAAA,MACAC,QAAQ2D;AAAAA,MACRvD,YAAayC,CAAAA,UAAUiB,oBAAoBjsB,OAAOgrB,KAAK;AAAA,IAAA,CACxD,CAAC,EACF9lB,KAAK,EAAE;AAAA,EAAA;AAGJ2mB,SAAAA;AACT;AAEA,SAASI,oBAAoBjsB,OAAcgrB,OAA0B;AAC7D,QAAA;AAAA,IAACkB;AAAAA,EAAAA,IAAMlB,OACPmB,gBAAgBnsB,MAAM2I,KAAKujB,GAAGtuB,IAAI;AACxC,MAAIsuB,GAAGtuB,SAAS;AACd,WAAO,GAAGoC,MAAMW,IAAIwrB,aAAa,CAAC;AAEpC,MAAID,GAAGtuB,SAAS;AACd,WAAO,GAAGoC,MAAMyN,OAAO0e,aAAa,CAAC,IAAID,GAAGxtB,KAAK;AAEnD,MAAIwtB,GAAGtuB,SAAS,SAASsuB,GAAGtuB,SAAS;AACnC,WAAO,GAAGoC,MAAMyN,OAAO0e,aAAa,CAAC,IAAID,GAAGE,MAAM;AAEpD,MAAIF,GAAGtuB,SAAS;AACP,WAAA,GAAGoC,MAAMyN,OAAO0e,aAAa,CAAC,IAAIrvB,KAAKC,UAAUmvB,GAAGxtB,KAAK,CAAC;AAEnE,MAAIwtB,GAAGtuB,SAAS;AACP,WAAA,GAAGoC,MAAMS,MAAM0rB,aAAa,CAAC,IAAIrvB,KAAKC,UAAUmvB,GAAGxtB,KAAK,CAAC;AAElE,MAAIwtB,GAAGtuB,SAAS;AACd,WAAO,GAAGoC,MAAMS,MAAM0rB,aAAa,CAAC,IAAID,GAAGG,QAAQ,KAAKpC,cACtDiC,GAAGI,aACL,CAAC,KAAKxvB,KAAKC,UAAUmvB,GAAGK,KAAK,CAAC;AAEhC,MAAIL,GAAGtuB,SAAS;AACd,WAAO,GAAGoC,MAAMyN,OAAO0e,aAAa,CAAC,IAAIlC,cAAciC,GAAGI,aAAa,CAAC,KAAKxvB,KAAKC,UAChFmvB,GAAGK,KACL,CAAC;AAEH,MAAIL,GAAGtuB,SAAS;AACP,WAAA,GAAGoC,MAAMW,IAAIwrB,aAAa,CAAC,IAAID,GAAGM,UAAU,KAAKN,GAAGO,QAAQ;AAGrE,QAAM,IAAIltB,MAAM,2BAA2B2sB,GAAGtuB,IAAI,EAAE;AACtD;AAEA,SAASuqB,OAAOyB,SAAiBriB,QAAO,GAAW;AAC3CukB,QAAAA,UAAU,IAAI/C,OAAOxhB,KAAI;AAE/B,SAAOqiB,QACJ1U,MAAM;AAAA,CAAI,EACVzW,IAAKiuB,CAAAA,SAASZ,UAAUY,IAAI,EAC5BxnB,KAAK;AAAA,CAAI;AACd;ACxMA,MAAMynB,kBAAkB;AAOjB,SAASC,uBAAuBtG,SAA6B;AAClE,QAAMuG,oBAAoBvG,QAAQhW,WAAW,GAAG,IAAIgW,UAAU,IAAIA,OAAO;AAGrE,MAAA,CAACqG,gBAAgBpvB,KAAKsvB,iBAAiB;AACzC,UAAM,IAAIttB,MACR,+BAA+BstB,iBAAiB,sCAClD;AAGKA,SAAAA;AACT;ACCA,MAAMntB,aAAW;AAAA;AAAA;AAAA,oGAGmFotB,QAAwB,wBAAA,cAAcC,oCAA4B;AAAA;AAAA;AAAA;AAAA,2EAI3F/I,mBAAmB;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AA0B9F,SAAS/b,cAAcnI,MAAyB;AAC9C,SAAOoI,uBAAMC,QAAAA,QAAQrI,KAAKsI,QAAQC,QAAQD,IAAI,EAAEE,MAAM,CAAC,CAAC,EACrD5K,QAAQ,WAAW;AAAA,IAACE,MAAM;AAAA,IAAWmB,SAAS;AAAA,EAAA,CAAK,EACnDrB,QAAQ,eAAe;AAAA,IAACE,MAAM;AAAA,IAAUmB,SAASguB,QAAAA;AAAAA,EAAAA,CAA6B,EAC9ErvB,QAAQ,YAAY;AAAA,IAACE,MAAM;AAAA,IAAWmB,SAAS;AAAA,EAAA,CAAK,EACpDrB,QAAQ,WAAW;AAAA,IAACE,MAAM;AAAA,EAAA,CAAS,EACnCF,QAAQ,eAAe;AAAA,IAACE,MAAM;AAAA,EAAA,CAAS,EACvCF,QAAQ,WAAW;AAAA,IAACE,MAAM;AAAA,EAAA,CAAS,EACnCF,QAAQ,eAAe;AAAA,IAACE,MAAM;AAAA,EAAA,CAAS,EACvCF,QAAQ,WAAW;AAAA,IAACE,MAAM;AAAA,IAAWmB,SAAS;AAAA,EAAK,CAAA,EAAEqJ;AAC1D;AAEA,MAAM4kB,sBAAyD;AAAA,EAC7DhxB,MAAM;AAAA,EACN4D,OAAO;AAAA,EACP3D,WAAW;AAAA,EAAA,UACXyD;AAAAA,EACAxD,aAAa;AAAA;AAAA,EAEb2D,QAAQ,OAAOC,MAAM/B,YAAY;AACzB,UAAA;AAAA,MAACC;AAAAA,MAAW+B;AAAAA,MAAQtC;AAAAA,MAAQuC;AAAAA,MAAOkK;AAAAA,IAAWnM,IAAAA,SAC9C,CAAC+E,EAAE,IAAIhD,KAAKG,oBACZgtB,0BAA0BzoB,cAAKU,QAAAA,KAAKgF,SAAS4Z,oBAAoB,GAEjE7Z,QAAQ,MAAMhC,cAAcnI,IAAI,GAEhCotB,aAAajjB,MAAMijB,YACnBC,MAAMljB,MAAMmjB,QACZ7uB,UAAU0L,MAAM1L,SAChBshB,UAAU5V,MAAM4V,SAChB1gB,aAAa8K,MAAM9K;AAEzB,QAAKZ,WAAW,CAACshB,WAAaA,WAAW,CAACthB;AAClC,YAAA,IAAIgB,MAAM,qEAAqE;AAGvF,QAAI,CAACuD,IAAI;AACP/C,aAAOW,MAAMV,MAAMW,IAAI,sCAAsC,CAAC;AAC9D,YAAMqlB,aAAa,MAAMC,kBAAkB/b,OAAO,GAC5CqB,QAAQ,IAAIC,0BAAM;AAAA,QACtBE,OAAO;AAAA,QACPD,SAAS,CACP;AAAA,UAACzP,MAAM;AAAA,UAAM0P,OAAO;AAAA,UAAMC,WAAW;AAAA,QAAA,GACrC;AAAA,UAAC3P,MAAM;AAAA,UAAS0P,OAAO;AAAA,UAASC,WAAW;AAAA,QAAO,CAAA;AAAA,MAAA,CAErD;AAEDqa,iBAAWlgB,QAASogB,CAAqB,qBAAA;AACvC3a,cAAMM,OAAO;AAAA,UAAC/I,IAAIojB,iBAAiBpjB;AAAAA,UAAI4I,OAAOwa,iBAAiBC,UAAUza;AAAAA,QAAAA,CAAM;AAAA,MAAA,CAChF,GACDH,MAAMU,cACNlM,OAAOS,MAAM,sDAAsD;AAEnE;AAAA,IAAA;AAIS6lB,kBAAA;AAAA,MACP5O,QAAQ,OAAOpP,QAAQie,QAAQhe,MAAM,CAAC,CAAC;AAAA,MACvCie,WAAW;AAAA,QAAC,kBAAkB;AAAA,MAAA;AAAA,IAAI,CACnC;AAGGQ,UAAAA,aAAazB,uBAAuBpb,SAASpH,EAAE,GAC/CuqB,kBAAkBtG,WAAWxc,OAAOob,yBAAyB;AAEnE,QAAI0H,gBAAgBhwB,SAAS;AAErB,YAAA,IAAIkC,MACR,kCAAkCuD,EAAE,QAAQ9C,MAAM4I,KAAKqkB,uBAAuB,CAAC;AAAA,KAAUlG,WACtFtoB,IAAKuoB,CAAAA,cAAcxiB,cAAK8oB,QAAAA,SAASL,yBAAyBjG,UAAUtB,YAAY,CAAC,EACjFxgB,KAAK;AAAA,IAAO,CAAC,EAClB;AAGI0gB,UAAAA,SAASyH,gBAAgB,CAAC;AAChC,QAAI,CAACzH;AACG,YAAA,IAAIrmB,MACR,2BAA2BuD,EAAE,QAAQ9C,MAAM4I,KAAK5I,MAAM4I,KAAKqkB,uBAAuB,CAAC,CAAC;AAAA;AAAA;AAAA,KAC1DlG,WAC9BtoB,IAAKuoB,CAAAA,cAAcxiB,cAAK8oB,QAAAA,SAASL,yBAAyBjG,UAAUtB,YAAY,CAAC,EACjFxgB,KAAK;AAAA,IAAO,CAAC,EACX;AAGF,UAAMiV,MAAMyL,OAAOzL;AACf,QAAA,QAAQA,OAAO,UAAUA;AAGrB,YAAA,IAAI5a,MACR,8EACF;AAGF,UAAM4mB,YAAuBhM,IAAIpb;AAEjC,QAAImuB,cAAc,CAACC;AACX,YAAA,IAAI5tB,MAAM,wDAAwD;AAG1E,UAAMuK,cAAcG,MAAMH;AAC1B,QAAIA,gBAAgB9K,QAAW;AAC7B,UAAI8K,cAAcgjB,QAAAA;AAChB,cAAM,IAAIvtB,MACR,oDAAoDutB,QAAAA,wBAAwB,EAC9E;AAGF,UAAIhjB,gBAAgB;AAClB,cAAM,IAAIvK,MAAM,8CAA8CuK,WAAW,EAAE;AAAA,IAAA;AAI/E,UAAMyjB,gBAAgBvvB,UAAU;AAAA,MAC9BsP,aAAa;AAAA,MACbC,gBAAgB;AAAA,IACjB,CAAA,EAAEjO,OAAO;AAEN,QAAA,CAACugB,WAAW,CAAC0N,cAAcnuB;AACvB,YAAA,IAAIG,MACR,6GACF;AAGF,UAAMiuB,YAAY;AAAA,MAChBjvB,SAASA,WAAWgvB,cAAchvB;AAAAA,MAClCa,WAAWygB,WAAW0N,cAAcnuB;AAAAA,MACpCquB,SAASF,cAAcE;AAAAA,MACvBpuB,OAAOkuB,cAAcluB;AAAAA,MACrBF,YAAYytB,uBAAuBztB,cAAc6kB,mBAAmB;AAAA,IACtE;AACA,QAAImJ,KAAK;AACO,oBAAA;AACd;AAAA,IAAA;AAUF,QAPAptB,OAAOS,MACL;AAAA,EAAKR,MAAMyN,OAAOzN,MAAM2I,KAAK,qDAAqD,CAAC,CAAC,EACtF,GACA5I,OAAOS,MACL,wDAAwDR,MAAM4I,KAAK,eAAe,CAAC;AAAA,CACrF,GAEIqB,MAAMyjB,WAQJ,CAPa,MAAMjwB,OAAOE,OAAgB;AAAA,MAC5ClB,SAAS,kCAAkCuD,MAAMyN,OAC/CzN,MAAM2I,KAAK6kB,UAAUjvB,OAAO,CAC9B,CAAC,eAAeyB,MAAMyN,OAAOzN,MAAM2I,KAAK6kB,UAAUpuB,SAAS,CAAC,CAAC;AAAA,MAC7DxB,MAAM;AAAA,IAAA,CACP,GAEc;AACbZ,cAAM,wBAAwB;AAC9B;AAAA,IAAA;AAIJ,UAAMuJ,UAAUxG,OAAOwG,QAAQ,sBAAsBzD,EAAE,GAAG,EAAE0D,MAAM;AAClE,UAAMmnB,YAAI;AAAA,MAAC3N,KAAKwN;AAAAA,MAAW1jB;AAAAA,MAAaiM,YAAY6X,eAAernB,OAAO;AAAA,IAAA,GAAI4f,SAAS,GACvF5f,QAAQsnB,KAAK;AAEb,aAASD,eAAe9kB,iBAAoD;AAC1E,aAAO,SAAoB9G,WAA6B;AAClD,YAAA,CAACiI,MAAMjI,UAAU;AACnB8G,0BAAgB+kB,KAAK;AACrB;AAAA,QAAA;AAEF,YAAI7rB,UAAS8rB,MAAM;AACD7mB,0BAAAA,OAAO,cAAcnE,EAAE;AAAA;AAAA,iBAEhC9C,MAAM2I,KAAK6kB,UAAUpuB,SAAS,CAAC;AAAA,iBAC/BY,MAAM2I,KAAK6kB,UAAUjvB,OAAO,CAAC;AAAA;AAAA,IAE1CyD,UAASya,SAAS;AAAA,IAClBza,UAAS6a,SAAS;AAAA,IAClB7c,MAAMS,MAAMuB,UAAS+rB,sBAAsB1wB,MAAM,CAAC,4BAC5CyL,gBAAgBklB,eAAe;AAAA,YAACC,QAAQjuB,MAAMS,MAAM,QAAG;AAAA,UAAA,CAAE;AACzD;AAAA,QAAA;AAGD,SAAC,MAAM,GAAGuB,UAASksB,mBAAmB,EAAEpoB,QAASqX,CAAgB,gBAAA;AAChErU,0BAAgB7B,OAAO,sBAAsBnE,EAAE,KAAKqqB,MAAM,mBAAmB,KAAK;AAAA;AAAA,oBAExEntB,MAAM2I,KAAK6kB,UAAUpuB,SAAS,CAAC;AAAA,oBAC/BY,MAAM2I,KAAK6kB,UAAUjvB,OAAO,CAAC;AAAA,oBAC7ByB,MAAM2I,KAAKwd,UAAUhC,eAAejf,KAAK,GAAG,CAAC,CAAC;AAAA;AAAA,IAE9DlD,UAASya,SAAS;AAAA,IAClBza,UAAS6a,SAAS;AAAA,IAClB7c,MAAMmuB,KAAKnsB,UAASosB,OAAO,CAAC;AAAA,IAC5BpuB,MAAMS,MAAMuB,UAAS+rB,sBAAsB1wB,MAAM,CAAC;AAAA;AAAA,IAGlD8f,eAAe,CAACnb,UAAS8rB,OACrB,QAAKnE,aAAa;AAAA,YAAC3pB;AAAAA,YAAO4pB,SAASzM;AAAAA,YAAagJ;AAAAA,YAAW0D,YAAY;AAAA,UAAA,CAAE,CAAC,KAC1E,EAAC;AAAA,QAAA,CAEA;AAAA,MACH;AAAA,IAAA;AAGF,mBAAewE,gBAAgB;AAC7BtuB,aAAOS,MAAM,sBAAsBsC,EAAE,eAAe,GAEhDoqB,cACFntB,OAAOS,MAAM,gBAAgBR,MAAM4I,KAAKskB,UAAU,CAAC,EAAE,GAGvDntB,OAAOS,MAAM,GACbT,OAAOS,MAAM,gBAAgBR,MAAM2I,KAAK6kB,UAAUpuB,SAAS,CAAC,EAAE,GAC9DW,OAAOS,MAAM,gBAAgBR,MAAM2I,KAAK6kB,UAAUjvB,OAAO,CAAC,EAAE;AAE5D,uBAAiB2sB,YAAYkC,eAAO;AAAA,QAACpN,KAAKwN;AAAAA,QAAWc,YAAYpB;AAAAA,SAAa/G,SAAS;AAChF+E,qBACLnrB,OAAOS,MAAAA,GACPT,OAAOS,MACLmpB,aAAa;AAAA,UACX3pB;AAAAA,UACA4pB,SAASsB;AAAAA,UACT/E;AAAAA,QACD,CAAA,CACH;AAAA,IAAA;AAAA,EAEJ;AAEJ,GCjRMzmB,aAAW;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA,GAcX6uB,iBAAuC;AAAA,EAC3CvyB,MAAM;AAAA,EACNC,WAAW;AAAA,EACXC,aAAa;AAAA,EACb2D,QAAQ,OACNC,MACA/B,aAEsB,MAAMywB,mBAAiB,GAExB1uB,MAAM/B,OAAO;AAAA,EAEpC2B,UAAAA;AACF;AAEA,eAAe8uB,qBAAmB;AAUpB,UAAA,MAAM;mBAAO,oBAAqC;AAAA,EAAA,CAAA,GAEnDzvB;AACb;AChDA,MAAM7C,gBAAc,8EAEdwD,aAAW;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA,GAcX+uB,uBAA6C;AAAA,EACjDzyB,MAAM;AAAA,EACN4D,OAAO;AAAA,EACP3D,WAAW;AAAA,EAAA,aACXC;AAAAA,EAAAA,UACAwD;AAAAA,EACAG,QAAQ,OAAOC,MAAM/B,aACP,MAAM,QAAA,QAAA,EAAA,KAAA,WAAA;AAAA,WAAA,QAAO,oBAAoC;AAAA,EAAA,CAAA,GAElDgB,QAAQe,MAAM/B,OAAO;AAEpC;AC7BA,IAAe,cAAA;AAAA,EACb/B,MAAM;AAAA,EACNC,WAAW;AAAA,EACXE,aAAa;AAAA,EACbD,aAAa;AACf;ACHA,MAAMA,cAAc,wDAEdwD,aAAW;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA,GAiBX6gB,2BAAiD;AAAA,EACrDvkB,MAAM;AAAA,EACN4D,OAAO;AAAA,EACP3D,WAAW;AAAA,EACXC;AAAAA,EAAAA,UACAwD;AAAAA,EACAG,QAAQ,OAAOC,MAAM/B,aACP,MAAM,QAAA,QAAA,EAAA,KAAA,WAAA;AAAA,WAAA,QAAO,qBAAqC;AAAA,EAAA,CAAA,GAEnDgB,QAAQe,MAAM/B,OAAO;AAEpC,GC/Ba2wB,gBACXrmB,QAAQsmB,OAAOC,SAASvmB,QAAQ4V,IAAI4Q,SAAS,UAAU,EAAE,QAAQxmB,QAAQ4V,MCQrEve,aAAW;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA,GAcXovB,eAAqC;AAAA,EACzC9yB,MAAM;AAAA,EACNC,WAAW;AAAA,EACXC,aAAa;AAAA,EACb2D,QAAQ,OACNC,MACA/B,YACG;AACG,UAAA;AAAA,MAACgC;AAAAA,MAAQC;AAAAA,MAAOvC;AAAAA,IAAM,IAAIM,SAC1BgxB,gBAAgB,MAAMP,oBAEtB/f,OAAQtI,CAAAA,QAAgBpG,OAAO0O,KAAKzO,MAAMyN,OAAOuhB,QAAQ7oB,GAAG,CAAC,GAC7DzF,QAASyF,CAAgBpG,QAAAA,OAAO0O,KAAKzO,MAAMW,IAAIquB,QAAQ7oB,GAAG,CAAC;AACjEsI,SAAK,gXAA+D,GACpEA,KAAK,yEAA+D,GACpEA,KAAK,yEAA+D,GACpEA,KAAK,oEAA+D,GACpEA,KAAK,yEAA+D,GACpEA,KAAK,oEAA+D,GACpEA,KAAK,yEAA+D,GACpEA,KAAK,yEAA+D,GACpEA,KAAK,yEAA+D,GACpEA,KAAK,gXAA+D,GACpEA,KAAK,EAAE;AAEH,QAAA;AACIsgB,YAAAA,cAAcjvB,MAAM/B,OAAO;AAAA,aAC1B1B,KAAK;AACZ,UAAIA,IAAIL,SAAS;AACTK,cAAAA;AAGFA,YAAAA,IAAII,OAAO,GACjBiE,MAAM;AAAA,CAAI,GAGRguB,iBACC,MAAMjxB,OAAOE,OAAO;AAAA,QACnBlB,SAAS;AAAA,QACTmB,MAAM;AAAA,MACP,CAAA,IAID,OADkB,MAAM0c,aAAavc,OAAO,GAC5B+B,MAAM/B,OAAO,IAI7BsK,QAAQmU,KAAK,CAAC;AAAA,IAAA;AAAA,EAGpB;AAAA,EACA9c,UAAAA;AACF;AAEA,eAAe8uB,mBAAmB;AAUpB,UAAA,MAAM;mBAAO,oBAAqC;AAAA,EAAA,CAAA,GAEnDzvB;AACb;AC5FO,SAASkwB,mBAAmBxyB,SAAiB;AAClD,SAAQJ,CAAsE,QAAA;AAC5E,UAAIA,IAAIG,eAAe,QACrBH,IAAII,UAAUA,UACRJ;AAAAA,EAIV;AACF;ACJA,MAAMqD,aAAW;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA,GAmBXwvB,oBAAuD;AAAA,EAC3DlzB,MAAM;AAAA,EACN4D,OAAO;AAAA,EACP3D,WAAW;AAAA,EAAA,UACXyD;AAAAA,EACAxD,aAAa;AAAA,EACb2D,QAAQ,OAAOC,MAAM/B,YAAY;AACzB,UAAA;AAAA,MAACC;AAAAA,MAAW+B;AAAAA,MAAQtC;AAAAA,IAAUM,IAAAA,SAC9B,CAACoxB,aAAa,IAAIrvB,KAAKG,oBACvBgK,QAAQnK,KAAKyO,YAEbrQ,SAASF,UAAYqa,EAAAA,MAAAA,EAAQ/Y,OAAO;AAAA,MAAC8vB,oBAAoB;AAAA,MAAOjwB,YAAY;AAAA,IAAA,CAAa,GACzF;AAAA,MAACC;AAAAA,IAAAA,IAAalB,OAAOoB,UACrB+vB,SAAS,MAAMnxB,OAAOgC,QAAgB;AAAA,MAACI,KAAK,aAAalB,SAAS;AAAA,IAAA,CAAS,GAAGmL,OACjF+kB,CAAAA,UAASA,MAAKC,cACjB,GACMC,QAAQL,iBAAkB,MAAMM,eAAehyB,MAAM,GACrDiyB,eAAezlB,MAAMqlB,QAAS,MAAMK,cAAclyB,QAAQ4xB,KAAK,GAC/DC,OAAOD,MAAM/wB,KAAK,CAAC;AAAA,MAACtC;AAAAA,UAAUA,KAAKoB,YAAAA,MAAkBsyB,aAAatyB,aAAa;AACrF,QAAI,CAACkyB;AACH,YAAM,IAAI/vB,MAAM,cAAcmwB,YAAY,aAAa;AAGnDxxB,UAAAA,OACHma,MAAM,EACNnY,QAAQ;AAAA,MACPC,QAAQ;AAAA,MACRG,KAAK,wBAAwBlB,SAAS;AAAA,MACtCxC,MAAM;AAAA,QAAC4yB;AAAAA,QAAOF,MAAMA,KAAKtzB;AAAAA,MAAI;AAAA,MAC7B4zB,cAAc;AAAA,MACdhrB,cAAc;AAAA,IACf,CAAA,EACA0R,MACC2Y,mBACE,yGACF,CACF,GAEFlvB,OAAOS,MAAM,sBAAsBgvB,KAAK,EAAE;AAAA,EAAA;AAE9C;AAIA,SAASC,eAAehyB,QAAsC;AAC5D,SAAOA,OAAOE,OAAO;AAAA,IACnBC,MAAM;AAAA,IACNnB,SAAS;AAAA,IACT8N,QAASslB,CAAQA,QAAAA,IAAI7e,KAAK;AAAA,IAC1BnT,UAAW7B,UACL,CAACA,QAAQ,CAACA,KAAKgR,SAAS,GAAG,IACtB,kBAGF;AAAA,EAAA,CAEV;AACH;AAEA,SAAS2iB,cAAclyB,QAAqB4xB,OAAgC;AAC1E,SAAO5xB,OAAOE,OAAO;AAAA,IACnBC,MAAM;AAAA,IACNnB,SAAS;AAAA,IACTmC,SAASywB,MAAM5wB,IAAK6wB,CAAU,UAAA;AAAA,MAC5B5wB,OAAO4wB,KAAKtzB;AAAAA,MACZA,MAAM,GAAGszB,KAAK5jB,KAAK,KAAK4jB,KAAKpzB,WAAW;AAAA,IAAA,EACxC;AAAA,EAAA,CACH;AACH;ACvFA,MAAM4zB,aAAa,CAAC,MAAM,QAAQ,QAAQ,MAAM,GAE1CpwB,WAAW;AAAA;AAAA;AAAA;AAAA,mDAIkCowB,WAAW5qB,KAAK,IAAI,CAAC;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA,GAclE6qB,mBAAyC;AAAA,EAC7C/zB,MAAM;AAAA,EACN4D,OAAO;AAAA,EACP3D,WAAW;AAAA,EACXyD;AAAAA,EACAxD,aAAa;AAAA,EACb2D,QAAQ,OAAOC,MAAM/B,YAAY;AACzB,UAAA;AAAA,MAACC;AAAAA,MAAW+B;AAAAA,MAAQC;AAAAA,QAASjC,SAC7B;AAAA,MAACiyB;AAAAA,MAAMC;AAAAA,MAAOC;AAAAA,MAAQC;AAAAA,IAAAA,IAAe;AAAA,MACzCH,MAAM;AAAA,MACNC,OAAO;AAAA,MACPC,QAAQ;AAAA,MACRC,aAAa;AAAA,MACb,GAAGrwB,KAAKyO;AAAAA,IACV;AAEI,QAAA,CAACuhB,WAAW9iB,SAASgjB,IAAI;AACrB,YAAA,IAAIzwB,MAAM,wBAAwBywB,IAAI,qBAAqBF,WAAW5qB,KAAK,IAAI,CAAC,EAAE;AAGtF+qB,QAAAA,UAAU,SAASA,UAAU;AAC/B,YAAM,IAAI1wB,MAAM,uBAAuB0wB,KAAK,mCAAmC;AAGjF,UAAM/xB,SAASF,aACToyB,eAAelyB,OAAOma,QAAQ/Y,OAAO;AAAA,MAAC8vB,oBAAoB;AAAA,IAAA,CAAM,GAChE;AAAA,MAAChwB;AAAAA,QAAalB,OAAOoB,OAAAA,GAErBswB,eAAe,IACf,CAACS,oBAAoBxQ,OAAO,IAAI,MAAM3e,QAAQ8O,IAAI,CACtDmgB,cACIC,aACGlwB,QAAkB;AAAA,MAACI,KAAK,wBAAwBlB,SAAS;AAAA,MAAIwwB;AAAAA,IAAAA,CAAa,EAC1E3f,KAAKqgB,qBAAqB,IAC7B,CAAA,GACJF,aAAalwB,QAAgC;AAAA,MAACI,KAAK,aAAalB,SAAS;AAAA,MAAIwwB;AAAAA,IAAa,CAAA,CAAC,CAC5F,GAEKW,YAAY1Q,QAAQ2Q,QAAQ/xB,IAAKgyB,CAAAA,WAAWA,OAAO3tB,EAAE,GACrD4tB,QAAQ,MAAMN,aACjBlwB,QAAuB;AAAA,MAACI,KAAK,UAAUiwB,UAAUrrB,KAAK,GAAG,CAAC;AAAA,MAAI0qB;AAAAA,IAAAA,CAAa,EAC3E3f,KAAM0gB,UAAUhU,MAAMC,QAAQ+T,IAAI,IAAIA,OAAO,CAACA,IAAI,CAAE,GASjDH,UAAU,CAAC,GAPM3Q,QAAQ2Q,QAC5B/xB,IAAKgyB,CAAY,YAAA;AAAA,MAChB,GAAGA;AAAAA,MACH,GAAGG,aAAaF,MAAMpyB,KAAM0oB,eAAcA,UAAUlkB,OAAO2tB,OAAO3tB,EAAE,CAAC;AAAA,IAAA,EACrE,EACDyH,OAAQkmB,CAAW,WAAA,CAACA,OAAOI,WAAWX,MAAM,GAEX,GAAGG,kBAAkB,GAEnDS,UAAUC,gBACdP,QAAAA,QAAQ/xB,IAAI,CAAC;AAAA,MAACqE;AAAAA,MAAI9G;AAAAA,MAAMszB;AAAAA,MAAMpjB;AAAAA,IAAAA,MAAU,CAACpJ,IAAI9G,MAAMszB,MAAMpjB,IAAI,CAAC,GAC9D,CAAC4jB,WAAWrZ,QAAQuZ,IAAI,CAAC,CAC3B,GAEMgB,OAAOf,UAAU,QAAQa,UAAUA,QAAQG,QAAQ,GAEnDC,YAAYF,KAAKzS,OACrB,CAACwJ,KAAKoJ,QAAQA,IAAI1yB,IAAI,CAACsI,SAAS+V,UAAUxZ,KAAKykB,IAAIxgB,cAAAA,QAAKR,OAAO,GAAGghB,IAAIjL,KAAK,CAAC,CAAC,GAC7EgT,WAAWrxB,IAAKoY,CAAQtP,QAAAA,cAAAA,QAAKsP,GAAG,CAAC,CACnC,GAEMua,WAAYD,CAAkB,QAAA;AAC5BE,YAAAA,WAAWF,IAAI,CAAC,MAAM,aACtBG,UAAUH,IAAI1yB,IAAI,CAAC8yB,KAAK/pB,MAAM,GAAG+pB,GAAG,GAAG1oB,OAAOqoB,UAAU1pB,CAAC,CAAC,CAAC,EAAEtC,KAAK,KAAK;AAC7E,aAAOmsB,WAAWrxB,MAAMwxB,IAAIF,OAAO,IAAIA;AAAAA,IACzC;AAEAvxB,WAAOS,MAAMR,MAAM4I,KAAKwoB,SAAStB,UAAU,CAAC,CAAC,GAC7CkB,KAAKlrB,QAASqrB,SAAQpxB,OAAOS,MAAM4wB,SAASD,GAAG,CAAC,CAAC;AAAA,EAAA;AAErD;AAEA,SAASP,aAAaD,MAAwB;AACtC,QAAA;AAAA,IAACc,aAAaz1B;AAAAA,IAAM4P,WAAWM;AAAAA,EAAI,IAAIykB,QAAQ,CAAC;AAC/C,SAAA;AAAA,IAAC30B,MAAMA,QAAQ;AAAA,IAAIkQ,MAAMA,QAAQ;AAAA,EAAE;AAC5C;AAEA,SAASokB,sBAAsBH,aAAuB;AACpD,SAAOA,YACJ5lB,OAAQmnB,CAAW,WAAA,CAACA,OAAOC,cAAc,CAACD,OAAOE,aAAa,CAACF,OAAOG,gBAAgB,EACtFpzB,IAAKizB,CAAY,YAAA;AAAA,IAChB5uB,IAAI;AAAA,IACJ9G,MAAM01B,OAAOlC;AAAAA,IACbF,MAAMoC,OAAOpC;AAAAA,IACbpjB,MAAMwlB,OAAO9lB;AAAAA,EAAAA,EACb;AACN;AChHO,MAAMkmB,aAAwC;AAAA,EACnD91B,MAAM;AAAA,EACNC,WAAW;AAAA,EACXE,aAAa;AAAA,EACbD,aAAa;AACf,GCiDM61B,WAAiE,CACrE1lB,cACA2lB,cACA9X,eACAE,iBACAL,qBACA5F,sBACAM,0BACAgB,sBACA6B,sBACA1C,sBACAlB,oBACAue,cACAC,oBACAC,0BACA5pB,uBACA6pB,6BACAC,4BACA3jB,WACAM,wBACAV,sBACAK,yBACAmjB,YACA5C,mBACAa,kBACAtO,WACAgC,kBACA5C,mBACAyR,gBACA3N,wBACAqI,qBACAuF,sBACApR,mBACAmB,qBACAZ,yBACA9C,gBACAe,qBACA6S,uBACAnU,wBACA9D,wBACAgG,4BACAI,cACAC,wBACAF,yBACAD,yBACApG,YACAyU,cACA2D,aACAC,0BACAjE,sBACAF,gBACA/N,aACAmS,eACAhP,sBAAsB,GAOXiP,qBAAqB;AAAA,EAChCC,yBAAyB;AAAA,EACzBd;AACF;;;;;;;;"}